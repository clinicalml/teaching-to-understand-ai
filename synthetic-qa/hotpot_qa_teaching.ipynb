{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"hotpot_qa_teaching.ipynb","provenance":[{"file_id":"17ZhI4xATy-NPWIl-Uh7sSzgkHtN2j3gw","timestamp":1614622568106},{"file_id":"1nDHjgK_wPzlUYYFK0gh3KWtBWpIVgsYH","timestamp":1614093172414}],"collapsed_sections":["UP1CACu3irWL","5WSnSiY1dF2E","ZcLYv_ROubNK","AK9JLhs-97wO","aHZUGq_f-IBp","edq-HElcAmIE","rFqizkYIVHz4","PuxiBHbj_zde"],"authorship_tag":"ABX9TyMHooMeJd2MmkRyNXvawLo3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"059c9c08be764be6bfdcdd814f2401ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_76e7a5cf893a497f92b338dd01cbed4d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_33635f3e441842c9aacc9045989427f2","IPY_MODEL_72fc20409ac64970bca1f20434c29e76"]}},"76e7a5cf893a497f92b338dd01cbed4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33635f3e441842c9aacc9045989427f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_39482c0745a844c39f238bed9a9dec16","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7405,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7405,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fde4010baf4a48a6bb0ed71d8e7aaf3b"}},"72fc20409ac64970bca1f20434c29e76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db817130bc5543f09027aee165d895e2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7405/7405 [00:08&lt;00:00, 835.25ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1ffa35d4e2b4813959fce0c071ec329"}},"39482c0745a844c39f238bed9a9dec16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fde4010baf4a48a6bb0ed71d8e7aaf3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db817130bc5543f09027aee165d895e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a1ffa35d4e2b4813959fce0c071ec329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9880e0c2636480c9f8ffe12d64090dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_125a746c922042919df2f58b23ef89c0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15114e6b63384d7e9e8ea8a1bc1f4692","IPY_MODEL_b83c0b49950148d8990c1fab3e162ce1"]}},"125a746c922042919df2f58b23ef89c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15114e6b63384d7e9e8ea8a1bc1f4692":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_57065a51338f4403bcb28c80d6305eb8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":765,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":765,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a07b66389045402b975a67f96a7f19be"}},"b83c0b49950148d8990c1fab3e162ce1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8eba1ed0e16c40d98fe1d25462b91380","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 765/765 [00:02&lt;00:00, 290B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84767651dea442db90862d9e039c536c"}},"57065a51338f4403bcb28c80d6305eb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a07b66389045402b975a67f96a7f19be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8eba1ed0e16c40d98fe1d25462b91380":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84767651dea442db90862d9e039c536c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04a4d6d372a5467b8fdd1de5c4f084f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e3a7d94da284c728f4114318184b7c3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b91f897534ff42e5aadd7ab43e9955c6","IPY_MODEL_a3185f949a2142dc9f2891179f243ee1"]}},"0e3a7d94da284c728f4114318184b7c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b91f897534ff42e5aadd7ab43e9955c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9192d89195364047b85ae67fcce3b668","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d23fbe8317f442bb1353e286838375e"}},"a3185f949a2142dc9f2891179f243ee1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4686b62e8e8a4559916687c4213daee0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:01&lt;00:00, 161kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7b2387dda6748aebe12425d15bc3282"}},"9192d89195364047b85ae67fcce3b668":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9d23fbe8317f442bb1353e286838375e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4686b62e8e8a4559916687c4213daee0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7b2387dda6748aebe12425d15bc3282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2f2391781734419b622be2361ff1433":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_af88ec8f33fe4a7fae835436268f213e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ba6640db2344bb7a179d04042dcf108","IPY_MODEL_a3777e0b0d7b42ba89d7a4fe2ccc7013"]}},"af88ec8f33fe4a7fae835436268f213e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ba6640db2344bb7a179d04042dcf108":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_72d1cb4b6f434c1e9e2fcf7d6ba04669","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e171cec87814ad6b9ddb7f0630a1c89"}},"a3777e0b0d7b42ba89d7a4fe2ccc7013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ccb1fd5cb174d18860595edec539856","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 176B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71364f72ae414719a3379be64a39cd67"}},"72d1cb4b6f434c1e9e2fcf7d6ba04669":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8e171cec87814ad6b9ddb7f0630a1c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ccb1fd5cb174d18860595edec539856":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71364f72ae414719a3379be64a39cd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f226ce3fe3f4e618d91fc9cb1066d25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2b519f7fe20c464a892f33b6d5677f64","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0215ee1fa348482fb75b1b58301fd768","IPY_MODEL_9c29a5fad1774f4c91c121da918f1cfb"]}},"2b519f7fe20c464a892f33b6d5677f64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0215ee1fa348482fb75b1b58301fd768":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_86609e0779644f5697dfaadcd17674ee","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":85,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":85,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf981352081c47c9aea8b1e9adcecf45"}},"9c29a5fad1774f4c91c121da918f1cfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bca184508bdb46b48eb321663fa10826","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 85.0/85.0 [00:00&lt;00:00, 1.30kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bdfb15978e0453b9c5adc3b973f14a9"}},"86609e0779644f5697dfaadcd17674ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cf981352081c47c9aea8b1e9adcecf45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bca184508bdb46b48eb321663fa10826":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3bdfb15978e0453b9c5adc3b973f14a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffda92c5d6864e80bdce835165b41b49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_23fa35d177884a52ad8b8de8f09cdf98","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1fd294c2966428884dfe57d727fb4eb","IPY_MODEL_ab49a7f2d2434d2fa0070098f616e572"]}},"23fa35d177884a52ad8b8de8f09cdf98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1fd294c2966428884dfe57d727fb4eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cd1f06145aaa4634b5f9b6b792525895","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":98612473,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":98612473,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_19a836ea83304ab29827c870209fb163"}},"ab49a7f2d2434d2fa0070098f616e572":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b4f89b979f394b3e9897c83814db6379","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 98.6M/98.6M [00:03&lt;00:00, 24.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1fad0a01fcf4772bc48af23eed3793d"}},"cd1f06145aaa4634b5f9b6b792525895":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"19a836ea83304ab29827c870209fb163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4f89b979f394b3e9897c83814db6379":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a1fad0a01fcf4772bc48af23eed3793d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UP1CACu3irWL"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"h9FD0NWldZ1T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616473884219,"user_tz":240,"elapsed":32746,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"8893f17a-2a61-406d-cc36-4d96ededebc3"},"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece\n","!pip install scikit-learn-extra"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 33.2MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 52.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=0a72c1f983f9522a62b3be448b2a80f0c703177485a08f1d1611be921af9d563\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n","Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/43b396481a8298c6010afb93b3c1e71d4ba6f8c10797a7da8eb005e45081/datasets-1.5.0-py3-none-any.whl (192kB)\n","\u001b[K     |████████████████████████████████| 194kB 9.0MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting huggingface-hub<0.1.0\n","  Downloading https://files.pythonhosted.org/packages/af/07/bf95f398e6598202d878332280f36e589512174882536eb20d792532a57d/huggingface_hub-0.0.7-py3-none-any.whl\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 15.0MB/s \n","\u001b[?25hCollecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 18.5MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: huggingface-hub, xxhash, fsspec, datasets\n","Successfully installed datasets-1.5.0 fsspec-0.8.7 huggingface-hub-0.0.7 xxhash-2.0.0\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 7.8MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n","Collecting scikit-learn-extra\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/891d2ee7bd18af8f2e1df5d63a52ee96edd0eacc21bb9627072b1c5f6a6c/scikit-learn-extra-0.1.0b2.tar.gz (615kB)\n","\u001b[K     |████████████████████████████████| 624kB 7.1MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->scikit-learn-extra) (1.0.1)\n","Building wheels for collected packages: scikit-learn-extra\n","  Building wheel for scikit-learn-extra (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.1.0b2-cp37-cp37m-linux_x86_64.whl size=339934 sha256=01032c697221253e70441084d78f864ae656230a7b6216ba2b154986f1d6101b\n","  Stored in directory: /root/.cache/pip/wheels/04/01/0f/943bffb48bac048fa216b4325f1a6c939491ccb0ff500e08f4\n","Successfully built scikit-learn-extra\n","Installing collected packages: scikit-learn-extra\n","Successfully installed scikit-learn-extra-0.1.0b2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRNFoaJXvO4x","executionInfo":{"status":"ok","timestamp":1616473892524,"user_tz":240,"elapsed":40979,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"cf276e92-dac6-4637-e7f3-566415b79def"},"source":["import math\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import argparse\n","from __future__ import print_function\n","from collections import Counter\n","import string\n","import re\n","import argparse\n","import json\n","import os\n","import random\n","import shutil\n","import time\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","from tqdm import tqdm\n","import torch.optim\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.autograd import Variable\n","from PIL import Image\n","import torch.utils.data as data\n","from torchvision.datasets.utils import download_url, check_integrity\n","import sys\n","from sklearn.decomposition import PCA\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","import pickle\n","from sklearn.gaussian_process.kernels import RBF\n","import torch\n","from scipy.stats import multivariate_normal\n","import  scipy.stats as st\n","from matplotlib import cm\n","import torch.optim as optim\n","from __future__ import print_function\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW, AutoModel\n","import nltk\n","from torch.utils.data import DataLoader\n","import pickle\n","import spacy\n","from gensim import corpora, models, similarities\n","import gensim\n","from spacy.lang.en import English\n","from nltk.corpus import wordnet as wn\n","from nltk.stem.wordnet import WordNetLemmatizer\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5WSnSiY1dF2E"},"source":["# HotpotQA\n"]},{"cell_type":"code","metadata":{"id":"e-1r7KAwnJZJ"},"source":["DISTRACTORS_PARS_LEN = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3E0eakH8dHfv","executionInfo":{"status":"ok","timestamp":1616474655549,"user_tz":240,"elapsed":1331,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"627427fe-1daf-4495-822c-5f702741f0fc"},"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"hotpot_qa\", 'distractor')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reusing dataset hotpot_qa (/root/.cache/huggingface/datasets/hotpot_qa/distractor/1.0.0/2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"S-o25hhVijhw"},"source":["train_dataset = dataset['train']\n","validation_dataset = dataset['validation']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJ6dM--GgRUY"},"source":["filtering steps:\n","\n","1.    remove yes-no questions\n","2.   join sentences together\n","3. keep only 1 distractor paragraphs \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"0aNneMSO8HIN"},"source":["tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n","model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqzhee23lkrz"},"source":["\n","def get_token_lenght(context, question):\n","    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n","    return len(inputs['input_ids'][0])\n","\n","def remove_distractors(example):\n","    all_pars = example['context']['title']\n","    gold_pars = list(set(example['supporting_facts']['title']))\n","    distractor_pars = list(set(all_pars) - set(gold_pars))\n","    # get indices to keep from disractors\n","    if len(distractor_pars) == 0 or DISTRACTORS_PARS_LEN == 0:\n","        distract_indices = []\n","    else:\n","        distract_indices = random.sample(range(len(distractor_pars)), DISTRACTORS_PARS_LEN)\n","    distractor_pars = [distractor_pars[idx] for idx in distract_indices]\n","    keep_pars = gold_pars + distractor_pars\n","    keep_pars_indices = [all_pars.index(keep_par) for keep_par in keep_pars]\n","    example['context']['title'] = [example['context']['title'][idx] for idx in keep_pars_indices]\n","    example['context']['sentences'] = [\"\".join(example['context']['sentences'][idx]) for idx in keep_pars_indices] \n","\n","    question = example['question']\n","    context = \"\".join(example['context']['sentences'])\n","    lenght = get_token_lenght(context, question)\n","    if lenght >= 512:\n","        all_pars = example['context']['title']\n","        gold_pars = list(set(example['supporting_facts']['title']))\n","        # get indices to keep from disractors\n","        keep_pars = gold_pars\n","        keep_pars_indices = [all_pars.index(keep_par) for keep_par in keep_pars]\n","        example['context']['title'] = [example['context']['title'][idx] for idx in keep_pars_indices]\n","        example['context']['sentences'] = [\"\".join(example['context']['sentences'][idx]) for idx in keep_pars_indices] \n","    return example"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["059c9c08be764be6bfdcdd814f2401ab","76e7a5cf893a497f92b338dd01cbed4d","33635f3e441842c9aacc9045989427f2","72fc20409ac64970bca1f20434c29e76","39482c0745a844c39f238bed9a9dec16","fde4010baf4a48a6bb0ed71d8e7aaf3b","db817130bc5543f09027aee165d895e2","a1ffa35d4e2b4813959fce0c071ec329"]},"id":"unz9KJ9qofO3","executionInfo":{"status":"ok","timestamp":1616474666674,"user_tz":240,"elapsed":12427,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"facf8eee-b901-4a1d-cd27-164907ba1358"},"source":["train_dataset = train_dataset.map(remove_distractors)\n","validation_dataset = validation_dataset.map(remove_distractors)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/hotpot_qa/distractor/1.0.0/2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d/cache-d7aac0e427adf49a.arrow\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"059c9c08be764be6bfdcdd814f2401ab","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7405.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fcJ5uT4rgojJ"},"source":["# remove yes/no questions and oversized questions\n","indices_train = []\n","indices_val = []\n","questions_train = train_dataset[:]['question']\n","contexts_train = train_dataset[:]['context']\n","questions_val = validation_dataset[:]['question']\n","contexts_val = validation_dataset[:]['context']\n","answers_train = train_dataset[:]['answer']\n","answers_val = validation_dataset[:]['answer']\n","\n","for i in range(len(answers_train)):\n","    if answers_train[i] not in ['yes','no']:\n","        question = questions_train[i]\n","        context = \"\".join(contexts_train[i]['sentences'])\n","        lenght = get_token_lenght(context, question)\n","        if lenght <= 500:\n","            indices_train.append(i)\n","for i in range(len(answers_val)):\n","    if answers_val[i] not in ['yes','no']:\n","        question = questions_val[i]\n","        context = \"\".join(contexts_val[i]['sentences'])\n","        lenght = get_token_lenght(context, question)\n","        if lenght <= 500:\n","            indices_val.append(i)\n","\n","\n","train_dataset = train_dataset.select(indices_train)\n","validation_dataset = validation_dataset.select(indices_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VLgW2o6dyI0F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616474734531,"user_tz":240,"elapsed":80266,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"51478eeb-60d3-4353-9b3f-169403730e3d"},"source":["train_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['answer', 'context', 'id', 'level', 'question', 'supporting_facts', 'type'],\n","    num_rows: 84754\n","})"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"7uaXr2c6wNWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616474734532,"user_tz":240,"elapsed":80260,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"1eacc17f-8a98-4080-8212-123df6ed779d"},"source":["validation_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['answer', 'context', 'id', 'level', 'question', 'supporting_facts', 'type'],\n","    num_rows: 6935\n","})"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"sByR2MfP5XBG"},"source":["# QA model on Hotpot"]},{"cell_type":"markdown","metadata":{"id":"ZcLYv_ROubNK"},"source":["## hotpot"]},{"cell_type":"code","metadata":{"id":"Bdwf31bAueiP","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e9880e0c2636480c9f8ffe12d64090dd","125a746c922042919df2f58b23ef89c0","15114e6b63384d7e9e8ea8a1bc1f4692","b83c0b49950148d8990c1fab3e162ce1","57065a51338f4403bcb28c80d6305eb8","a07b66389045402b975a67f96a7f19be","8eba1ed0e16c40d98fe1d25462b91380","84767651dea442db90862d9e039c536c","04a4d6d372a5467b8fdd1de5c4f084f1","0e3a7d94da284c728f4114318184b7c3","b91f897534ff42e5aadd7ab43e9955c6","a3185f949a2142dc9f2891179f243ee1","9192d89195364047b85ae67fcce3b668","9d23fbe8317f442bb1353e286838375e","4686b62e8e8a4559916687c4213daee0","a7b2387dda6748aebe12425d15bc3282","a2f2391781734419b622be2361ff1433","af88ec8f33fe4a7fae835436268f213e","5ba6640db2344bb7a179d04042dcf108","a3777e0b0d7b42ba89d7a4fe2ccc7013","72d1cb4b6f434c1e9e2fcf7d6ba04669","8e171cec87814ad6b9ddb7f0630a1c89","7ccb1fd5cb174d18860595edec539856","71364f72ae414719a3379be64a39cd67","2f226ce3fe3f4e618d91fc9cb1066d25","2b519f7fe20c464a892f33b6d5677f64","0215ee1fa348482fb75b1b58301fd768","9c29a5fad1774f4c91c121da918f1cfb","86609e0779644f5697dfaadcd17674ee","cf981352081c47c9aea8b1e9adcecf45","bca184508bdb46b48eb321663fa10826","3bdfb15978e0453b9c5adc3b973f14a9","ffda92c5d6864e80bdce835165b41b49","23fa35d177884a52ad8b8de8f09cdf98","c1fd294c2966428884dfe57d727fb4eb","ab49a7f2d2434d2fa0070098f616e572","cd1f06145aaa4634b5f9b6b792525895","19a836ea83304ab29827c870209fb163","b4f89b979f394b3e9897c83814db6379","a1fad0a01fcf4772bc48af23eed3793d"]},"executionInfo":{"status":"ok","timestamp":1616367427535,"user_tz":240,"elapsed":15308,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"6dd180b6-00ef-48d9-f30b-9d2ccaef8fee"},"source":["from transformers import DistilBertTokenizerFast\n","#tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"csarron/mobilebert-uncased-squad-v1\")\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"csarron/mobilebert-uncased-squad-v1\")\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9880e0c2636480c9f8ffe12d64090dd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=765.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04a4d6d372a5467b8fdd1de5c4f084f1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2f2391781734419b622be2361ff1433","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f226ce3fe3f4e618d91fc9cb1066d25","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffda92c5d6864e80bdce835165b41b49","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=98612473.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["MobileBertForQuestionAnswering(\n","  (mobilebert): MobileBertModel(\n","    (embeddings): MobileBertEmbeddings(\n","      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n","      (LayerNorm): NoNorm()\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): MobileBertEncoder(\n","      (layer): ModuleList(\n","        (0): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (1): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (2): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (3): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (4): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (5): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (6): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (7): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (8): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (9): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (10): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (11): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (12): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (13): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (14): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (15): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (16): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (17): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (18): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (19): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (20): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (21): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (22): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","        (23): MobileBertLayer(\n","          (attention): MobileBertAttention(\n","            (self): MobileBertSelfAttention(\n","              (query): Linear(in_features=128, out_features=128, bias=True)\n","              (key): Linear(in_features=128, out_features=128, bias=True)\n","              (value): Linear(in_features=512, out_features=128, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): MobileBertSelfOutput(\n","              (dense): Linear(in_features=128, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (intermediate): MobileBertIntermediate(\n","            (dense): Linear(in_features=128, out_features=512, bias=True)\n","          )\n","          (output): MobileBertOutput(\n","            (dense): Linear(in_features=512, out_features=128, bias=True)\n","            (LayerNorm): NoNorm()\n","            (bottleneck): OutputBottleneck(\n","              (dense): Linear(in_features=128, out_features=512, bias=True)\n","              (LayerNorm): NoNorm()\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (bottleneck): Bottleneck(\n","            (input): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","            (attention): BottleneckLayer(\n","              (dense): Linear(in_features=512, out_features=128, bias=True)\n","              (LayerNorm): NoNorm()\n","            )\n","          )\n","          (ffn): ModuleList(\n","            (0): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (1): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","            (2): FFNLayer(\n","              (intermediate): MobileBertIntermediate(\n","                (dense): Linear(in_features=128, out_features=512, bias=True)\n","              )\n","              (output): FFNOutput(\n","                (dense): Linear(in_features=512, out_features=128, bias=True)\n","                (LayerNorm): NoNorm()\n","              )\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6GHlNV-aPMz","executionInfo":{"status":"ok","timestamp":1616367433386,"user_tz":240,"elapsed":18237,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"15c40f8b-e9b8-404b-95c2-f8b28dc39ae7"},"source":["def read_hotpot(hotpot_dataset):\n","\n","    contexts = []\n","    questions = []\n","    answers = []\n","    all_contexts = hotpot_dataset['context'][:]\n","    all_questions = hotpot_dataset['question'][:]\n","    all_answers = hotpot_dataset['answer'][:]\n","    invalid_quests = 0\n","    for i in range(len(all_contexts)):\n","\n","        answer = {}\n","        context = \"\".join(all_contexts[i]['sentences'])\n","        answer['text'] = all_answers[i]\n","        answer_start = context.find(answer['text'])\n","        if answer_start == -1:\n","            invalid_quests += 1\n","        else:\n","            answer['answer_start'] = answer_start\n","            answers.append(answer)\n","            contexts.append(context)\n","            questions.append(all_questions[i])\n","    print(f'invalid percentage {invalid_quests/len(hotpot_dataset)*100:.2f}')\n","    return contexts, questions, answers\n","\n","train_contexts, train_questions, train_answers = read_hotpot(train_dataset[:70000])\n","trainval_contexts, trainval_questions, trainval_answers = read_hotpot(train_dataset[70000:])\n","val_contexts, val_questions, val_answers = read_hotpot(validation_dataset[:])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["invalid percentage 0.00\n","invalid percentage 0.00\n","invalid percentage 0.00\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AK9JLhs-97wO"},"source":["## Prep data and train"]},{"cell_type":"code","metadata":{"id":"IbeopWmXaPtF"},"source":["def add_end_idx(answers, contexts):\n","    for answer, context in zip(answers, contexts):\n","        gold_text = answer['text']\n","        start_idx = answer['answer_start']\n","        end_idx = start_idx + len(gold_text)\n","\n","        # sometimes squad answers are off by a character or two – fix this\n","        if context[start_idx:end_idx] == gold_text:\n","            answer['answer_end'] = end_idx\n","        elif context[start_idx-1:end_idx-1] == gold_text:\n","            answer['answer_start'] = start_idx - 1\n","            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n","        elif context[start_idx-2:end_idx-2] == gold_text:\n","            answer['answer_start'] = start_idx - 2\n","            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n","    \n","add_end_idx(train_answers, train_contexts)\n","add_end_idx(trainval_answers, trainval_contexts)\n","add_end_idx(val_answers, val_contexts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCVqDifMlBGz","executionInfo":{"status":"ok","timestamp":1616367496437,"user_tz":240,"elapsed":53476,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"0c6afc5f-329d-4c49-f1a9-80317661ce9c"},"source":["train_encodings = tokenizer(train_questions, train_contexts,  truncation=True, padding=True, return_tensors=\"pt\")\n","trainval_encodings = tokenizer(trainval_questions, trainval_contexts,  truncation=True, padding=True, return_tensors=\"pt\")\n","val_encodings = tokenizer(val_questions, val_contexts, truncation=True, padding=True)\n","val_ans_encodings = tokenizer([val_answers[i]['text'] for i in range(len(val_answers))])\n","train_ans_encodings = tokenizer([train_answers[i]['text'] for i in range(len(train_answers))])\n","trainval_ans_encodings = tokenizer([trainval_answers[i]['text'] for i in range(len(trainval_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"l5vvNvxxaX5w"},"source":["def add_token_positions(encodings, answers):\n","    def find_answer_in_context(context,answer):\n","        for j in range(len(context)):\n","            if context[j:j+len(answer)] == answer:\n","                return j\n","        return None     \n","    start_positions = []\n","    end_positions = []\n","    for i in range(len(answers[:])):\n","        ans = answers[i].tokens[1:-2]\n","        cntxt = encodings[i].tokens\n","        start_pos =  find_answer_in_context(cntxt, ans)\n","        start_positions.append(start_pos)\n","\n","        # if start position is None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = 0\n","            end_positions.append(0)\n","        else:\n","            end_positions.append(start_pos + len(ans))\n","\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","add_token_positions(train_encodings, train_ans_encodings)\n","add_token_positions(val_encodings, val_ans_encodings)\n","add_token_positions(trainval_encodings, trainval_ans_encodings)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuovIFwiaaEp"},"source":["import torch\n","\n","class HotpotDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","BATCH_SIZE = 8\n","train_dataset = HotpotDataset(train_encodings)\n","trainval_dataset = HotpotDataset(trainval_encodings)\n","val_dataset = HotpotDataset(val_encodings)\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","trainval_loader = DataLoader(trainval_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9BpqHA4YWyIR"},"source":[""]},{"cell_type":"code","metadata":{"id":"40Mqih9Z8rTx"},"source":["\n","def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","    return max(scores_for_ground_truths)\n","\n","\n","\n","def evaluate_truth_pred(truths, preds):\n","    '''\n","    truths, preds: matched arrays of ground truth answers and predictions\n","    '''\n","    f1 = exact_match = total = 0\n","    for i in range(len(truths)):\n","        total += 1\n","        ground_truths = [truths[i]]\n","        prediction = preds[i]\n","        exact_match += metric_max_over_ground_truths(\n","            exact_match_score, prediction, ground_truths)\n","        f1 += metric_max_over_ground_truths(\n","            f1_score, prediction, ground_truths)\n","\n","    exact_match = 100.0 * exact_match / (total+ 0.00000000001)\n","    f1 = 100.0 * f1 / (total+ 0.00000000001)\n","\n","    return {'exact_match': exact_match, 'f1': f1}\n","\n","\n","def get_answer( model, tokenizer, context, question):\n","    # 1. TOKENIZE THE INPUT\n","    # note: if you don't include return_tensors='pt' you'll get a list of lists which is easier for\n","    # exploration but you cannot feed that into a model.\n","    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n","    inputs = inputs.to(device)\n","    # 2. OBTAIN MODEL SCORES\n","    # the AutoModelForQuestionAnswering class includes a span predictor on top of the model.\n","    # the model returns answer start and end scores for each word in the text\n","    answer_start_scores, answer_end_scores = model(**inputs, return_dict=False)\n","    answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n","    answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n","    # 3. GET THE ANSWER SPAN\n","    # once we have the most likely start and end tokens, we grab all the tokens between them\n","    # and convert tokens back to words!\n","    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n","    return answer\n","# https://huggingface.co/transformers/migration.html\n","def model_evaluation(model, tokenizer, questions, contexts, answers, to_print = False):\n","    preds = []\n","    my_list = list(range(len(questions)))\n","    #with tqdm(total=len(my_list)) as pbar:\n","    for ex in range(len(questions)):\n","        answer = get_answer(model, tokenizer, contexts[ex],questions[ex])\n","        preds.append(answer)\n","        if ex % 100 == 0 and to_print:\n","            print(\"context \" +contexts[ex] )\n","            print(\"quest \" +questions[ex] )\n","            print(\"truth \" +answers[ex]['text'] )\n","            print(\"pred \" + answer)\n","            #pbar.update(1)\n","    truths = [answers[i]['text'] for i in range(len(answers))]\n","    scores = evaluate_truth_pred(truths, preds)\n","    print(scores)\n","    return scores\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZ00CC6rafJp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616381506857,"user_tz":240,"elapsed":10449471,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"11cde8f7-e9ca-402c-8e02-c67c65870dfb"},"source":["from transformers import get_linear_schedule_with_warmup\n","n_epochs = 30\n","model.train()\n","optimizer = AdamW(model.parameters(), lr=3e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, 1000, len(val_questions)*n_epochs/BATCH_SIZE)\n","\n","from tqdm import tqdm\n","my_list = list(range(len(train_questions)*n_epochs))\n","with tqdm(total=len(my_list)) as pbar:\n","    for epoch in range(n_epochs):\n","        print(\"####################\")\n","        print(\"New epoch\")\n","        print(\"####################\")\n","        model.train()\n","        for batch in val_loader:\n","            optimizer.zero_grad()\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            start_positions = batch['start_positions'].to(device)\n","            end_positions = batch['end_positions'].to(device)\n","            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n","            answer_start_scores = outputs['start_logits'][0]\n","            answer_end_scores = outputs['end_logits'][0]\n","            answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n","            answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n","            loss = outputs[0]\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            pbar.update(BATCH_SIZE)\n","        if epoch % 4 == 0:\n","            model.eval()\n","            model_evaluation(model, tokenizer, val_questions, val_contexts, val_answers)\n","\n","model.eval()\n","model_evaluation(model, tokenizer, val_questions, val_contexts, val_answers)\n","#model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/2100000 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 6936/2100000 [04:50<22:02:59, 26.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 47.570295602018675, 'f1': 59.0529262066622}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 13872/2100000 [13:17<22:05:07, 26.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 20808/2100000 [17:50<21:51:36, 26.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|▏         | 27744/2100000 [22:22<22:05:26, 26.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 34680/2100000 [27:10<21:46:36, 26.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 59.63950973323712, 'f1': 68.796600246801}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 41616/2100000 [35:32<21:42:06, 26.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  2%|▏         | 48552/2100000 [40:06<21:35:34, 26.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 55488/2100000 [44:39<21:38:07, 26.25it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 62424/2100000 [49:30<21:33:08, 26.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 64.90266762797395, 'f1': 71.6002835525855}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 69360/2100000 [57:54<21:23:42, 26.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▎         | 76296/2100000 [1:02:28<21:22:15, 26.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▍         | 83232/2100000 [1:07:02<21:20:52, 26.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▍         | 90168/2100000 [1:11:50<21:14:10, 26.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 65.68132660418159, 'f1': 71.91632919677143}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▍         | 97104/2100000 [1:20:22<21:07:30, 26.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▍         | 104040/2100000 [1:24:57<21:06:50, 26.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  5%|▌         | 110976/2100000 [1:29:32<21:06:04, 26.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 117912/2100000 [1:34:20<21:03:44, 26.14it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 66.83489545782254, 'f1': 72.73890622058144}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 124848/2100000 [1:42:50<20:46:19, 26.41it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▋         | 131784/2100000 [1:47:24<20:50:50, 26.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 138720/2100000 [1:51:58<20:43:50, 26.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 145656/2100000 [1:56:50<20:34:49, 26.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 68.34895457822628, 'f1': 73.8511567288189}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 152592/2100000 [2:05:12<20:31:26, 26.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 159528/2100000 [2:09:45<20:29:31, 26.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 166464/2100000 [2:14:19<20:21:16, 26.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  8%|▊         | 173400/2100000 [2:19:10<20:21:31, 26.29it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 68.32011535688527, 'f1': 73.67437168543023}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▊         | 180336/2100000 [2:27:32<20:11:17, 26.41it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▉         | 187272/2100000 [2:32:06<20:08:21, 26.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▉         | 194208/2100000 [2:36:39<20:09:05, 26.27it/s]"],"name":"stderr"},{"output_type":"stream","text":["####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|▉         | 201144/2100000 [2:41:30<20:00:12, 26.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 68.7238644556596, 'f1': 74.00583397366152}\n","####################\n","New epoch\n","####################\n"],"name":"stdout"},{"output_type":"stream","text":[" 10%|▉         | 208080/2100000 [2:50:00<25:45:41, 20.40it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 68.7238644556596, 'f1': 73.99819130923794}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'exact_match': 68.7238644556596, 'f1': 73.99819130923794}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"aHZUGq_f-IBp"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"n_BHsDveUAHo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614706362914,"user_tz":300,"elapsed":313619,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"59f9a93b-6de0-4f65-bfb1-d57642dcf695"},"source":["model.eval()\n","model_evaluation(model, tokenizer, val_questions, val_contexts, val_answers)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 6935/6935 [05:12<00:00, 22.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 42.33597692862293, 'f1': 56.085130500668406}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'exact_match': 42.33597692862293, 'f1': 56.085130500668406}"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fYfWmK_AA5k","executionInfo":{"status":"ok","timestamp":1614805724220,"user_tz":300,"elapsed":87930,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"11f17172-1c00-4082-8ad4-a27b2b9f6a53"},"source":["model.eval()\n","model_evaluation(model, tokenizer, train_questions[:1000], train_contexts[:1000], train_answers[:1000])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 1000/1000 [01:27<00:00, 11.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'exact_match': 56.2, 'f1': 65.28558802220684}\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'exact_match': 56.2, 'f1': 65.28558802220684}"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"Qswn9gYe_9-M"},"source":["before any training: {'exact_match': 42.33597692862293, 'f1': 56.085130500668406}\n"]},{"cell_type":"markdown","metadata":{"id":"XyWLfhR6Az3C"},"source":["# Teaching setup"]},{"cell_type":"markdown","metadata":{"id":"edq-HElcAmIE"},"source":["## Kernel"]},{"cell_type":"code","metadata":{"id":"Rw2ANn_XIqAO"},"source":["tokenizer_sent = AutoTokenizer.from_pretrained(\"sentence-transformers/stsb-distilbert-base\")\n","\n","model_sent = AutoModel.from_pretrained(\"sentence-transformers/stsb-distilbert-base\").to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D10AnbtIBvLG"},"source":["def mean_pooling(model_output, attention_mask):\n","    #Mean Pooling - Take attention mask into account for correct averaging\n","\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","    return sum_embeddings / sum_mask\n","\n","def get_sentence_embedding(model, tokenizer, input):\n","\n","    #Tokenize sentences\n","    encoded_input = tokenizer(input, return_tensors='pt').to(device)\n","\n","    #Compute token embeddings\n","    with torch.no_grad():\n","        model_output = model(**encoded_input, return_dict=True, output_hidden_states  = True)\n","\n","    #Perform pooling. In this case, mean pooling\n","    sentence_embeddings = mean_pooling(model_output['hidden_states'], encoded_input['attention_mask'])\n","    return sentence_embeddings[0]\n","    \n","def get_example_embedding(model, tokenizer, question, context):\n","    #Tokenize sentences\n","    encoded_input = tokenizer(question, context, return_tensors='pt').to(device)\n","\n","    #Compute token embeddings\n","    with torch.no_grad():\n","        model_output = model(**encoded_input, return_dict=True, output_hidden_states  = True)\n","\n","    #Perform pooling. In this case, mean pooling\n","    sentence_embeddings = mean_pooling(model_output['hidden_states'], encoded_input['attention_mask'])\n","    return sentence_embeddings[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjLzhebZqo8w"},"source":["from sklearn.metrics.pairwise import rbf_kernel\n","def kernel_similarity(x, y, model = None, tokenizer = None, already_embedded = True):\n","    if already_embedded:\n","        kernel_dist = rbf_kernel(x.reshape(1, -1),y.reshape(1, -1))\n","        return kernel_dist[0][0]\n","    else:\n","        '''\n","        x,y: tuple of question and context\n","        '''\n","        xq = get_sentence_embedding(model, tokenizer, x[0]).cpu().numpy()\n","        xc = get_sentence_embedding(model, tokenizer, x[1]).cpu().numpy()\n","        yq = get_sentence_embedding(model, tokenizer, y[0]).cpu().numpy()\n","        yc = get_sentence_embedding(model, tokenizer, y[1]).cpu().numpy()\n","        kernel_dist = rbf_kernel(xq.reshape(1, -1),yq.reshape(1, -1)) + rbf_kernel(xc.reshape(1, -1),yc.reshape(1, -1))\n","        kernel_dist /= 2\n","        return kernel_dist[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zOoI4-35A0Ee"},"source":["question = \" Are both Upper Crust Pizzeria and Eatza Pizza restaurants?\"\n","context = \"Upper Crust Pizzeria is a Boston, Massachusetts based chain of pizzeria restaurants. Eatza Pizza was a buffet-style restaurant chain founded in Arizona in 1997.\"\n","question2 = \"Are Alek Keshishian and Kirk Kerkorian both Armenian-American?\"\n","context2 = \"Alek Keshishian (Armenian: Ալեք Գևորգի Քեշիշյան , born 30 July 1964 in Beirut, Lebanon) is an Armenian-American film and commercial director, writer, producer and music video director. Kerkor Kirk Kerkorian (June 6, 1917 – June 15, 2015) was an Armenian-American businessman, investor, and philanthropist.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEi-Z__bCf_0"},"source":["question = \" Are both Upper Crust Pizzeria and Eatza Pizza restaurants?\"\n","context = \"Upper Crust Pizzeria is a Boston, Massachusetts based chain of pizzeria restaurants. Eatza Pizza was a buffet-style restaurant chain founded in Arizona in 1997.\"\n","question2 = \"Where did the character Xavin changed into a black female just for the sake first appeared\"\n","context2 =\"Xavin had first appeared to the Runaways, taking on the form of a black male, but changed into a black female just for the sake of Karolina Dean, a lesbian whom they were to marry. Karolina Dean ( ), also briefly known as Lucy in the Sky, or L.S.D., is a fictional character, a superheroine appearing in American comic books published by Marvel Comics. The character first appeared in the series Runaways.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-8CP5Yz2Lv4"},"source":["embed1 = get_example_embedding(model, tokenizer, question, context)\n","embed2 = get_example_embedding(model, tokenizer, question2, context2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TI0_oI52VyW","executionInfo":{"status":"ok","timestamp":1614878396428,"user_tz":300,"elapsed":256450,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"e3085878-a78c-4c5d-a8b4-b10175487b9f"},"source":["kernel_similarity(embed1.cpu().numpy(),embed2.cpu().numpy())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9706599"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmzRXo2KMam2","executionInfo":{"status":"ok","timestamp":1614878396430,"user_tz":300,"elapsed":256445,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"c3eb9cc6-3438-4419-ac36-5ec33ed1ab52"},"source":["kernel_similarity((question,context), (question2,context2), model_sent, tokenizer_sent, False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.95894337"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"rFqizkYIVHz4"},"source":["## Set cover\n","\n","K-mediods and k-center"]},{"cell_type":"code","metadata":{"id":"bLZC1GpMVYiX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614878398908,"user_tz":300,"elapsed":254190,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"f3e5c28f-83ba-4596-c665-16058dfb3b4b"},"source":["!pip install scikit-learn-extra"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-learn-extra in /usr/local/lib/python3.7/dist-packages (0.1.0b2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->scikit-learn-extra) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q86VJXv0VLQZ","executionInfo":{"status":"ok","timestamp":1614878653035,"user_tz":300,"elapsed":508308,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"0e7c7d93-f705-4ca9-c385-8ff6768e024e"},"source":["# get embeddings for validation set \n","my_list = list(range(len(val_questions[:])))\n","val_embeddings = []\n","\n","with tqdm(total=len(my_list)) as pbar:\n","    for i in range(len(val_questions[:])):\n","        embed = get_example_embedding(model, tokenizer, val_questions[i], val_contexts[i]).cpu().numpy()\n","        val_embeddings.append(embed)\n","        pbar.update(1)\n","\n","val_embeddings = np.asarray(val_embeddings)\n","from sklearn_extra.cluster import KMedoids\n","kmedoids = KMedoids(n_clusters=100, init='k-medoids++', max_iter=10000).fit(val_embeddings)\n","print(kmedoids.inertia_)\n","example_indices = kmedoids.medoid_indices_\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 6935/6935 [04:12<00:00, 27.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["11324.806\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eLnq0tdrVWCI","executionInfo":{"status":"ok","timestamp":1614878654511,"user_tz":300,"elapsed":509777,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"ec389ff7-7931-4c30-c814-3dc0bdc92125"},"source":["from sklearn_extra.cluster import KMedoids\n","kmedoids = KMedoids(n_clusters=100, init='k-medoids++', max_iter=10000).fit(val_embeddings)\n","print(kmedoids.inertia_)\n","example_indices = kmedoids.medoid_indices_\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["11382.537\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PuxiBHbj_zde"},"source":["## Human model Complex\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vn_XDNKEBnA5","executionInfo":{"status":"ok","timestamp":1614878656504,"user_tz":300,"elapsed":510174,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"328e63d9-c055-4fbf-f0f2-680ffe8e9a2c"},"source":["# downloads\n","spacy.load('en')\n","parser = English()\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","en_stop = set(nltk.corpus.stopwords.words('english'))\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"14hVslHL_0ng"},"source":["# see https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n","#import pyLDAvis.gensim and https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n","def tokenize(text):\n","    lda_tokens = []\n","    tokens = parser(text)\n","    for token in tokens:\n","        if token.orth_.isspace():\n","            continue\n","        elif token.like_url:\n","            lda_tokens.append('URL')\n","        elif token.orth_.startswith('@'):\n","            lda_tokens.append('SCREEN_NAME')\n","        else:\n","            lda_tokens.append(token.lower_)\n","    return lda_tokens\n","\n","def get_lemma(word):\n","    lemma = wn.morphy(word)\n","    if lemma is None:\n","        return word\n","    else:\n","        return lemma\n","def get_lemma2(word):\n","    return WordNetLemmatizer().lemmatize(word)\n","\n","def detect_question(token):\n","    # assume token is string\n","    tag = nltk.pos_tag([token])\n","    if tag[0][1] in [\"WP\", \"WRB\", \"WP$\"]:\n","        return True\n","    else:\n","        return False\n","def prepare_text_for_lda(text):\n","    tokens = tokenize(text)\n","    tokens = [token for token in tokens if len(token) > 3]\n","    tokens = [token for token in tokens if (token not in en_stop) or  (detect_question(token))]\n","    tokens = [get_lemma(token) for token in tokens]\n","    return tokens\n","\n","def learn_lda_model():\n","    file_name = \"../squad/train-v2.0.json\"\n","    paragraphs = []\n","    with open(file_name) as f:\n","        dataset = json.load(f)['data']\n","    for article in dataset:\n","        for paragraph in article['paragraphs']:\n","            paragraphs.append(paragraph['context'])\n","\n","    # prep data\n","    paragraphs_lda = []\n","    for i in range(len(paragraphs)):\n","        paragraphs_lda.append(prepare_text_for_lda(paragraphs[i]))\n","\n","    dictionary = corpora.Dictionary(paragraphs_lda)\n","    corpus = [dictionary.doc2bow(text) for text in paragraphs_lda]\n","    pickle.dump(corpus, open('corpus.pkl', 'wb'))\n","    dictionary.save('dictionary.gensim')\n","    NUM_TOPICS = 10\n","    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n","    ldamodel.save('lda_model_10_squad.gensim')\n","    topics = ldamodel.print_topics(num_words=10)\n","    for topic in topics:\n","        print(topic)\n","\n","class LDA_model:\n","    def __init__(self):\n","        self.n_topics = 10\n","        self.model =  models.LdaModel.load('lda_model_10_squad.gensim')\n","        self.dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n","        self.corpus = pickle.load(open('corpus.pkl', 'rb'))\n","    def predict(self, paragraph):\n","        paragraph = prepare_text_for_lda(paragraph)\n","        new_doc_bow = self.dictionary.doc2bow(paragraph)\n","        result = self.model.get_document_topics(new_doc_bow)\n","        vector = [0] * self.n_topics\n","        for top in result:\n","            vector[top[0]] = top[1]\n","        return vector\n","    def show_topics(self):\n","        topics = self.model.print_topics(num_words=10)\n","        for topic in topics:\n","            print(topic)\n","#learn_lda_model()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6YB6u8H_55N"},"source":["\n","#import pyLDAvis.gensim\n","\n","def tokenize(text):\n","    lda_tokens = []\n","    tokens = parser(text)\n","    for token in tokens:\n","        if token.orth_.isspace():\n","            continue\n","        elif token.like_url:\n","            lda_tokens.append('URL')\n","        elif token.orth_.startswith('@'):\n","            lda_tokens.append('SCREEN_NAME')\n","        else:\n","            lda_tokens.append(token.lower_)\n","    return lda_tokens\n","\n","def get_lemma(word):\n","    lemma = wn.morphy(word)\n","    if lemma is None:\n","        return word\n","    else:\n","        return lemma\n","def get_lemma2(word):\n","    return WordNetLemmatizer().lemmatize(word)\n","\n","def detect_question(token):\n","    # assume token is string\n","    tag = nltk.pos_tag([token])\n","    if tag[0][1] in [\"WP\", \"WRB\", \"WP$\"]:\n","        return True\n","    else:\n","        return False\n","\n","\n","\n","def question_classification(question):\n","    question_words = [\"what\", \"when\", \"where\", \"which\", \"who\", \"whom\", \"whose\", \"why\", \"how\"]\n","    question_vec = [0] * len(question_words)\n","    tokens = tokenize(question)\n","    tokens = [get_lemma(token) for token in tokens]\n","    all_zero = True\n","    for token in tokens:\n","        for i in range(len(question_words)):\n","            if token == question_words[i]:\n","                question_vec[i] == 1\n","                all_zero = False\n","    if all_zero:\n","        print(f' question: {question}')\n","    return question_vec, all_zero\n","\n","def question_test():\n","    file_name = \"../squad/dev-v2.0.json\"\n","    paragraphs = []\n","    total = 0\n","    zeros = 0\n","    with open(file_name) as f:\n","        dataset = json.load(f)['data']\n","    for article in dataset:\n","        print(article[\"title\"])\n","        for paragraph in article['paragraphs']:\n","            paragraphs.append(paragraph['context'])\n","            for qa in paragraph['qas']:\n","                total +=1\n","                a, b = question_classification(qa['question'])\n","                zeros += int(b)\n","    print(zeros/total*1.0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WfnCUMgaIqnM"},"source":["## Human model Naiive"]},{"cell_type":"code","metadata":{"id":"W58vz-PuIqBY"},"source":["class HumanPredictor_simple:\n","    def __init__(self, accuracy):\n","        '''\n","        accuracy and ai_accuracy: floats in [0,1]\n","        '''\n","        self.accuracy = accuracy\n","    def predict(self, contexts, questions, answers):\n","        '''\n","        expects array of strings for inputs\n","        returns list of string answer\n","        '''\n","        preds = []\n","        for i in range(len(questions)):\n","            coin = random.random() # random number between [0,1]\n","            if coin <= self.accuracy:\n","                preds.append(answers[i]['text'])\n","            else:\n","                # generate random answer\n","                sents = nltk.sent_tokenize(contexts[i])\n","                rand_sent = random.randint(0,len(sents)-1)\n","                preds.append(sents[rand_sent])\n","        return preds\n","    def prior_rejector(self, contexts, questions, answers):\n","        '''\n","        this rejector is agnostic to input, random deferall 1-self.accuracy times\n","        '''\n","        preds = []\n","        for i in range(len(questions)):\n","            coin = random.random() # random number between [0,1]\n","            if coin >= self.accuracy:\n","                preds.append(1)\n","            else:\n","                preds.append(0)\n","        return preds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8U7LbFTFVFhr"},"source":["## Our Approach"]},{"cell_type":"code","metadata":{"id":"ASIRoqmiApwE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614896769323,"user_tz":300,"elapsed":288,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"c8951e1a-133f-4269-963e-2144d0102748"},"source":["class HumanLearner:\n","    def __init__(self, kernel):\n","        '''\n","        kernel: function that takes two inputs and returns a similarity\n","        prior rejector: returns rejector\n","        '''\n","        self.teaching_set = []\n","        self.kernel = kernel\n","    def predict(self, xs, prior_rejector_preds, to_print = False):\n","        '''\n","        xs: expected array of inputs\n","        '''\n","        preds = []\n","        idx = 0\n","        used_posterior = 0 \n","        if to_print:\n","            print(\"-- Human making reject predictions --\")\n","            with tqdm(total=len(xs)) as pbar:\n","                for x in xs:\n","                    ball_at_x = []\n","                    similarities = rbf_kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n","                    for i in range(len(self.teaching_set)):\n","                        similarity = similarities[i]\n","                        if similarity >=  self.teaching_set[i][2]:\n","                            ball_at_x.append(self.teaching_set[i])\n","                    if len(ball_at_x) == 0: \n","                        # use prior rejector\n","                        preds.append(prior_rejector_preds[idx])\n","                    else:\n","                        used_posterior += 1\n","                        ball_similarities = rbf_kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n","                        normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n","                        score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n","                        pred = score_one / normalization\n","                        if pred >= 0.5:\n","                            preds.append(1)\n","                        else:\n","                            preds.append(0)\n","                    idx += 1\n","                    pbar.update(1)\n","        else:\n","            for x in xs:\n","                ball_at_x = []\n","                similarities = rbf_kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n","                for i in range(len(self.teaching_set)):\n","                    similarity = similarities[i]\n","                    if similarity >=  self.teaching_set[i][2]:\n","                        ball_at_x.append(self.teaching_set[i])\n","                if len(ball_at_x) == 0: \n","                    # use prior rejector\n","                    preds.append(prior_rejector_preds[idx])\n","                else:\n","                    used_posterior += 1\n","                    ball_similarities = rbf_kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n","                    normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n","                    score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n","                    pred = score_one / normalization\n","                    if pred >= 0.5:\n","                        preds.append(1)\n","                    else:\n","                        preds.append(0)\n","                idx += 1\n","        if to_print:\n","            print(f'Used posterior {used_posterior/len(xs)*100:.2f}')\n","        return preds\n","\n","    def add_to_teaching(self, teaching_example):\n","        '''\n","        teaching_example: (x, label, gamma)\n","        '''\n","        self.teaching_set.append(teaching_example)\n","\n","    def remove_last_teaching_item(self):\n","        self.teaching_set = self.teaching_set[:-1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Exception ignored in: <function tqdm.__del__ at 0x7fd391e02710>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1062, in __del__\n","    self.close()\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1237, in close\n","    if self.disable:\n","AttributeError: 'tqdm' object has no attribute 'disable'\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Fqa5tAIgML2l"},"source":["def compute_predictions_humanai(hum_preds, hum_rejector, ai_preds, data_x):\n","    '''\n","    hum_preds: array of human predictions\n","    ai_preds: array of AI predictions\n","    hum_rejector: HumanLearner\n","    data_x: array of inputs\n","\n","    Returns array of final predictions and deferalls\n","    '''\n","    predictions = []\n","    with torch.no_grad():\n","        reject_decisions = hum_rejector(data_x)\n","        for i in range(len(data_x)):\n","            if reject_decisions[i] == 1:\n","                # defer\n","                predictions.append(ai_preds[i])\n","            else:\n","                predictions.append(hum_preds[i])\n","    return predictions, reject_decisions\n","\n","def get_metrics(preds, truths):\n","    # custom for each use case\n","    return evaluate_truth_pred(truths, preds)\n","\n","def compute_metrics(human_preds, ai_preds, reject_decisions, truths, to_print = False):\n","    coverage = 1 - np.sum(reject_decisions)/len(reject_decisions)\n","    humanai_preds = []\n","    human_preds_sys = []\n","    truths_human = []\n","    ai_preds_sys = []\n","    truths_ai = []\n","    for i in range(len(reject_decisions)):\n","        if reject_decisions[i] == 1:\n","            humanai_preds.append(ai_preds[i])\n","            ai_preds_sys.append(ai_preds[i])\n","            truths_ai.append(truths[i])\n","        else:\n","            humanai_preds.append(human_preds[i])\n","            human_preds_sys.append(human_preds[i])\n","            truths_human.append(truths[i])\n","    humanai_metrics = get_metrics(humanai_preds, truths)\n","    human_metrics = get_metrics(human_preds_sys, truths_human)\n","    ai_metrics = get_metrics(ai_preds_sys, truths_ai)\n","    if to_print:\n","        print(f'Coverage is {coverage*100:.2f}')\n","        print(f' metrics of system are: {humanai_metrics}')\n","        print(f' metrics of human are: {human_metrics}')\n","        print(f' metrics of AI are: {ai_metrics}')\n","    return coverage, humanai_metrics, human_metrics, ai_metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzX4BNVrwsjv"},"source":["# Preliminary steps:\n","# Step 1.1: get predictions of human and predictions of AI on teaching set\n","# Step 1.2: get prior rejector decisions of Human on teaching set\n","# Step 2: Compute optimal deferal decision for each point in teaching set  \n","# Step 3: Compute optimal gamma for each point, can start with a constant guess\n","\n","# Algorithms:\n","# Initialize HumanLearner\n","# Baseline 1:\n","# step 1: get k-mediods points\n","# step 2: add to HumanLearner\n","# step 3: evaluate on validation set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lhl6qE9p7yrz"},"source":["# Define teaching and validation\n","split_teach_val = 0.5\n","teaching_contexts = trainval_contexts[:math.floor(len(trainval_contexts)*split_teach_val)]\n","teaching_questions = trainval_questions[:math.floor(len(trainval_contexts)*split_teach_val)]\n","teaching_answers = trainval_answers[:math.floor(len(trainval_contexts)*split_teach_val)]\n","validation_contexts = trainval_contexts[math.floor(len(trainval_contexts)*split_teach_val):]\n","validation_questions = trainval_questions[math.floor(len(trainval_contexts)*split_teach_val):]\n","validation_answers = trainval_answers[math.floor(len(trainval_contexts)*split_teach_val):]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kvke1RG19y8n","executionInfo":{"status":"ok","timestamp":1614879357238,"user_tz":300,"elapsed":700549,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"18c314b7-ae62-48b4-dae0-57b95ee20ce8"},"source":["# Get AI predictions\n","ai_teaching_preds = []\n","ai_validation_preds = []\n","print(\"--Getting AI predictions on teach and validation sets \\n--\")\n","with tqdm(total=len(teaching_contexts)) as pbar:\n","    for ex in range(len(teaching_contexts)):\n","        answer = get_answer(model, tokenizer, teaching_contexts[ex], teaching_questions[ex])\n","        ai_teaching_preds.append(answer)\n","        pbar.update(1)\n","with tqdm(total=len(validation_contexts)) as pbar:\n","    for ex in range(len(validation_contexts)):\n","        answer = get_answer(model, tokenizer, validation_contexts[ex], validation_questions[ex])\n","        ai_validation_preds.append(answer)\n","        pbar.update(1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 2/7377 [00:00<08:09, 15.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["--Getting AI predictions on teach and validation sets \n","--\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7377/7377 [05:48<00:00, 21.17it/s]\n","100%|██████████| 7377/7377 [05:51<00:00, 20.97it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wObOYxRa_yYy","executionInfo":{"status":"ok","timestamp":1614879357849,"user_tz":300,"elapsed":701151,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"6c5a584b-30d7-4e7e-cd8f-ca9a50e0081c"},"source":["# Get Human Predictions\n","\n","\n","\n","# Get AI predictions\n","ai_teaching_preds = []\n","ai_validation_preds = []\n","ai_val_preds = []\n","ai_train_preds = []\n","\n","with open('C:/Users/Hussein/Documents/Research/Human learn to defer/hotpotqa/outputs_val_1dis/predictions_ans.json', 'r') as handle:\n","    preds_val = json.load(handle)\n","    \n","#with open('preds_train_data.p', 'rb') as handle:\n","#    preds_train = pickle.load(handle)\n","\n","for key, value in preds_val.items():\n","    ai_val_preds.append(value)\n","\n","#for key, value in preds_train.items():\n","#    ai_train_preds.append(value)\n","\n","ai_teaching_preds = ai_val_preds[:START_TEST]\n","ai_validation_preds = ai_val_preds[START_TEST:]\n","\n","\n","\n","\n","\n","human_predictor = HumanPredictor_simple(0.8)\n","hum_teaching_preds = []\n","hum_validation_preds = []\n","priorhum_teaching_preds = []\n","priorhum_validation_preds = []\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--Getting Human predictions on teach and validation sets --\n","\n","--Getting prior rejector predictions on teach and validation sets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AkOgLiQFCfnr"},"source":["# Optimal deferall decisions\n","opt_defer_teaching = []\n","opt_defer_validation = []\n","for ex in range(len(teaching_contexts)):\n","    f1_hum = metric_max_over_ground_truths(f1_score, teaching_answers[ex]['text'], [hum_teaching_preds[ex]])\n","    f1_ai = metric_max_over_ground_truths(f1_score, teaching_answers[ex]['text'], [ai_teaching_preds[ex]])\n","\n","    if f1_ai > f1_hum:\n","        opt_defer_teaching.append(1)\n","    else:\n","        opt_defer_teaching.append(0)\n","\n","for ex in range(len(validation_contexts)):\n","    f1_hum = metric_max_over_ground_truths(f1_score, validation_answers[ex]['text'], [hum_validation_preds[ex]])\n","    f1_ai = metric_max_over_ground_truths(f1_score, validation_answers[ex]['text'], [ai_validation_preds[ex]])\n","    if f1_ai > f1_hum:\n","        opt_defer_validation.append(1)\n","    else:\n","        opt_defer_validation.append(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3n94HMAQohg","executionInfo":{"status":"ok","timestamp":1614879359040,"user_tz":300,"elapsed":702326,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"21b28404-33d1-4a90-cc47-5a3880275dbe"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, priorhum_validation_preds, [validation_answers[i]['text'] for i in range(len(validation_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 79.83\n"," metrics of system are: {'exact_match': 75.58628168632225, 'f1': 78.23708365565689}\n"," metrics of human are: {'exact_match': 80.38716250636767, 'f1': 81.33845872431229}\n"," metrics of AI are: {'exact_match': 56.58602150537596, 'f1': 65.96289159966645}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.7982919886132575,\n"," {'exact_match': 75.58628168632225, 'f1': 78.23708365565689},\n"," {'exact_match': 80.38716250636767, 'f1': 81.33845872431229},\n"," {'exact_match': 56.58602150537596, 'f1': 65.96289159966645})"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLDRcNORVnhE","executionInfo":{"status":"ok","timestamp":1614879359509,"user_tz":300,"elapsed":702787,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"3c6148bb-cb2b-4235-daa2-6caa4d492936"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, opt_defer_validation, [validation_answers[i]['text'] for i in range(len(validation_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 36.94\n"," metrics of system are: {'exact_match': 91.73105598481756, 'f1': 93.86405510427629}\n"," metrics of human are: {'exact_match': 95.55963302752258, 'f1': 96.14810443891169}\n"," metrics of AI are: {'exact_match': 89.48839208942371, 'f1': 92.52612852713017}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.3693913514978989,\n"," {'exact_match': 91.73105598481756, 'f1': 93.86405510427629},\n"," {'exact_match': 95.55963302752258, 'f1': 96.14810443891169},\n"," {'exact_match': 89.48839208942371, 'f1': 92.52612852713017})"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2toUXpkvGR-C","executionInfo":{"status":"ok","timestamp":1614879915847,"user_tz":300,"elapsed":1259114,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"fcdd0eae-df15-4597-d36d-411df4f97d91"},"source":["# get embeddings for teaching set \n","teaching_embeddings = []\n","with tqdm(total=len(teaching_questions)) as pbar:\n","    for i in range(len(teaching_questions[:])):\n","        embed = get_example_embedding(model, tokenizer, teaching_questions[i], teaching_contexts[i]).cpu().numpy()\n","        teaching_embeddings.append(embed)\n","        pbar.update(1)\n","teaching_embeddings = np.asarray(teaching_embeddings)\n","\n","validation_embeddings = []\n","with tqdm(total=len(validation_questions)) as pbar:\n","    for i in range(len(validation_questions[:])):\n","        embed = get_example_embedding(model, tokenizer, validation_questions[i], validation_contexts[i]).cpu().numpy()\n","        validation_embeddings.append(embed)\n","        pbar.update(1)\n","validation_embeddings = np.asarray(validation_embeddings)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 7377/7377 [04:34<00:00, 26.90it/s]\n","100%|██████████| 7377/7377 [04:42<00:00, 26.16it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcU7RmpWnuVC","executionInfo":{"status":"ok","timestamp":1614894330228,"user_tz":300,"elapsed":209019,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"77409a45-790f-40c8-c0f9-f8dbf8d38d4e"},"source":["# get optimal gammas\n","optimal_gammas = []\n","with tqdm(total=len(teaching_embeddings)) as pbar:\n","    for i in range(len(teaching_embeddings)):\n","        # get all similarities\n","        opt_defer_ex = opt_defer_teaching[i]\n","        similarities_embeds = rbf_kernel(teaching_embeddings[i].reshape(1,-1), np.asarray(teaching_embeddings))[0]\n","        sorted_sim = sorted([(similarities_embeds[k], opt_defer_teaching[k]) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n","        indicess = list(range(1, len(opt_defer_teaching)))\n","        indicess.reverse()\n","        for k in indicess:\n","            if sorted_sim[k][1] == opt_defer_ex and sorted_sim[k- 1][1] != opt_defer_ex:\n","                optimal_gammas.append(sorted_sim[k][0])\n","                break\n","        pbar.update(1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 7377/7377 [03:28<00:00, 35.35it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ju0Uo1ygN57b","executionInfo":{"status":"ok","timestamp":1614899257668,"user_tz":300,"elapsed":1949,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"97568e24-c8ee-440e-fbf2-31ecf6b59807"},"source":["# Baseline get medoids\n","from sklearn_extra.cluster import KMedoids\n","kmedoids = KMedoids(n_clusters=10, init='k-medoids++', max_iter=10000).fit(teaching_embeddings)\n","print(kmedoids.inertia_)\n","teaching_indices = kmedoids.medoid_indices_"],"execution_count":null,"outputs":[{"output_type":"stream","text":["13291.047\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3vb__twflp4","executionInfo":{"status":"ok","timestamp":1614899281349,"user_tz":300,"elapsed":271,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"a5fc2fe7-eeea-41df-eb3f-2f5ca32e1f1e"},"source":["[teaching_contexts[i] for i in teaching_indices]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Stabbing Westward is an American industrial rock band. Christopher Hall and Walter Flakus formed the band in 1986 in Macomb, Illinois, but did not release their first studio album until eight years later. The band released three more studio albums before announcing a dissolution on February 9, 2002. Stabbing Westward reunited in 2016 to celebrate their 30th anniversary together, and will play more shows in 2017.State Radio is a Boston-based rock trio comprising singer and primary songwriter Chad Stokes Urmston (also a member of Dispatch), bassist Chuck Fay, and, formerly, drummer Michael Najarian. The band's songs focus on social and political issues and have been musically described as a combination of reggae, punk and rock.\",\n"," 'Hugh Ferriss (1889 – 1962) was an American delineator (one who creates drawings and sketches of buildings) and architect. After his death a colleague said he \\'influenced my generation of architects\\' more than any other man. Ferriss also influenced popular culture, for example Gotham City (the setting for Batman) and Kerry Conran\\'s \"Sky Captain and the World of Tomorrow\".Sky Captain and the World of Tomorrow is a 2004 American science fiction action-adventure film written and directed by Kerry Conran in his directorial debut, and produced by Jon Avnet, Sadie Frost, Jude Law and Marsha Oglesby. The film stars Law, Gwyneth Paltrow and Angelina Jolie; it is an example of the \"dieselpunk\" genre.',\n"," '\"3\" is a song recorded by American singer Britney Spears for her second greatest hits album, \"The Singles Collection\" (2009). It was written and produced by Max Martin and Shellback, with additional writing from Tiffany Amber. The song was released on October 2, 2009 by Jive Records, as the only single from \"The Singles Collection\". \"3\" is an uptempo electropop song that features a heavy bassline and synthesizers, and lyrics that talk about threesomes, while referencing American folk-singing trio Peter, Paul and Mary during the chorus as sexual slang.Karl Johan Schuster (] ; born 1 February 1985), known professionally as Shellback, is a Swedish songwriter, record producer, and musician. Shellback was listed as the No. 1 producer of 2012 on \"Billboard\" magazine\\'s year end chart, and he also topped the list of their \"Top 10 Songwriters Airplay Chart\" the same year; he has won four Grammy Awards.',\n"," 'Melbourne ( ) is the capital and most populous city of the Australian state of Victoria, and the second-most populous city in Australia and Oceania. The name \"Melbourne\" covers an urban agglomeration spanning 2664 km2 , which comprises the broader metropolitan area, as well as being the common name for its city centre. The metropolis is located on the large natural bay of Port Phillip and expands into the hinterlands towards the Dandenong and Macedon mountain ranges, Mornington Peninsula and Yarra Valley. Melbourne consists of 31 municipalities. It has a population of 4,641,636 as of 2016 , and its inhabitants are called Melburnians.Charles Elliott Perry (1871–1937) was a New Zealand Anglican clergyman. He was born in Melbourne, Victoria, Australia in 1871.',\n"," 'Cody Hodges (born November 20, 1982) is a philanthropist, motivational speaker, and former professional American football player, playing in the National Football League, Arena Football League, and the Arena League 2. Hodges is best known for his one season as the starting quarterback for the Texas Tech Red Raiders during the 2005 season. As a fifth year Senior, he led the nation in passing and total offense and an appearance in the 2006 Cotton Bowl Classic and a 9–3 overall record. He was the 3rd straight fifth year senior to start for Mike Leach and Texas Tech and was also the second of 4 West Texas natives to take the quarterback reins in the Leach era, along with predecessor Sonny Cumbie and successors Taylor Potts and Seth Doege.Taylor Potts (born October 13, 1987) is a former American football quarterback. He played college football at Texas Tech, and was signed by the St. Louis Rams as an undrafted free agent in 2011. He was waived during training camp, and then signed as a free agent by the San Diego Chargers in May 2012, where he was expected to compete for the third-string quarterback position.',\n"," 'William Joshua \"Josh\" Hopkins (born September 12, 1970) is an American actor and amateur musician. Hopkins was born in Lexington, Kentucky. He has participated in many TV series and films. He is the writer and performer of the song \"\"Feigning Interest\"\", a humoristic music video about dating that went viral in 2007. In 2015, he starred in the ABC thriller \"Quantico\" as Liam O\\'Connor.\"All Mixed Up\" is the first episode of the second season of the American television sitcom \"Cougar Town\". It originally aired on September 22, 2010 in the United States on ABC. In this episode, Jules (Courteney Cox) sees a therapist named Glenn (Jennifer Aniston) in order to relieve the stresses of her issues. Meanwhile, Bobby (Brian Van Holt) is troubled with the reality of Grayson\\'s (Josh Hopkins) relationship with Jules, and Travis (Dan Byrd) prepares for college.',\n"," 'Gary Burr, born in Meriden, Connecticut, is an American musician, songwriter, and record producer, primarily in the country music genre. Many of the songs he has written have become Top-10 hits, the first of which was \"Love\\'s Been A Little Bit Hard On Me\" released by Juice Newton (#7 on Billboard\\'s Hot 100) in 1982. He became a member of the group Pure Prairie League (1984 to 1985), taking over after Vince Gill departed the group. Burr later moved to Nashville to focus on his songwriting career, though he has continued performing and is currently a member of the Blue Sky Riders. He has written and co-written songs for a large number of country artists (The Oak Ridge Boys, Reba McEntire, Patty Loveless, etc.), and a few songs for Pop and Rock artists (Juice Newton, Lynyrd Skynyrd, and Lisa Loeb).Lynyrd Skynyrd (pronounced ) is an American rock band best known for popularizing the Southern rock genre during the 1970s. Originally formed in 1964 as \"My Backyard\" in Jacksonville, Florida, the band was also known by names such as \"The Noble Five\" and \"One Percent\", before finally deciding on \"Lynyrd Skynyrd\" in 1969. The band gained worldwide recognition for its live performances and signature songs \"Sweet Home Alabama\" and \"Free Bird\". At the peak of their success, two band members and a backup singer died in an airplane crash in 1977, putting an abrupt end to the band\\'s most popular incarnation. The band has sold 28 million records in the United States.',\n"," 'Thomas Andrew Felton (born September 22, 1987) is an English actor. Felton began appearing in commercials when he was eight years old for companies such as Commercial Union and Barclaycard. He made his screen debut in the role of Peagreen Clock in \"The Borrowers\" (1997) and he portrayed Louis T. Leonowens in \"Anna and the King\" (1999). He rose to prominence for his role as Draco Malfoy in the film adaptions of the best-selling \"Harry Potter\" fantasy novels by J.K. Rowling. His performances in \"Harry Potter and the Half-Blood Prince\" and \"Harry Potter and the Deathly Hallows – Part 1\" won him two consecutive MTV Movie Awards for Best Villain in 2010 and 2011.In Secret, previously titled Thérèse, is a 2013 American erotic thriller film written and directed by Charlie Stratton. Based on Émile Zola\\'s 1867 classic novel \"Thérèse Raquin\", the film stars Elizabeth Olsen, Tom Felton, Oscar Isaac and Jessica Lange. It was screened in the Special Presentation section at the 2013 Toronto International Film Festival. The film received a regional release on February 21, 2014.',\n"," 'War and Peace (Op. 91) (Russian: Война и мир , \"Voyna i mir\") is an opera in two parts (an Epigraph and 13 scenes), sometimes arranged as five acts, by Sergei Prokofiev to a Russian libretto by the composer and Mira Mendelson, based on the novel \"War and Peace\" by Leo Tolstoy. Although Tolstoy\\'s work is classified as a novel, the 1812 invasion of Russia by the French was based on real-life events, and some real-life people appear as characters in both the novel and the opera, e.g. Prince Mikhail Kutuzov and Napoleon Bonaparte.Werther is an opera (\"drame lyrique\") in four acts by Jules Massenet to a French libretto by Édouard Blau, Paul Milliet and Georges Hartmann (who used the pseudonym Henri Grémont). It is loosely based on the German epistolary novel \"The Sorrows of Young Werther\" by Johann Wolfgang von Goethe, which was based both on fact and on Goethe\\'s own early life. Earlier examples of operas using the story were made by Kreutzer (1792) and Pucitta (1802).',\n"," 'The White Rose is a traditional Cornish folk song, the chorus of which appeared in the film \"Ladies in Lavender\" (2005). The song remains popular and has been recorded by many of the Cornish male voice choirs and is often performed at funerals. In 2001 it was read at the funeral of Rick Rescorla, Cornish hero of 9/11.Cyril Richard Rescorla (May 27, 1939 – September 11, 2001) was a United States Army officer and private security officer of British origin who served in Northern Rhodesia as a member of the Northern Rhodesia Police (NRP) and as a commissioned officer in the Vietnam War, where he was a second lieutenant in the United States Army.']"]},"metadata":{"tags":[]},"execution_count":222}]},{"cell_type":"code","metadata":{"id":"jYdDHTVDOuMy"},"source":["human_learner = HumanLearner(kernel_similarity)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ypgVR3zaYxi"},"source":["for teach_ex_idx in teaching_indices:\n","    ex_embed = teaching_embeddings[teach_ex_idx]\n","    ex_label = opt_defer_teaching[teach_ex_idx]\n","    gamma = optimal_gammas[teach_ex_idx] # random choice\n","    human_learner.add_to_teaching([ex_embed, ex_label, gamma])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8nTD390avbN","executionInfo":{"status":"ok","timestamp":1614894636143,"user_tz":300,"elapsed":19427,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"a714cfd4-5c5f-4732-ebcd-fdbf1c267ff3"},"source":["preds_teaching = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 35/7377 [00:00<00:21, 346.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["-- Human making reject predictions --\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7377/7377 [00:19<00:00, 384.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Used posterior 30.61\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH0UyQ6yOQkT","executionInfo":{"status":"ok","timestamp":1614894696973,"user_tz":300,"elapsed":19590,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"82a5ac6d-7707-4028-f2c6-20619ee4874f"},"source":["preds_val = human_learner.predict(validation_embeddings, priorhum_validation_preds)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  1%|          | 37/7377 [00:00<00:19, 368.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["-- Human making reject predictions --\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7377/7377 [00:19<00:00, 382.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["Used posterior 26.56\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Hkv4LciOXCM","executionInfo":{"status":"ok","timestamp":1614894705942,"user_tz":300,"elapsed":778,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"d33ea61e-2961-4335-9d64-ec30b7490970"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, preds_val, [validation_answers[i]['text'] for i in range(len(validation_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 84.86\n"," metrics of system are: {'exact_match': 76.98251321675467, 'f1': 79.17845779927067}\n"," metrics of human are: {'exact_match': 80.2396166134184, 'f1': 81.20980314949209}\n"," metrics of AI are: {'exact_match': 58.728737690241196, 'f1': 67.79419469059745}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.8485834350006778,\n"," {'exact_match': 76.98251321675467, 'f1': 79.17845779927067},\n"," {'exact_match': 80.2396166134184, 'f1': 81.20980314949209},\n"," {'exact_match': 58.728737690241196, 'f1': 67.79419469059745})"]},"metadata":{"tags":[]},"execution_count":182}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDEj109hZvFx","executionInfo":{"status":"ok","timestamp":1614894702562,"user_tz":300,"elapsed":798,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"613e00e8-8865-4e4a-da08-8da9d0029424"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, priorhum_validation_preds, [validation_answers[i]['text'] for i in range(len(validation_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 79.83\n"," metrics of system are: {'exact_match': 75.58628168632225, 'f1': 78.23708365565689}\n"," metrics of human are: {'exact_match': 80.38716250636767, 'f1': 81.33845872431229}\n"," metrics of AI are: {'exact_match': 56.58602150537596, 'f1': 65.96289159966645}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.7982919886132575,\n"," {'exact_match': 75.58628168632225, 'f1': 78.23708365565689},\n"," {'exact_match': 80.38716250636767, 'f1': 81.33845872431229},\n"," {'exact_match': 56.58602150537596, 'f1': 65.96289159966645})"]},"metadata":{"tags":[]},"execution_count":181}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74emkKDJdQ3O","executionInfo":{"status":"ok","timestamp":1614894640151,"user_tz":300,"elapsed":771,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"b507e8f6-3d42-4148-d260-45e7dcb44e59"},"source":["compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teaching, [teaching_answers[i]['text'] for i in range(len(teaching_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 84.87\n"," metrics of system are: {'exact_match': 78.98874881388087, 'f1': 81.23010892614373}\n"," metrics of human are: {'exact_match': 82.35106213064992, 'f1': 83.35042708942146}\n"," metrics of AI are: {'exact_match': 60.1254480286733, 'f1': 69.33466804775396}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.8487189914599431,\n"," {'exact_match': 78.98874881388087, 'f1': 81.23010892614373},\n"," {'exact_match': 82.35106213064992, 'f1': 83.35042708942146},\n"," {'exact_match': 60.1254480286733, 'f1': 69.33466804775396})"]},"metadata":{"tags":[]},"execution_count":179}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj3gpI3Ib_iz","executionInfo":{"status":"ok","timestamp":1614894595055,"user_tz":300,"elapsed":778,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"6595b411-69e8-42f7-d70e-6a68225c8b95"},"source":["compute_metrics(hum_teaching_preds, ai_teaching_preds, priorhum_teaching_preds, [teaching_answers[i]['text'] for i in range(len(teaching_answers))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 79.91\n"," metrics of system are: {'exact_match': 75.59983733224878, 'f1': 78.37410342845895}\n"," metrics of human are: {'exact_match': 80.71246819338408, 'f1': 81.78910994403012}\n"," metrics of AI are: {'exact_match': 55.263157894736466, 'f1': 64.79012002137856}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.7991053273688491,\n"," {'exact_match': 75.59983733224878, 'f1': 78.37410342845895},\n"," {'exact_match': 80.71246819338408, 'f1': 81.78910994403012},\n"," {'exact_match': 55.263157894736466, 'f1': 64.79012002137856})"]},"metadata":{"tags":[]},"execution_count":174}]},{"cell_type":"markdown","metadata":{"id":"ya-DAgGbPmFh"},"source":["## Our approach"]},{"cell_type":"code","metadata":{"id":"gp3DsCWrQAFR"},"source":["data_sizes  = []\n","indices_used = []\n","points_chosen = []\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBIkCCsUPoPT"},"source":["MAX_SIZE = 2000\n","human_learner = HumanLearner(kernel_similarity)\n","errors = []\n","for itt in range(MAX_SIZE):\n","    print(f'New size {itt}')\n","    best_index = -1\n","    best_value = 0\n","\n","    valid_indices = list(set(list(range(len(teaching_answers)))) - set(indices_used))\n","    subset_size = min(10, len(valid_indices))\n","    random_teach_subset = random.sample(valid_indices, subset_size) # used to take gradient steps\n","    random_validation_subset = random.sample(valid_indices, subset_size)\n","    print(\"\")\n","    # for each point, add and see effect then remove\n","    counter_ = 0\n","    for j in random_teach_subset:\n","        counter_ += 1\n","        ex_embed = teaching_embeddings[j]\n","        ex_label = opt_defer_teaching[j]\n","        gamma = optimal_gammas[j] # random choice\n","        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n","        preds_teach = human_learner.predict([teaching_embeddings[i] for i in random_validation_subset], [priorhum_teaching_preds[i] for i in random_validation_subset])\n","        _, metrics, __, ___ = compute_metrics([hum_teaching_preds[kk] for kk in random_validation_subset], [ai_teaching_preds[kk] for kk in random_validation_subset], preds_teach, [teaching_answers[kk]['text'] for kk in random_validation_subset])\n","        #if counter_ % 100 == 0:\n","        #    print(metrics)\n","        acc = metrics[\"f1\"]\n","        if acc >= best_value:\n","            best_value = acc\n","            best_index = j\n","        human_learner.remove_last_teaching_item()\n","\n","    indices_used.append(best_index) # add found element to set used\n","    ex_embed = teaching_embeddings[best_index]\n","    ex_label = opt_defer_teaching[best_index]\n","    gamma = optimal_gammas[best_index] # random choice\n","    human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n","    if itt % 50 == 0:\n","        print(\"####### Actual eval \" +str(itt)+ \" ###########\")\n","        preds_teach = human_learner.predict(validation_embeddings, priorhum_validation_preds)\n","        _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, [validation_answers[i]['text'] for i in range(len(validation_answers))], True)\n","        errors.append(metrics)   \n","        print(\"##############################\")"],"execution_count":null,"outputs":[]}]}