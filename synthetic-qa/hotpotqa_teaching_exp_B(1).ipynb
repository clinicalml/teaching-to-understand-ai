{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP1CACu3irWL"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "meSB2v0g0EH2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRNFoaJXvO4x",
    "outputId": "c1c77847-9645-4eff-ceea-ee423e1b2018"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key text.dvipnghack in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 127 (\"text.dvipnghack : None      # some versions of dvipng don't handle alpha\")\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 430 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key nbagg.transparent in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 433 ('nbagg.transparent: True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 453 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 484 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 485 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.mencoder_path in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 516 ('animation.mencoder_path: mencoder')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.mencoder_args in file c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 519 ('animation.mencoder_args:          # Additional arguments to pass to mencoder')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\program files\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hussein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hussein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import wikipedia\n",
    "import time\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "import  scipy.stats as st\n",
    "from matplotlib import cm\n",
    "import torch.optim as optim\n",
    "from __future__ import print_function\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW, AutoModel\n",
    "import nltk\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import spacy\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import matplotlib\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import copy\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WSnSiY1dF2E"
   },
   "source": [
    "# HotpotQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "a67f65fdf2734482b6b760f2757dd435",
      "5e5c83c1ad964b52ab3f5ab294d15b6a",
      "ffbcead0b8bf4e1da8e4b029dd387eac",
      "66ff3b0230c34be18879e855bdfbc0dd",
      "841c89052af64248bb19965425580559",
      "ef01e42092e24514b234c42d983c8de8",
      "f34227be34db469e95cfd1f95a225e18",
      "8ef35c274a7a4173b901537b50fa95b2",
      "2d9c589f2668480cac427163dd8fa541",
      "0c77e74c032d4a4884daecd92d619a72",
      "eff7d36b95474bf5828673bad75a7c3c",
      "9e54490ae0d846ef84340bc0cc16635f",
      "609215891e394b95b7873f317d45dea3",
      "1adac33380de4121aa3593e2e15c9595",
      "3b42603b8b1c4ac2812068485fc4a246",
      "9208247da78a467195447352a5e5db1b",
      "678521f6e22e45c4bb346376c3a2d135",
      "e1c3a4da07cb4d3b9ea4c38c321f3a49",
      "516c2bfcb0024f618dd68e6ffb888e2f",
      "214439042c384f999287cef480f956ce",
      "f483a4688d0740e7b0ef2231cbdd4d74",
      "1e2d23dc4f9b48d39811624d0b6e54ba",
      "d363ebd45d2d4385acdf720c624d52b3",
      "f01356e5ed8e4f9991fe6839ae1da8d5",
      "6818dcd1957141039f043f1a4accca29",
      "c916e760a9514b17ae128559eed80c0c",
      "cb3d3a49d66542fe935906ef08b52ff0",
      "39248cca6ba14781819262c79197f46b",
      "5a2073f8ba0a41e9ae41d8e63f97127c",
      "8c6138961893478abcaa77cfa507ba21",
      "f81a8ea5bca1475da4fba7e9a03316ce",
      "a3d9a9ded626438690685b3b3096488a",
      "768df23dfaf447d080e845b4c1bd08bd",
      "fb07f93cc8624594b41e83607be0dda9",
      "0babc95d3ffa467cbdb307e9f691c077",
      "85585db43ae147ef90fb12f3f1eef1e5",
      "c0d0376851b4441fb30903e55f5aa78a",
      "749afa67c4554b01accdfdef13c8dac5",
      "88118d3cab034266b4dbfbe6f0600e0e",
      "9177d2dc568643a5a949a96b804dfa2d",
      "7d45c3d7c001432598703f1d9b0a11ae",
      "afc87a4a21974707bf95c4e3c6502d3e",
      "ca3799c46c654e4389e33a2fcea86700",
      "8af8ee76afcc4fe08a7155e8aaf94761",
      "50ca82f1f55c451689146981550dfb77",
      "365424c612434daf9945229fec2bc6fb",
      "3111d5456c3f4efd9c94c19c55560eb4",
      "7c17e8380dc44d00baec2a3c181e75cb"
     ]
    },
    "id": "3E0eakH8dHfv",
    "outputId": "281b5f68-b383-45b5-a6e8-44e06d97fd61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hotpot_qa (C:\\Users\\Hussein\\AppData\\Roaming\\SPB_Data\\.cache\\huggingface\\datasets\\hotpot_qa\\distractor\\1.0.0\\2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "DISTRACTORS_PARS_LEN = 0\n",
    "dataset = load_dataset(\"hotpot_qa\", 'distractor')\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqzhee23lkrz",
    "outputId": "4f31f0ce-6982-4410-f69d-e8fa43d123ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_token_lenght(context, question):\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    return len(inputs['input_ids'][0])\n",
    "\n",
    "def remove_distractors(example, n_distractors = 0):\n",
    "    all_pars = example['context']['title']\n",
    "    gold_pars = list(set(example['supporting_facts']['title']))\n",
    "    distractor_pars = list(set(all_pars) - set(gold_pars))\n",
    "    # get indices to keep from disractors\n",
    "    if len(distractor_pars) == 0 or n_distractors == 0:\n",
    "        distract_indices = []\n",
    "    else:\n",
    "        distract_indices = random.sample(range(len(distractor_pars)), n_distractors)\n",
    "    distractor_pars = [distractor_pars[idx] for idx in distract_indices]\n",
    "    keep_pars = gold_pars + distractor_pars\n",
    "    keep_pars_indices = [all_pars.index(keep_par) for keep_par in keep_pars]\n",
    "    example['context']['title'] = [example['context']['title'][idx] for idx in keep_pars_indices]\n",
    "    example['context']['sentences'] = [example['context']['sentences'][idx] for idx in keep_pars_indices]\n",
    "    \n",
    "    sentences_par = [\"\".join(example['context']['sentences'][idx]) for idx in range(len(example['context']['sentences']))]\n",
    "    example['intros'] = \" \".join([example['context']['sentences'][idx][0] for idx in range(len(example['context']['sentences']))])\n",
    "    example['passage'] = \" #$ \".join(sentences_par)\n",
    "    return example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "cced9717f2db4828a1eab405ccfe26bf",
      "50aef972bd6649be9f8cd99233271f05",
      "858e9646d78242bdb868033fd0cba5d5",
      "d5d200b2a06f4177a0bb7fad1fb5a487",
      "ef228b4e20544802a374962a9278d5c1",
      "9949e54b38cb491d9caad7c4850ecb0a",
      "0b773166041b4b52bc968e8da555d235",
      "9ee4989788e84c019b33605078607446",
      "9e2b8131630f4198b6aa38a0ad71b309",
      "70c284ee211a4e7db734dd90216b1a42",
      "4be8038b99994c81a6c2dddfea661edd",
      "a46013a5ac134dd5822cfb735b272dc9",
      "ecf56216555b43848a1e2957b3b70255",
      "a93568dd97de42b6845d006ffd14f06e",
      "44f309612f9d4a36b103c26d87573bcd",
      "36e6d5888db0417b847ab7ec64f71c8e"
     ]
    },
    "id": "unz9KJ9qofO3",
    "outputId": "726f41e8-7c33-4f95-c112-e60d89ef9185"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Hussein\\AppData\\Roaming\\SPB_Data\\.cache\\huggingface\\datasets\\hotpot_qa\\distractor\\1.0.0\\2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d\\cache-49419642e646b929.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Hussein\\AppData\\Roaming\\SPB_Data\\.cache\\huggingface\\datasets\\hotpot_qa\\distractor\\1.0.0\\2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d\\cache-3d13b7733730f460.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(remove_distractors)\n",
    "validation_dataset = validation_dataset.map(remove_distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1AI46NXwNV-",
    "outputId": "9a5aa897-8a35-4a09-8099-a06bb02da296"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6947\n",
      "14631\n"
     ]
    }
   ],
   "source": [
    "# Free form vs yes/no\n",
    "all_indices = set(list(range(len(validation_dataset))))\n",
    "yes_no_indices = set([i  for i in range(len(validation_dataset)) if validation_dataset[i]['answer'] in [\"yes\",\"no\"] ])\n",
    "free_indices_val = all_indices - yes_no_indices\n",
    "all_indices = set(list(range(len(train_dataset))))\n",
    "yes_no_indices_train = set([i  for i in range(len(train_dataset)) if (train_dataset[i]['answer'] in [\"yes\",\"no\"]) or (train_dataset[i]['level'] in ['easy','medium']) ])\n",
    "free_indices_train = all_indices - yes_no_indices_train\n",
    "print(len(free_indices_val))\n",
    "print(len(free_indices_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6fP4_P2wNWA",
    "outputId": "53ab2199-2681-4178-c43c-76376c2c64c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_dataset = [train_dataset[i] for i in free_indices_train ]\n",
    "hard_dataset += [validation_dataset[i] for i in free_indices_val]\n",
    "dataset_indices =  set(list(range(len(hard_dataset))))\n",
    "VAL_START = len([train_dataset[i] for i in free_indices_train ])\n",
    "len(hard_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK9JLhs-97wO"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40Mqih9Z8rTx",
    "outputId": "0c357c0c-8b51-4902-d469-76ab92a4fcda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_truth_pred(truths, preds):\n",
    "    '''\n",
    "    truths, preds: matched arrays of ground truth answers and predictions\n",
    "    '''\n",
    "    f1 = exact_match = total = 0\n",
    "    for i in range(len(truths)):\n",
    "        total += 1\n",
    "        if truths[i] in ['yes', \"no\"]:\n",
    "            continue\n",
    "        ground_truths = [truths[i]]\n",
    "        prediction = preds[i]\n",
    "        exact_match += metric_max_over_ground_truths(\n",
    "            exact_match_score, prediction, ground_truths)\n",
    "        f1 += metric_max_over_ground_truths(\n",
    "            f1_score, prediction, ground_truths)\n",
    "\n",
    "    exact_match = 100.0 * exact_match / (total+ 0.00000000001)\n",
    "    f1 = 100.0 * f1 / (total+ 0.00000000001)\n",
    "\n",
    "    return {'exact_match': exact_match, 'f1': f1}\n",
    "\n",
    "\n",
    "def get_answer( model, tokenizer, context, question):\n",
    "    # 1. TOKENIZE THE INPUT\n",
    "    # note: if you don't include return_tensors='pt' you'll get a list of lists which is easier for\n",
    "    # exploration but you cannot feed that into a model.\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    # 2. OBTAIN MODEL SCORES\n",
    "    # the AutoModelForQuestionAnswering class includes a span predictor on top of the model.\n",
    "    # the model returns answer start and end scores for each word in the text\n",
    "    answer_start_scores, answer_end_scores = model(**inputs, return_dict=False)\n",
    "    answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n",
    "    # 3. GET THE ANSWER SPAN\n",
    "    # once we have the most likely start and end tokens, we grab all the tokens between them\n",
    "    # and convert tokens back to words!\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "    return answer\n",
    "# https://huggingface.co/transformers/migration.html\n",
    "def model_evaluation(model, tokenizer, questions, contexts, answers, to_print = False):\n",
    "    preds = []\n",
    "    my_list = list(range(len(questions)))\n",
    "    with tqdm(total=len(my_list)) as pbar:\n",
    "        for ex in range(len(questions)):\n",
    "            answer = get_answer(model, tokenizer, contexts[ex],questions[ex])\n",
    "            preds.append(answer)\n",
    "            if ex % 100 == 0 and to_print:\n",
    "                print(\"context \" +contexts[ex] )\n",
    "                print(\"quest \" +questions[ex] )\n",
    "                print(\"truth \" +answers[ex]['text'] )\n",
    "                print(\"pred \" + answer)\n",
    "            pbar.update(1)\n",
    "    truths = [answers[i]['text'] for i in range(len(answers))]\n",
    "    scores = evaluate_truth_pred(truths, preds)\n",
    "    print(scores)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def kernel_similarity(x, y):\n",
    "        kernel_dist = rbf_kernel(x.reshape(1, -1),y.reshape(1, -1))\n",
    "        return kernel_dist[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpcZrrMcwNWP"
   },
   "source": [
    "# FakeAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbyNu1-WwNWQ",
    "outputId": "5c70919f-353b-4bfe-dffb-5c250cc2a331"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FakeAI:\n",
    "    r\"\"\"\n",
    "    FakeAI that is incorrect in random clusters in the input space\n",
    "    \n",
    "    Args:\n",
    "        train_passages: list of embedded passages\n",
    "        train_questions: list of embedded questions\n",
    "        n_clus_p: number of centroids in kmeans for passages\n",
    "        n_clus_q: number of centroids in kmeans for questions\n",
    "        clust_err_p: clusters where AI makes error on passages\n",
    "        clust_err_q: clusters where AI makes error on questions\n",
    "    \"\"\"\n",
    "    def __init__(self, train_passages, train_questions, n_clus_p, n_clus_q, beta_params = (1,1), kmeans = None, err_p = None):\n",
    " \n",
    "        self.train_passages = train_passages\n",
    "        self.train_questions = train_questions\n",
    "        self.n_clus_p = n_clus_p\n",
    "        self.n_clus_q = n_clus_q\n",
    "        if err_p == None:\n",
    "            self.clust_err_p = np.random.beta(beta_params[0],beta_params[1],self.n_clus_p)\n",
    "            '''\n",
    "            for i in range(len(self.clust_err_p)):\n",
    "                if self.clust_err_p[i] <= 0.333333:\n",
    "                    self.clust_err_p[i] = 0.0\n",
    "                elif self.clust_err_p[i]>=0.6666666:\n",
    "                    self.clust_err_p[i] = 1.0\n",
    "                else:\n",
    "                    self.clust_err_p[i] = 0.5\n",
    "            '''\n",
    "        else:\n",
    "            self.clust_err_p = err_p\n",
    "        self.clust_err_q = np.random.beta(0.2,0.8,self.n_clus_p)#np.random.rand(self.n_clus_q)#/2 + 0.5\n",
    "        if kmeans == None:\n",
    "            self.build_kmeans()\n",
    "        else:\n",
    "            self.kmeans_pass = kmeans\n",
    "            self.kmeans_quest = kmeans\n",
    "\n",
    "        \n",
    "    def build_kmeans(self):\n",
    "        # Builds kmeans for passages and questions\n",
    "        self.kmeans_quest = KMeans(n_clusters=self.n_clus_q, max_iter = 10000).fit(self.train_questions)\n",
    "        self.kmeans_pass = KMeans(n_clusters=self.n_clus_p, max_iter = 100000).fit(self.train_passages)\n",
    "\n",
    "    def predict_right_wrong(self, passages, questions):\n",
    "        '''\n",
    "        Args:\n",
    "            passages: list of embedded passages\n",
    "            questions: list of embedded questions (same size as passages)\n",
    "        Returns:\n",
    "            preds: binary array indicating if AI is right (1) or wrong (0)\n",
    "        '''\n",
    "        clusts_p = self.kmeans_pass.predict(passages)\n",
    "        clusts_q = self.kmeans_quest.predict(questions)\n",
    "        preds = []\n",
    "        for i in range(len(clusts_p)):\n",
    "            coin = random.random() # random number between [0,1]\n",
    "            if coin >= self.clust_err_p[clusts_p[i]]:\n",
    "                preds.append(0)\n",
    "            else:\n",
    "                preds.append(1)\n",
    "        return preds\n",
    "\n",
    "    \n",
    "    def predict_raw_probas(self, passages, questions):\n",
    "        '''\n",
    "        Args:\n",
    "            passages: list of embedded passages\n",
    "            questions: list of embedded questions (same size as passages)\n",
    "        Returns:\n",
    "            preds: binary array indicating if AI is right (1) or wrong (0)\n",
    "        '''\n",
    "        clusts_p = self.kmeans_pass.predict(passages)\n",
    "        clusts_q = self.kmeans_quest.predict(questions)\n",
    "        preds = []\n",
    "        for i in range(len(clusts_p)):\n",
    "            preds.append(self.clust_err_p[clusts_p[i]])\n",
    "        return preds\n",
    "    \n",
    "    def prior_rejector(self, passages, questions, epsilon_reject):\n",
    "        '''\n",
    "        rejector defined as : 1{prob_of_correct <= epsilon_reject}\n",
    "        '''\n",
    "        clusts_p = self.kmeans_pass.predict(passages)\n",
    "        clusts_q = self.kmeans_quest.predict(questions)\n",
    "        preds = []\n",
    "        for i in range(len(clusts_p)):\n",
    "            coin = random.random() # random number between [0,1]\n",
    "            if  self.clust_err_p[clusts_p[i]] <= epsilon_reject:\n",
    "                preds.append(1)\n",
    "            else:\n",
    "                preds.append(0)\n",
    "        return preds\n",
    "\n",
    "    def predict_proba(self, raw_passages):\n",
    "        embed_ps = model.encode(raw_passages)\n",
    "        embed_ps = [embed_ps[i] for i in range(len(embed_ps))]\n",
    "        clusts_p = self.kmeans_pass.predict(embed_ps)\n",
    "        preds = []\n",
    "        for i in range(len(clusts_p)):\n",
    "            coin = random.random() # random number between [0,1]\n",
    "            if coin >= self.clust_err_p[clusts_p[i]]:\n",
    "                preds.append([0.0,1.0])\n",
    "            else:\n",
    "                preds.append([1.0,0.0])\n",
    "        return np.asarray(preds)\n",
    "\n",
    "    def predict_proba_encoded(self, passages):\n",
    "        clusts_p = self.kmeans_pass.predict(np.array(passages, dtype=np.float32))\n",
    "        preds = []\n",
    "        for i in range(len(clusts_p)):\n",
    "            coin = random.random() # random number between [0,1]\n",
    "            if coin >= self.clust_err_p[clusts_p[i]]:\n",
    "                preds.append([0.0,1.0])\n",
    "            else:\n",
    "                preds.append([1.0,0.0])\n",
    "        return np.asarray(preds)\n",
    "\n",
    "\n",
    "def is_a_stopword(feature, weight):\n",
    "    split_words = feature.split(' ')\n",
    "    for word in split_words:\n",
    "        if word in stopwords:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_highlighted_p(ai_model, paragraph):\n",
    "    '''\n",
    "    from https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html#lime-tutorial\n",
    "    '''\n",
    "    \n",
    "    te = TextExplainer(random_state=42)\n",
    "    te.fit(paragraph, ai_model.predict_proba)\n",
    "    show_pred = te.show_prediction(target_names=['correct','false'], top=(8,0), feature_filter = is_a_stopword)\n",
    "    correct = False\n",
    "    if show_pred.data.find(\"y=correct\") != -1:\n",
    "        correct = True\n",
    "    b = show_pred.data.split('<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">')\n",
    "    to_show = '<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">' +b[-1]\n",
    "    if not correct:\n",
    "        to_show = to_show.replace(\"hsl(120,\",\"hsl(0,\")\n",
    "    return to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "541d96be93914f69b66376ba74a99d37",
      "1bfadc5a51cd47068be189674f9d3c49",
      "ef2a247862bb49ef8c83c5cd664a15e3",
      "18c16d656a064c248e298ead75564043",
      "f3554f7b32bc428984b27f319ac2e605",
      "76dbc1405ff745928737f59cae06ad1f",
      "a7346f15005d4f2fa88bf5938b5a041d",
      "06985fc128644e649774167c580e38be"
     ]
    },
    "id": "jN6a89iFAk25",
    "outputId": "bcd40459-475e-4e10-8138-75505f7dbc82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1') #distilbert-base-nli-stsb-mean-tokens\n",
    "# https://www.sbert.net/docs/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYBacIDTwNWV"
   },
   "source": [
    "# Teaching Prelims\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-L_wImhCL-o"
   },
   "source": [
    "## Human classes and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "GYUTZTA3wNWW",
    "outputId": "c4a87f39-d7f3-4eed-f2ae-237617d55466"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HumanLearner:\n",
    "    def __init__(self, kernel):\n",
    "        '''\n",
    "        kernel: function that takes two inputs and returns a similarity\n",
    "        prior rejector: returns rejector\n",
    "        '''\n",
    "        self.teaching_set = []\n",
    "        self.kernel = kernel\n",
    "    def predict(self, xs, prior_rejector_preds, to_print = False):\n",
    "        '''\n",
    "        xs: expected array of inputs\n",
    "        '''\n",
    "        preds = []\n",
    "        idx = 0\n",
    "        used_posterior = 0 \n",
    "        if to_print:\n",
    "            print(\"-- Human making reject predictions --\")\n",
    "            with tqdm(total=len(xs)) as pbar:\n",
    "                for x in xs:\n",
    "                    ball_at_x = []\n",
    "                    similarities = rbf_kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n",
    "                    for i in range(len(self.teaching_set)):\n",
    "                        similarity = similarities[i]\n",
    "                        if similarity >=  self.teaching_set[i][2]:\n",
    "                            ball_at_x.append(self.teaching_set[i])\n",
    "                    if len(ball_at_x) == 0: \n",
    "                        # use prior rejector\n",
    "                        preds.append(prior_rejector_preds[idx])\n",
    "                    else:\n",
    "                        used_posterior += 1\n",
    "                        ball_similarities = rbf_kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n",
    "                        normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n",
    "                        score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n",
    "                        pred = score_one / normalization\n",
    "                        if pred >= 0.5:\n",
    "                            preds.append(1)\n",
    "                        else:\n",
    "                            preds.append(0)\n",
    "                    idx += 1\n",
    "                    pbar.update(1)\n",
    "        else:\n",
    "            for x in xs:\n",
    "                ball_at_x = []\n",
    "                similarities = rbf_kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n",
    "                for i in range(len(self.teaching_set)):\n",
    "                    similarity = similarities[i]\n",
    "                    if similarity >=  self.teaching_set[i][2]:\n",
    "                        ball_at_x.append(self.teaching_set[i])\n",
    "                if len(ball_at_x) == 0: \n",
    "                    # use prior rejector\n",
    "                    preds.append(prior_rejector_preds[idx])\n",
    "                else:\n",
    "                    used_posterior += 1\n",
    "                    ball_similarities = rbf_kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n",
    "                    normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n",
    "                    score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n",
    "                    pred = score_one / normalization\n",
    "                    if pred >= 0.5:\n",
    "                        preds.append(1)\n",
    "                    else:\n",
    "                        preds.append(0)\n",
    "                idx += 1\n",
    "        if to_print:\n",
    "            print(f'Used posterior {used_posterior/len(xs)*100:.2f}')\n",
    "        return preds\n",
    "\n",
    "    def add_to_teaching(self, teaching_example):\n",
    "        '''\n",
    "        teaching_example: (x, label, gamma)\n",
    "        '''\n",
    "        self.teaching_set.append(teaching_example)\n",
    "\n",
    "    def remove_last_teaching_item(self):\n",
    "        self.teaching_set = self.teaching_set[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Z4329rtlwNWX",
    "outputId": "847dd211-3167-4abf-90f9-3a445338f728"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_predictions_humanai(hum_preds, hum_rejector, ai_preds, data_x):\n",
    "    '''\n",
    "    hum_preds: array of human predictions\n",
    "    ai_preds: array of AI predictions\n",
    "    hum_rejector: HumanLearner\n",
    "    data_x: array of inputs\n",
    "\n",
    "    Returns array of final predictions and deferalls\n",
    "    '''\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        reject_decisions = hum_rejector(data_x)\n",
    "        for i in range(len(data_x)):\n",
    "            if reject_decisions[i] == 1:\n",
    "                # defer\n",
    "                predictions.append(ai_preds[i])\n",
    "            else:\n",
    "                predictions.append(hum_preds[i])\n",
    "    return predictions, reject_decisions\n",
    "\n",
    "def get_metrics(preds, truths):\n",
    "    # custom for each use case\n",
    "    return evaluate_truth_pred(truths, preds)\n",
    "\n",
    "def compute_metrics(human_preds, ai_preds, reject_decisions, truths, to_print = False):\n",
    "    coverage = 1 - np.sum(reject_decisions)/len(reject_decisions)\n",
    "    humanai_preds = []\n",
    "    human_preds_sys = []\n",
    "    truths_human = []\n",
    "    ai_preds_sys = []\n",
    "    truths_ai = []\n",
    "    for i in range(len(reject_decisions)):\n",
    "        if reject_decisions[i] == 1:\n",
    "            humanai_preds.append(ai_preds[i])\n",
    "            ai_preds_sys.append(ai_preds[i])\n",
    "            truths_ai.append(truths[i])\n",
    "        else:\n",
    "            humanai_preds.append(human_preds[i])\n",
    "            human_preds_sys.append(human_preds[i])\n",
    "            truths_human.append(truths[i])\n",
    "    humanai_metrics = get_metrics(humanai_preds, truths)\n",
    "    human_metrics = get_metrics(human_preds_sys, truths_human)\n",
    "    ai_metrics = get_metrics(ai_preds_sys, truths_ai)\n",
    "    if to_print:\n",
    "        print(f'Coverage is {coverage*100:.2f}')\n",
    "        print(f' metrics of system are: {humanai_metrics}')\n",
    "        print(f' metrics of human are: {human_metrics}')\n",
    "        print(f' metrics of AI are: {ai_metrics}')\n",
    "    return coverage, humanai_metrics, human_metrics, ai_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBHrWz39CjhT"
   },
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dtK3TIrwNWY",
    "outputId": "850563e8-29b3-4eb5-e86e-f86a90919717"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define teaching and validation\n",
    "random.seed(66)\n",
    "all_passages = [hard_dataset[i]['passage'] for i in range(len(hard_dataset))]\n",
    "embeddings_passage = model.encode(all_passages)\n",
    "embeddings_passage = [embeddings_passage[i] for i in range(len(embeddings_passage))]\n",
    "\n",
    "all_questions = [hard_dataset[i]['question'] for i in range(len(hard_dataset))]\n",
    "all_answers = [hard_dataset[i]['answer'] for i in range(len(hard_dataset))]\n",
    "all_sentences =  [hard_dataset[i]['context']['sentences'] for i in range(len(hard_dataset))]\n",
    "\n",
    "train_indices = list(range(VAL_START))\n",
    "test_indices = list(range(VAL_START,len(hard_dataset)))\n",
    "\n",
    "train_passages = [embeddings_passage[i] for i in train_indices]\n",
    "#train_questions = [embeddings_question[i] for i in train_indices]\n",
    "test_passages = [embeddings_passage[i] for i in test_indices]\n",
    "#test_questions = [embeddings_question[i] for i in test_indices]\n",
    "train_sentences = [all_sentences[i] for i in train_indices]\n",
    "test_sentences = [all_sentences[i] for i in test_indices]\n",
    "\n",
    "train_answers = [all_answers[i] for i in train_indices]\n",
    "test_answers = [all_answers[i] for i in test_indices]\n",
    "train_raw_passages = [all_passages[i] for i in train_indices]\n",
    "test_raw_passages = [all_passages[i] for i in test_indices]\n",
    "train_raw_questions= [all_questions[i] for i in train_indices]\n",
    "test_raw_questions = [all_questions[i] for i in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF5GamxWCtvI",
    "outputId": "b70c533a-a7e1-4cba-fb82-b0e9a15f3438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "teaching_embeddings = np.asarray([np.concatenate([train_passages[i]]) for i in range(len(train_passages))])\n",
    "validation_embeddings = np.asarray([np.concatenate([test_passages[i]]) for i in range(len(test_passages))])\n",
    "del embeddings_passage\n",
    "del model\n",
    "del train_passages\n",
    "del test_passages\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHpcZgQzpYQP",
    "outputId": "afe387b7-fbe4-4f2d-dc56-db9c788091e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarities_embeds_all = rbf_kernel(np.asarray(teaching_embeddings), np.asarray(teaching_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNml65F6nEMo",
    "outputId": "034d92cf-199d-4d20-c7c1-80932ce8558d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n"
     ]
    }
   ],
   "source": [
    "sorted_sims = []\n",
    "print(\"started\")\n",
    "for i in range(len(similarities_embeds_all)):\n",
    "    if i% 500 == 0:\n",
    "        print(i)\n",
    "    sorted_sim = sorted([(similarities_embeds_all[i][k], k) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n",
    "    sorted_sims.append(np.asarray(sorted_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azMMvAQonEMo",
    "outputId": "db08a850-339e-40be-cef4-5619d9c42110"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get optimal gammas\n",
    "def get_optimal_gammas():\n",
    "    optimal_gammas = []\n",
    "    with tqdm(total=len(teaching_embeddings)) as pbar:\n",
    "        similarities_embeds_all = rbf_kernel( np.asarray(teaching_embeddings), np.asarray(teaching_embeddings))\n",
    "        for i in range(len(teaching_embeddings)):\n",
    "            # get all similarities\n",
    "            similarities_embeds = similarities_embeds_all[i]\n",
    "            opt_defer_ex = opt_defer_teaching[i]\n",
    "            opt_gamma = 1\n",
    "            sorted_sim = sorted([(similarities_embeds[k], opt_defer_teaching[k]) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n",
    "            indicess = list(range(1, len(opt_defer_teaching)))\n",
    "            indicess.reverse()\n",
    "            for k in indicess:\n",
    "                if sorted_sim[k][1] == opt_defer_ex and sorted_sim[k- 1][1] != opt_defer_ex:\n",
    "                    opt_gamma = sorted_sim[k][0]\n",
    "                    break\n",
    "            optimal_gammas.append(opt_gamma)\n",
    "            pbar.update(1)\n",
    "    return optimal_gammas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3oEF1rEnXKB"
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMCUulSHCy78"
   },
   "source": [
    "## Selection Algorithm- consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Czd2J20eN8VB",
    "outputId": "d948597e-83c9-4462-c515-e76504ed9989"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_improvement_defer(current_defer_preds, opt_defer_preds, gammas, xs, coin_prob = 0.2):\n",
    "    error_improvements = []\n",
    "    #similarities_embeds_all = rbf_kernel(np.asarray(xs), np.asarray(xs))\n",
    "    error_at_i = 0\n",
    "    for i in range(len(gammas)):\n",
    "        coin = random.random() # random number between [0,1]\n",
    "        error_at_i = 0\n",
    "        if coin >= coin_prob:\n",
    "            error_improvements.append(error_at_i)\n",
    "            continue\n",
    "        similarities_embeds = similarities_embeds_all[i]\n",
    "        for j in range(len(similarities_embeds)):\n",
    "            if similarities_embeds[j] >= gammas[i]:\n",
    "                f1_hum = hum_teaching_preds_b[j]\n",
    "                f1_ai = ai_teaching_preds_b[j]\n",
    "                if opt_defer_preds[i] == 1:\n",
    "                    if current_defer_preds[j] == 0:\n",
    "                        error_at_i += f1_ai - f1_hum\n",
    "                else:\n",
    "                    if current_defer_preds[j] == 1:\n",
    "                        error_at_i += f1_hum - f1_ai\n",
    "        error_improvements.append(error_at_i)\n",
    "\n",
    "        # get the ball for x\n",
    "        # in this ball how many does the current defer not match the optimal\n",
    "    return error_improvements\n",
    "\n",
    "\n",
    "def get_greedy_gamma(i, current_defer_preds, opt_defer_preds, gammas, xs):\n",
    "    similarities_embeds = similarities_embeds_all[i]\n",
    "    sorted_sim = sorted_sims[i]#sorted([(similarities_embeds[k], k) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n",
    "    indicess = list(range(1, len(opt_defer_teaching)))\n",
    "    indicess.reverse()\n",
    "    max_improve = -1000\n",
    "    gamma_value = 1\n",
    "    current_improve = 0\n",
    "    so_far = 0\n",
    "    for j in indicess:\n",
    "        if so_far >= len(indicess)*0.25:\n",
    "            break\n",
    "        so_far += 1\n",
    "        idx = int(sorted_sim[j][1])\n",
    "        #f1_hum = metric_max_over_ground_truths(f1_score, train_answers[idx], [hum_teaching_preds[idx]]) # pass as param plz\n",
    "        #f1_ai = metric_max_over_ground_truths(f1_score, train_answers[idx], [ai_teaching_preds[idx]])# pass as param plz\n",
    "        f1_hum = hum_teaching_preds_b[idx]\n",
    "        f1_ai = ai_teaching_preds_b[idx]\n",
    "        if opt_defer_preds[i] == 1:\n",
    "            if current_defer_preds[idx] == 0:\n",
    "                current_improve += f1_ai - f1_hum\n",
    "        else:\n",
    "            if current_defer_preds[idx] == 1:\n",
    "                current_improve += f1_hum - f1_ai\n",
    "\n",
    "        if current_improve >= max_improve:\n",
    "            max_improve = current_improve \n",
    "            gamma_value = sorted_sim[j][0]\n",
    "\n",
    "    return max_improve, gamma_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4llaAF5NsL2",
    "outputId": "3e71b98d-5bfd-409a-edfb-75ad2aedbe1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def teach_ours(greedy_gamma = False):\n",
    "    human_learner = HumanLearner(None)\n",
    "    errors = []\n",
    "    data_sizes  = []\n",
    "    indices_used = []\n",
    "    points_chosen = []\n",
    "    for itt in range(MAX_SIZE):\n",
    "        print(f'New size {itt}')\n",
    "        best_index = -1\n",
    "        # predict with current human learner\n",
    "        if itt == 0:\n",
    "            preds_teach = priorhum_teaching_preds\n",
    "        else:\n",
    "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "        error_improvements = get_improvement_defer(preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "        best_index = np.argmax(error_improvements)\n",
    "        indices_used.append(best_index) # add found element to set used\n",
    "        ex_embed = teaching_embeddings[best_index]\n",
    "        ex_label = opt_defer_teaching[best_index]\n",
    "\n",
    "        if greedy_gamma:\n",
    "            _, greedy_gamma = get_greedy_gamma(best_index, preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "            gamma = greedy_gamma\n",
    "            print(f'got improvements with max {_}')\n",
    "\n",
    "        else:\n",
    "            gamma = optimal_gammas[best_index]\n",
    "            print(f'got improvements with max {max(error_improvements)}')\n",
    "\n",
    "\n",
    "        #gamma = optimal_gammas[best_index] # + (np.random.rand(1)[0])*(1-optimal_gammas[best_index])-(1-optimal_gammas[best_index])/2 # random choice\n",
    "        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n",
    "\n",
    "        if False and itt % 3 == 0:\n",
    "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, train_answers, True)\n",
    "            #errors.append(metrics)   \n",
    "            print(\"##############################\")\n",
    "\n",
    "        if itt % PLOT_INTERVAL == 0:\n",
    "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner.predict(validation_embeddings, priorhum_validation_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, test_answers, True)\n",
    "            errors.append(metrics['exact_match'])   \n",
    "            print(\"##############################\")\n",
    "    return errors, indices_used\n",
    "#errors, indices_used = teach_ours(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCa5P-rXnEMv"
   },
   "source": [
    "## Selection double greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5nncmzznEMv",
    "outputId": "0767d55d-9adc-42c2-e148-74eb948fe2c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "indicess = list(range(1, len(teaching_embeddings)))\n",
    "indicess.reverse()\n",
    "def get_improvement_defer_greedy(current_defer_preds, opt_defer_preds, gammas, xs):\n",
    "\n",
    "    error_improvements = []\n",
    "    #similarities_embeds_all = rbf_kernel(np.asarray(xs), np.asarray(xs))\n",
    "    error_at_i = 0\n",
    "    found_gammas = []\n",
    "    for i in range(len(opt_defer_preds)):\n",
    "        coin = random.random() # random number between [0,1]\n",
    "        if coin >= 0.1:\n",
    "            error_improvements.append(0)\n",
    "            found_gammas.append(1)\n",
    "            continue\n",
    "        similarities_embeds = similarities_embeds_all[i]\n",
    "        sorted_sim = sorted_sims[i]#sorted([(similarities_embeds[k], k) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n",
    "\n",
    "        max_improve = -1000\n",
    "        gamma_value = 1\n",
    "        current_improve = 0\n",
    "        so_far = 0\n",
    "        for j in indicess:\n",
    "            if so_far >= len(indicess)*0.25:\n",
    "                break\n",
    "            so_far += 1\n",
    "            idx = int(sorted_sim[j][1])\n",
    "            f1_hum = hum_teaching_preds_b[idx]\n",
    "            f1_ai = ai_teaching_preds_b[idx]\n",
    "            if opt_defer_preds[i] == 1:\n",
    "                if current_defer_preds[idx] == 0:\n",
    "                    current_improve += f1_ai - f1_hum\n",
    "            else:\n",
    "                if current_defer_preds[idx] == 1:\n",
    "                    current_improve += f1_hum - f1_ai\n",
    "\n",
    "            if current_improve >= max_improve:\n",
    "                max_improve = current_improve \n",
    "                gamma_value = sorted_sim[j][0]\n",
    "            \n",
    "        error_improvements.append(max_improve)\n",
    "        found_gammas.append(gamma_value)\n",
    "    return error_improvements, found_gammas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KZkwM5InEMx",
    "outputId": "f71ef284-8b89-4b3b-e1c4-bef770bcb3bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def teach_ours_doublegreedy():\n",
    "    human_learner = HumanLearner(None)\n",
    "    errors = []\n",
    "    data_sizes  = []\n",
    "    indices_used = []\n",
    "    points_chosen = []\n",
    "    for itt in range(MAX_SIZE):\n",
    "        print(f'New size {itt}')\n",
    "        best_index = -1\n",
    "        # predict with current human learner\n",
    "        if itt == 0:\n",
    "            preds_teach = priorhum_teaching_preds\n",
    "        else:\n",
    "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "        error_improvements, best_gammas = get_improvement_defer_greedy(preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "        print(f'got improvements with max {max(error_improvements)}')\n",
    "        best_index = np.argmax(error_improvements)\n",
    "        indices_used.append(best_index) # add found element to set used\n",
    "        ex_embed = teaching_embeddings[best_index]\n",
    "        ex_label = opt_defer_teaching[best_index]\n",
    "        gamma = best_gammas[best_index] # + (np.random.rand(1)[0])*(1-optimal_gammas[best_index])-(1-optimal_gammas[best_index])/2 # random choice\n",
    "        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n",
    "\n",
    "        if False and itt % 3 == 0:\n",
    "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, train_answers, True)\n",
    "            #errors.append(metrics)   \n",
    "            print(\"##############################\")\n",
    "\n",
    "        if itt % PLOT_INTERVAL == 0:\n",
    "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner.predict(validation_embeddings, priorhum_validation_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, test_answers, True)\n",
    "            errors.append(metrics['exact_match'])   \n",
    "            print(\"##############################\")\n",
    "    return errors, indices_used\n",
    "#errors_doublegreedy, indices_used_doublegreedy = teach_ours_doublegreedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Ch46jJttQL"
   },
   "source": [
    "## Random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZKwIJsntunf",
    "outputId": "457b8103-26db-4bf8-d67a-6fe5df6ec990"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def teach_random(greedy_gamma = False):\n",
    "    human_learner_random = HumanLearner(None)\n",
    "    errors_random = []\n",
    "    data_sizes  = []\n",
    "    indices_used_random = random.sample(list(range(len(teaching_embeddings))), MAX_SIZE) # used to take gradient steps\n",
    "    points_chosen = []\n",
    "    for itt in range(MAX_SIZE):\n",
    "        print(f'New size {itt}')\n",
    "        best_index = indices_used_random[itt]\n",
    "        ex_embed = teaching_embeddings[best_index]\n",
    "        ex_label = opt_defer_teaching[best_index]\n",
    "        if greedy_gamma:\n",
    "            if itt == 0 or first_time:\n",
    "                preds_teach = priorhum_teaching_preds\n",
    "                first_time = False\n",
    "            else:\n",
    "                preds_teach = human_learner_random.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, greedy_gamma = get_greedy_gamma(best_index, preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "            gamma = greedy_gamma\n",
    "        else:\n",
    "            gamma = optimal_gammas[best_index]\n",
    "        human_learner_random.add_to_teaching([ex_embed, ex_label, gamma])\n",
    "\n",
    "        if  False and itt % 100 == 0:\n",
    "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner_random.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, train_answers, True)\n",
    "            #errors_random.append(metrics)   \n",
    "            print(\"##############################\")\n",
    "\n",
    "        if  (itt) % PLOT_INTERVAL == 0:\n",
    "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner_random.predict(validation_embeddings, priorhum_validation_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, test_answers, True)\n",
    "            errors_random.append(metrics['exact_match'])   \n",
    "            print(\"##############################\")\n",
    "    return errors_random, indices_used_random\n",
    "#errors_random, indices_used_random = teach_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSkPt-33wSAp"
   },
   "source": [
    "## Medoids Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpiWrRqwwT94",
    "outputId": "8a72155e-df6a-4be3-a92a-7942c6f8eb9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "def teach_medoids(greedy_gamma = False):\n",
    "    \n",
    "    human_learner_medoid = HumanLearner(None)\n",
    "    errors_medoid = []\n",
    "    data_sizes  = []\n",
    "    indices_used_medoid = []\n",
    "    points_chosen = []\n",
    "    \n",
    "    for itt in range(MAX_SIZE):\n",
    "        if False and itt % 3 == 0:\n",
    "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner_medoid.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, train_answers, True)\n",
    "            #errors_medoid.append(metrics)   \n",
    "            print(\"##############################\")\n",
    "\n",
    "        if itt % PLOT_INTERVAL == 0:\n",
    "            human_learner_medoid = HumanLearner(None)\n",
    "            kmedoids = KMedoids(n_clusters=itt+1, init='k-medoids++').fit(teaching_embeddings)\n",
    "            teaching_indices = kmedoids.medoid_indices_\n",
    "\n",
    "            print(f'New size {itt}')\n",
    "            first_time = True\n",
    "            for teach_ex_idx in teaching_indices:\n",
    "                best_index = teach_ex_idx\n",
    "                if greedy_gamma:\n",
    "                    if itt == 0 or first_time:\n",
    "                        preds_teach = priorhum_teaching_preds\n",
    "                        first_time = False\n",
    "                    else:\n",
    "                        preds_teach = human_learner_medoid.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "                    _, greedy_gamma = get_greedy_gamma(best_index, preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "                    gamma = greedy_gamma\n",
    "                else:\n",
    "                    gamma = optimal_gammas[best_index]\n",
    "                ex_embed = teaching_embeddings[best_index]\n",
    "                ex_label = opt_defer_teaching[best_index]\n",
    "                 #+ (np.random.rand(1)[0])*(1-optimal_gammas[best_index])-(1-optimal_gammas[best_index])/2 # random choice\n",
    "                human_learner_medoid.add_to_teaching([ex_embed, ex_label, gamma])\n",
    "\n",
    "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner_medoid.predict(validation_embeddings, priorhum_validation_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, test_answers, True)\n",
    "            errors_medoid.append(metrics['exact_match'])   \n",
    "            print(\"##############################\")\n",
    "    return errors_medoid, indices_used_medoid\n",
    "#errors_medoid, indices_used_medoid = teach_medoids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZosFDIVUqNbA"
   },
   "source": [
    "## LIME baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jrHGZr_qQkx",
    "outputId": "e94637ba-7ba7-43b9-fc0e-b7cbf0384b8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_improvement_lime(features_covered, xs, indices_used_lime):\n",
    "    error_improvements = []\n",
    "    for i in range(len(xs)):\n",
    "        error_at_i = 0\n",
    "        if i in indices_used_lime:\n",
    "            error_at_i = -10000\n",
    "        for feat_id, feat_val in individual_feature_importance[i].items():\n",
    "            if features_covered[feat_id] == 0:\n",
    "                error_at_i +=  global_feature_importance[feat_id]\n",
    "                    \n",
    "        error_improvements.append(error_at_i)\n",
    "        # get the ball for x\n",
    "        # in this ball how many does the current defer not match the optimal\n",
    "    \n",
    "    best_index = np.argmax(error_improvements)\n",
    "    for feat_id, feat_val in individual_feature_importance[best_index].items():\n",
    "        if features_covered[feat_id] == 0:\n",
    "            features_covered[feat_id] = 1\n",
    "    return error_improvements, features_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yp-wJsPyqOrW",
    "outputId": "3bb61f5b-6ce9-4c8f-84b1-d68ff3070d58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def teach_lime(greedy_gamma = False):\n",
    "    human_learner = HumanLearner(None)\n",
    "    errors_lime = []\n",
    "    data_sizes  = []\n",
    "    indices_used_lime = {}\n",
    "    points_chosen = []\n",
    "    features_covered = {}\n",
    "    for i in range(DATA_DIM):\n",
    "        features_covered[i] = 0\n",
    "\n",
    "    for itt in range(MAX_SIZE):\n",
    "        print(f'New size {itt}')\n",
    "        best_index = -1\n",
    "        # predict with current human learner\n",
    "\n",
    "        error_improvements, features_covered = get_improvement_lime(features_covered, teaching_embeddings[:cutoff_size], indices_used_lime)\n",
    "        print(f'got improvements with max {max(error_improvements)}')\n",
    "        best_index = np.argmax(error_improvements)\n",
    "        indices_used_lime[best_index] =1 # add found element to set used\n",
    "        ex_embed = teaching_embeddings[best_index]\n",
    "        ex_label = opt_defer_teaching[best_index]\n",
    "\n",
    "        if greedy_gamma:\n",
    "            if itt == 0 :\n",
    "                preds_teach = priorhum_teaching_preds\n",
    "            else:\n",
    "                preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "                \n",
    "            _, greedy_gamma = get_greedy_gamma(best_index, preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "            gamma = greedy_gamma\n",
    "        else:\n",
    "            gamma = optimal_gammas[best_index]\n",
    "\n",
    "        #gamma = optimal_gammas[best_index]  #+ (np.random.rand(1)[0])*2*(1-optimal_gammas[best_index])-(1-optimal_gammas[best_index]) # random choice\n",
    "        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n",
    "\n",
    "        if False and itt % 3 == 0:\n",
    "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, train_answers, True)\n",
    "            #errors_lime.append(metrics)   \n",
    "            print(\"##############################\")\n",
    "\n",
    "        if itt % PLOT_INTERVAL == 0:\n",
    "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner.predict(validation_embeddings, priorhum_validation_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, test_answers, True)\n",
    "            errors_lime.append(metrics['exact_match'])   \n",
    "            print(\"##############################\")\n",
    "    return errors_lime, indices_used_lime\n",
    "#errors_lime, indices_used_lime = teach_lime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VhWuzn6CYyT"
   },
   "source": [
    "## Learn AI behavior baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "fZV7k42ICjxJ",
    "outputId": "4c6605ac-5d19-4796-b0de-c32cedbc44a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier, KNeighborsClassifier\n",
    "def teach_learnai(greedy_gamma = False):\n",
    "    human_learner_learnai = HumanLearner(None)\n",
    "    errors_learnai = []\n",
    "    data_sizes  = []\n",
    "    indices_used_learnai = []\n",
    "    points_chosen = []\n",
    "    set_xs = [teaching_embeddings[0]]\n",
    "    set_ys = [ai_teaching_preds_b[0]]\n",
    "    for itt in range(MAX_SIZE):\n",
    "        print(f'New size {itt}')\n",
    "        best_index = 0\n",
    "        best_value = 0\n",
    "        neigh = KNeighborsClassifier(n_neighbors = 1, weights='distance')\n",
    "        random_teach_subset = random.sample(list(range(len(teaching_embeddings))), 500) # used to take gradient steps\n",
    "        random_test_subset = random.sample(list(range(len(teaching_embeddings))), 500) # used to take gradient steps\n",
    "\n",
    "        for j in random_teach_subset:\n",
    "            x_try = teaching_embeddings[j]\n",
    "            y_try = ai_teaching_preds_b[j]\n",
    "            set_xs.append(x_try)\n",
    "            set_ys.append(y_try)\n",
    "            np_set_xs = np.asarray(set_xs)\n",
    "            np_set_ys = np.asarray(set_ys)\n",
    "            neigh = KNeighborsClassifier(n_neighbors = 1, weights='distance')\n",
    "            neigh.fit(np_set_xs, np_set_ys)\n",
    "            acc = neigh.score(np.asarray([teaching_embeddings[kk] for kk in random_test_subset]), np.asarray([ai_teaching_preds_b[kk] for kk in random_test_subset]))\n",
    "            if acc >= best_value:\n",
    "                best_value = acc\n",
    "                best_index = j\n",
    "            set_xs = set_xs[:-1]\n",
    "            set_ys = set_ys[:-1]\n",
    "        print(best_value)\n",
    "        indices_used_learnai.append(best_index)\n",
    "        ex_embed = teaching_embeddings[best_index]\n",
    "        ex_label = opt_defer_teaching[best_index]\n",
    "        \n",
    "        if greedy_gamma:\n",
    "            if itt == 0 :\n",
    "                preds_teach = priorhum_teaching_preds\n",
    "                first_time = False\n",
    "            else:\n",
    "                preds_teach = human_learner_learnai.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "                \n",
    "            _, greedy_gamma = get_greedy_gamma(best_index, preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
    "            gamma = greedy_gamma\n",
    "        else:\n",
    "            gamma = optimal_gammas[best_index]\n",
    "        human_learner_learnai.add_to_teaching([ex_embed, ex_label, gamma])\n",
    "\n",
    "\n",
    "        if False and itt % 3 == 0:\n",
    "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner_learnai.predict(teaching_embeddings, priorhum_teaching_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, train_answers, True)\n",
    "            #errors_learnai.append(metrics)   \n",
    "            print(\"##############################\")\n",
    "\n",
    "        if itt % PLOT_INTERVAL == 0:\n",
    "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
    "            preds_teach = human_learner_learnai.predict(validation_embeddings, priorhum_validation_preds)\n",
    "            _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, test_answers, True)\n",
    "            errors_learnai.append(metrics['exact_match'])   \n",
    "            print(\"##############################\")\n",
    "    return errors_learnai, indices_used_learnai\n",
    "#errors_learnai, indices_used_learnai = teach_learnai()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTR95IRRnEM8"
   },
   "source": [
    "# Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "AEKVWOUPnEM8",
    "outputId": "d7e22dab-2457-4451-cff9-e361ffb0a27f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_predictor = FakeAI(teaching_embeddings, teaching_embeddings, 15, 15,  (2,1), kmeans = None)\n",
    "kmeans_pass = human_predictor.kmeans_pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setting = \"A\"\n",
    "greedy_gamma = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "P1xlqdMg0Hh0",
    "outputId": "9041923a-a3dd-4287-80fa-53f52cad70a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if setting == \"A\":\n",
    "    REJECT_EPSILON = 0.1\n",
    "else:\n",
    "    REJECT_EPSILON = 0.9\n",
    "MAX_TRIALS = 10\n",
    "MAX_SIZE = 50 + 1\n",
    "PLOT_INTERVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cm6xhNkunEM8",
    "outputId": "2165f34c-47be-4af4-a803-f63d988618aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " trial 0  \n",
      " \n",
      "\n",
      "34.83518065351945\n",
      "19.70634806391245\n",
      "human score is 36.27465092845828\n",
      "(0.1220670793148122, {'exact_match': 71.10983158197773, 'f1': 73.02861923578791}, {'exact_match': 88.44339622641405, 'f1': 89.23843005921495}, {'exact_match': 68.69978685030321, 'f1': 70.77482032149594})\n",
      "running our method\n",
      "New size 0\n",
      "got improvements with max 1118\n",
      "####### val eval 0 ###########\n",
      "Coverage is 54.96\n",
      " metrics of system are: {'exact_match': 59.018281272491635, 'f1': 61.87127501548582}\n",
      " metrics of human are: {'exact_match': 51.78103719224711, 'f1': 55.15562561200807}\n",
      " metrics of AI are: {'exact_match': 67.84915308405219, 'f1': 70.0656979692978}\n",
      "##############################\n",
      "New size 1\n",
      "got improvements with max 586\n",
      "New size 2\n",
      "got improvements with max 262\n",
      "New size 3\n",
      "got improvements with max 142\n",
      "New size 4\n",
      "got improvements with max 111\n",
      "New size 5\n",
      "got improvements with max 67\n",
      "####### val eval 5 ###########\n",
      "Coverage is 17.85\n",
      " metrics of system are: {'exact_match': 67.05052540665025, 'f1': 69.2310204584477}\n",
      " metrics of human are: {'exact_match': 55.32258064516084, 'f1': 58.385735261357176}\n",
      " metrics of AI are: {'exact_match': 69.59873839144898, 'f1': 71.58745179617195}\n",
      "##############################\n",
      "New size 6\n",
      "got improvements with max 50\n",
      "New size 7\n",
      "got improvements with max 41\n",
      "New size 8\n",
      "got improvements with max 37\n",
      "New size 9\n",
      "got improvements with max 30\n",
      "New size 10\n",
      "got improvements with max 29\n",
      "####### val eval 10 ###########\n",
      "Coverage is 12.37\n",
      " metrics of system are: {'exact_match': 68.04375989635804, 'f1': 70.15580294795303}\n",
      " metrics of human are: {'exact_match': 59.1385331781134, 'f1': 61.72019184640368}\n",
      " metrics of AI are: {'exact_match': 69.30026281208924, 'f1': 71.34604439608557}\n",
      "##############################\n",
      "New size 11\n",
      "got improvements with max 21\n",
      "New size 12\n",
      "got improvements with max 18\n",
      "New size 13\n",
      "got improvements with max 16\n",
      "New size 14\n",
      "got improvements with max 19\n",
      "New size 15\n",
      "got improvements with max 14\n",
      "####### val eval 15 ###########\n",
      "Coverage is 11.13\n",
      " metrics of system are: {'exact_match': 68.3460486540952, 'f1': 70.44748660820599}\n",
      " metrics of human are: {'exact_match': 61.70763260025793, 'f1': 64.24606084077283}\n",
      " metrics of AI are: {'exact_match': 69.17719468739865, 'f1': 71.22392038180911}\n",
      "##############################\n",
      "New size 16\n",
      "got improvements with max 13\n",
      "New size 17\n",
      "got improvements with max 13\n",
      "New size 18\n",
      "got improvements with max 13\n",
      "New size 19\n",
      "got improvements with max 12\n",
      "New size 20\n",
      "got improvements with max 13\n",
      "####### val eval 20 ###########\n",
      "Coverage is 11.23\n",
      " metrics of system are: {'exact_match': 68.56196919533602, 'f1': 70.6553687608898}\n",
      " metrics of human are: {'exact_match': 63.7179487179479, 'f1': 66.08017909647698}\n",
      " metrics of AI are: {'exact_match': 69.1746392086913, 'f1': 71.23403714717838}\n",
      "##############################\n",
      "New size 21\n",
      "got improvements with max 12\n",
      "New size 22\n",
      "got improvements with max 13\n",
      "New size 23\n",
      "got improvements with max 10\n",
      "New size 24\n",
      "got improvements with max 13\n",
      "New size 25\n",
      "got improvements with max 12\n",
      "####### val eval 25 ###########\n",
      "Coverage is 11.53\n",
      " metrics of system are: {'exact_match': 68.63394270908296, 'f1': 70.72322950242263}\n",
      " metrics of human are: {'exact_match': 64.4194756554299, 'f1': 66.7197749004395}\n",
      " metrics of AI are: {'exact_match': 69.18320859095336, 'f1': 71.24499441231335}\n",
      "##############################\n",
      "New size 26\n",
      "got improvements with max 10\n",
      "New size 27\n",
      "got improvements with max 9\n",
      "New size 28\n",
      "got improvements with max 8\n",
      "New size 29\n",
      "got improvements with max 7\n",
      "New size 30\n",
      "got improvements with max 8\n",
      "####### val eval 30 ###########\n",
      "Coverage is 11.69\n",
      " metrics of system are: {'exact_match': 68.87865265582256, 'f1': 70.96322434968341}\n",
      " metrics of human are: {'exact_match': 66.00985221674796, 'f1': 68.36603003322826}\n",
      " metrics of AI are: {'exact_match': 69.25835370823134, 'f1': 71.30697688186946}\n",
      "##############################\n",
      "New size 31\n",
      "got improvements with max 8\n",
      "New size 32\n",
      "got improvements with max 9\n",
      "New size 33\n",
      "got improvements with max 8\n",
      "New size 34\n",
      "got improvements with max 8\n",
      "New size 35\n",
      "got improvements with max 6\n",
      "####### val eval 35 ###########\n",
      "Coverage is 11.98\n",
      " metrics of system are: {'exact_match': 68.99381027781766, 'f1': 71.07179019055741}\n",
      " metrics of human are: {'exact_match': 66.46634615384535, 'f1': 68.76588508050642}\n",
      " metrics of AI are: {'exact_match': 69.33769419460332, 'f1': 71.3855290379102}\n",
      "##############################\n",
      "New size 36\n",
      "got improvements with max 6\n",
      "New size 37\n",
      "got improvements with max 7\n",
      "New size 38\n",
      "got improvements with max 6\n",
      "New size 39\n",
      "got improvements with max 6\n",
      "New size 40\n",
      "got improvements with max 6\n",
      "####### val eval 40 ###########\n",
      "Coverage is 12.16\n",
      " metrics of system are: {'exact_match': 69.05138908881521, 'f1': 71.12993108042423}\n",
      " metrics of human are: {'exact_match': 66.62721893491046, 'f1': 68.92519268112756}\n",
      " metrics of AI are: {'exact_match': 69.38708620124538, 'f1': 71.43524146184107}\n",
      "##############################\n",
      "New size 41\n",
      "got improvements with max 5\n",
      "New size 42\n",
      "got improvements with max 6\n",
      "New size 43\n",
      "got improvements with max 6\n",
      "New size 44\n",
      "got improvements with max 6\n",
      "New size 45\n",
      "got improvements with max 7\n",
      "####### val eval 45 ###########\n",
      "Coverage is 11.96\n",
      " metrics of system are: {'exact_match': 69.10896789981277, 'f1': 71.2002738292839}\n",
      " metrics of human are: {'exact_match': 67.62936221419895, 'f1': 69.89825898579699}\n",
      " metrics of AI are: {'exact_match': 69.31000654022226, 'f1': 71.37718264794601}\n",
      "##############################\n",
      "New size 46\n",
      "got improvements with max 6\n",
      "New size 47\n",
      "got improvements with max 6\n",
      "New size 48\n",
      "got improvements with max 5\n",
      "New size 49\n",
      "got improvements with max 5\n",
      "New size 50\n",
      "got improvements with max 4\n",
      "####### val eval 50 ###########\n",
      "Coverage is 11.95\n",
      " metrics of system are: {'exact_match': 69.18094141355971, 'f1': 71.26886035414864}\n",
      " metrics of human are: {'exact_match': 68.07228915662569, 'f1': 70.31557084991877}\n",
      " metrics of AI are: {'exact_match': 69.33137158737932, 'f1': 71.39820975557264}\n",
      "##############################\n",
      "running lime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▎                                                                | 2000/14631 [25:35<2:35:18,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size 0\n",
      "got improvements with max 11.266205090168459\n",
      "####### val eval 0 ###########\n",
      "Coverage is 58.70\n",
      " metrics of system are: {'exact_match': 56.97423348207851, 'f1': 59.900903745240015}\n",
      " metrics of human are: {'exact_match': 48.822952427660496, 'f1': 52.34181962711611}\n",
      " metrics of AI are: {'exact_match': 68.56047403276379, 'f1': 70.6453948688751}\n",
      "##############################\n",
      "New size 1\n",
      "got improvements with max 10.46511882663776\n",
      "New size 2\n",
      "got improvements with max 10.191016633783246\n",
      "New size 3\n",
      "got improvements with max 8.4525611151435\n",
      "New size 4\n",
      "got improvements with max 8.418926532222404\n",
      "New size 5\n",
      "got improvements with max 8.306887286572854\n",
      "####### val eval 5 ###########\n",
      "Coverage is 24.77\n",
      " metrics of system are: {'exact_match': 64.38750539801345, 'f1': 66.8314477635185}\n",
      " metrics of human are: {'exact_match': 48.51830331202761, 'f1': 52.17924097035504}\n",
      " metrics of AI are: {'exact_match': 69.61347110600829, 'f1': 71.65663871090364}\n",
      "##############################\n",
      "New size 6\n",
      "got improvements with max 8.140446123132389\n",
      "New size 7\n",
      "got improvements with max 7.951295838667488\n",
      "New size 8\n",
      "got improvements with max 7.486989969865272\n",
      "New size 9\n",
      "got improvements with max 7.269639192567289\n",
      "New size 10\n",
      "got improvements with max 6.79618251056205\n",
      "####### val eval 10 ###########\n",
      "Coverage is 13.85\n",
      " metrics of system are: {'exact_match': 66.41715848567718, 'f1': 68.6561858829603}\n",
      " metrics of human are: {'exact_match': 51.45530145530092, 'f1': 54.843037464484865}\n",
      " metrics of AI are: {'exact_match': 68.8220551378445, 'f1': 70.87644465966427}\n",
      "##############################\n",
      "New size 11\n",
      "got improvements with max 6.791670730675422\n",
      "New size 12\n",
      "got improvements with max 6.785000891156286\n",
      "New size 13\n",
      "got improvements with max 6.623736153430807\n",
      "New size 14\n",
      "got improvements with max 6.599543835967366\n",
      "New size 15\n",
      "got improvements with max 6.486124530652393\n",
      "####### val eval 15 ###########\n",
      "Coverage is 9.50\n",
      " metrics of system are: {'exact_match': 67.05052540665025, 'f1': 69.2864359428624}\n",
      " metrics of human are: {'exact_match': 49.242424242423496, 'f1': 53.06187231683894}\n",
      " metrics of AI are: {'exact_match': 68.91999363766492, 'f1': 70.98966673547811}\n",
      "##############################\n",
      "New size 16\n",
      "got improvements with max 6.371785363966219\n",
      "New size 17\n",
      "got improvements with max 6.326532040726609\n",
      "New size 18\n",
      "got improvements with max 6.22482540833933\n",
      "New size 19\n",
      "got improvements with max 6.0316339130889345\n",
      "New size 20\n",
      "got improvements with max 6.001626779865974\n",
      "####### val eval 20 ###########\n",
      "Coverage is 7.07\n",
      " metrics of system are: {'exact_match': 67.56873470562823, 'f1': 69.77919687910675}\n",
      " metrics of human are: {'exact_match': 49.89816700610896, 'f1': 54.1432426977114}\n",
      " metrics of AI are: {'exact_match': 68.91263940520436, 'f1': 70.96836253943275}\n",
      "##############################\n",
      "New size 21\n",
      "got improvements with max 5.990440868865754\n",
      "New size 22\n",
      "got improvements with max 5.8667651709218\n",
      "New size 23\n",
      "got improvements with max 5.8596346941974335\n",
      "New size 24\n",
      "got improvements with max 5.839108915304059\n",
      "New size 25\n",
      "got improvements with max 5.702805954614938\n",
      "####### val eval 25 ###########\n",
      "Coverage is 6.58\n",
      " metrics of system are: {'exact_match': 67.69828703037273, 'f1': 69.89759475229125}\n",
      " metrics of human are: {'exact_match': 49.45295404813896, 'f1': 53.66838568258442}\n",
      " metrics of AI are: {'exact_match': 68.98305084745752, 'f1': 71.04039113824741}\n",
      "##############################\n",
      "New size 26\n",
      "got improvements with max 5.682889094366152\n",
      "New size 27\n",
      "got improvements with max 5.418295658537898\n",
      "New size 28\n",
      "got improvements with max 5.3485073595082016\n",
      "New size 29\n",
      "got improvements with max 5.3168160445054\n",
      "New size 30\n",
      "got improvements with max 5.30950294390087\n",
      "####### val eval 30 ###########\n",
      "Coverage is 6.25\n",
      " metrics of system are: {'exact_match': 67.78465524686905, 'f1': 69.96779558505148}\n",
      " metrics of human are: {'exact_match': 50.46082949308639, 'f1': 54.61206783900059}\n",
      " metrics of AI are: {'exact_match': 68.93904498694907, 'f1': 70.9910392272725}\n",
      "##############################\n",
      "New size 31\n",
      "got improvements with max 5.283364258579907\n",
      "New size 32\n",
      "got improvements with max 5.273326275966042\n",
      "New size 33\n",
      "got improvements with max 5.263551395145052\n",
      "New size 34\n",
      "got improvements with max 5.088688985068615\n",
      "New size 35\n",
      "got improvements with max 5.071260563182728\n",
      "####### val eval 35 ###########\n",
      "Coverage is 5.40\n",
      " metrics of system are: {'exact_match': 67.87102346336539, 'f1': 70.03169066142127}\n",
      " metrics of human are: {'exact_match': 48.7999999999987, 'f1': 52.94682507359578}\n",
      " metrics of AI are: {'exact_match': 68.9592209373097, 'f1': 71.00655745926576}\n",
      "##############################\n",
      "New size 36\n",
      "got improvements with max 5.0493985064408\n",
      "New size 37\n",
      "got improvements with max 4.9279771303691255\n",
      "New size 38\n",
      "got improvements with max 4.712584534224294\n",
      "New size 39\n",
      "got improvements with max 4.685387929436242\n",
      "New size 40\n",
      "got improvements with max 4.6292175624947305\n",
      "####### val eval 40 ###########\n",
      "Coverage is 4.00\n",
      " metrics of system are: {'exact_match': 67.9717863826111, 'f1': 70.09126109794296}\n",
      " metrics of human are: {'exact_match': 47.84172661870331, 'f1': 51.59892961259635}\n",
      " metrics of AI are: {'exact_match': 68.81091617933713, 'f1': 70.86212151973422}\n",
      "##############################\n",
      "New size 41\n",
      "got improvements with max 4.480522863408746\n",
      "New size 42\n",
      "got improvements with max 4.4221200291366864\n",
      "New size 43\n",
      "got improvements with max 4.300659708503197\n",
      "New size 44\n",
      "got improvements with max 4.267366809858458\n",
      "New size 45\n",
      "got improvements with max 4.160025751128747\n",
      "####### val eval 45 ###########\n",
      "Coverage is 3.45\n",
      " metrics of system are: {'exact_match': 68.05815459910743, 'f1': 70.17574933737453}\n",
      " metrics of human are: {'exact_match': 47.91666666666467, 'f1': 51.833778449609056}\n",
      " metrics of AI are: {'exact_match': 68.77888772923801, 'f1': 70.83208943176295}\n",
      "##############################\n",
      "New size 46\n",
      "got improvements with max 4.116543719316006\n",
      "New size 47\n",
      "got improvements with max 4.09210361990208\n",
      "New size 48\n",
      "got improvements with max 4.051968415799175\n",
      "New size 49\n",
      "got improvements with max 3.9203793123664727\n",
      "New size 50\n",
      "got improvements with max 3.8273437261191683\n",
      "####### val eval 50 ###########\n",
      "Coverage is 3.41\n",
      " metrics of system are: {'exact_match': 68.1013387073556, 'f1': 70.21454648859428}\n",
      " metrics of human are: {'exact_match': 48.523206751052804, 'f1': 52.32112585614417}\n",
      " metrics of AI are: {'exact_match': 68.79284649776443, 'f1': 70.84654957203547}\n",
      "##############################\n",
      "running medoid\n",
      "New size 0\n",
      "####### val eval 0 ###########\n",
      "Coverage is 76.94\n",
      " metrics of system are: {'exact_match': 51.40348351806528, 'f1': 54.73961912571012}\n",
      " metrics of human are: {'exact_match': 45.83723105706259, 'f1': 49.61525471491494}\n",
      " metrics of AI are: {'exact_match': 69.97503121098583, 'f1': 71.83682747508594}\n",
      "##############################\n",
      "New size 5\n",
      "####### val eval 5 ###########\n",
      "Coverage is 32.36\n",
      " metrics of system are: {'exact_match': 63.048798042320335, 'f1': 65.5650633488618}\n",
      " metrics of human are: {'exact_match': 49.77758007117416, 'f1': 53.42056014952201}\n",
      " metrics of AI are: {'exact_match': 69.39774420089365, 'f1': 71.37498954424719}\n",
      "##############################\n",
      "New size 10\n",
      "####### val eval 10 ###########\n",
      "Coverage is 15.59\n",
      " metrics of system are: {'exact_match': 65.25118756297672, 'f1': 67.54243944853201}\n",
      " metrics of human are: {'exact_match': 42.28993536472722, 'f1': 46.136653358027345}\n",
      " metrics of AI are: {'exact_match': 69.49181446111857, 'f1': 71.49579318932615}\n",
      "##############################\n",
      "New size 15\n",
      "####### val eval 15 ###########\n",
      "Coverage is 10.57\n",
      " metrics of system are: {'exact_match': 67.06492010939965, 'f1': 69.20578975923111}\n",
      " metrics of human are: {'exact_match': 44.55040871934544, 'f1': 47.91603446506418}\n",
      " metrics of AI are: {'exact_match': 69.72477064220172, 'f1': 71.72094835989395}\n",
      "##############################\n",
      "New size 20\n",
      "####### val eval 20 ###########\n",
      "Coverage is 9.28\n",
      " metrics of system are: {'exact_match': 67.06492010939965, 'f1': 69.2457061055472}\n",
      " metrics of human are: {'exact_match': 50.38759689922402, 'f1': 53.36722570077758}\n",
      " metrics of AI are: {'exact_match': 68.77181847032678, 'f1': 70.87084413491498}\n",
      "##############################\n",
      "New size 25\n",
      "####### val eval 25 ###########\n",
      "Coverage is 6.38\n",
      " metrics of system are: {'exact_match': 67.62631351662579, 'f1': 69.74442466715554}\n",
      " metrics of human are: {'exact_match': 53.04740406320422, 'f1': 55.810835697560805}\n",
      " metrics of AI are: {'exact_match': 68.61931119311183, 'f1': 70.69346831929725}\n",
      "##############################\n",
      "New size 30\n",
      "####### val eval 30 ###########\n",
      "Coverage is 8.98\n",
      " metrics of system are: {'exact_match': 67.55434000287885, 'f1': 69.74789350122224}\n",
      " metrics of human are: {'exact_match': 51.28205128205046, 'f1': 54.72761233056862}\n",
      " metrics of AI are: {'exact_match': 69.16020876166365, 'f1': 71.23020497528319}\n",
      "##############################\n",
      "New size 35\n",
      "####### val eval 35 ###########\n",
      "Coverage is 4.16\n",
      " metrics of system are: {'exact_match': 67.56873470562823, 'f1': 69.66833436344265}\n",
      " metrics of human are: {'exact_match': 42.56055363321652, 'f1': 45.73188559878991}\n",
      " metrics of AI are: {'exact_match': 68.65425052568328, 'f1': 70.70733011186323}\n",
      "##############################\n",
      "New size 40\n",
      "####### val eval 40 ###########\n",
      "Coverage is 4.62\n",
      " metrics of system are: {'exact_match': 68.17331222110253, 'f1': 70.25550905702396}\n",
      " metrics of human are: {'exact_match': 51.09034267912613, 'f1': 54.00679257985547}\n",
      " metrics of AI are: {'exact_match': 69.00090552369443, 'f1': 71.0426865380337}\n",
      "##############################\n",
      "New size 45\n"
     ]
    }
   ],
   "source": [
    "scores_ours = []\n",
    "scores_medoid = []\n",
    "scores_random = []\n",
    "scores_aibaseline = []\n",
    "scores_oracle = []\n",
    "scores_lime = []\n",
    "scores_human = []\n",
    "for trial in range(MAX_TRIALS):\n",
    "    # Get Human Predictions\n",
    "    not_found_good_config = True\n",
    "    print(f' \\n \\n trial {trial}  \\n \\n')\n",
    "    while not_found_good_config:\n",
    "        hum_teaching_preds = []\n",
    "        hum_validation_preds = []\n",
    "        priorhum_teaching_preds = []\n",
    "        priorhum_validation_preds = []\n",
    "        if setting == \"A\":\n",
    "            human_predictor = FakeAI(teaching_embeddings, teaching_embeddings, 15, 15,  (1,1), kmeans = kmeans_pass)\n",
    "        else:\n",
    "            human_predictor = FakeAI(teaching_embeddings, teaching_embeddings, 15, 15,  (2,1), kmeans = kmeans_pass)\n",
    "        hum_teaching_preds = []\n",
    "        hum_validation_preds = []\n",
    "        priorhum_teaching_preds = []\n",
    "        priorhum_validation_preds = []\n",
    "        hum_teaching_preds_b = human_predictor.predict_right_wrong(teaching_embeddings, teaching_embeddings)\n",
    "        hum_validation_preds_b = human_predictor.predict_right_wrong(validation_embeddings, validation_embeddings)\n",
    "        for i in range(len(hum_teaching_preds_b)):\n",
    "            if hum_teaching_preds_b[i] == 1:\n",
    "                hum_teaching_preds.append(train_answers[i])\n",
    "            else:\n",
    "                sents = nltk.sent_tokenize(train_raw_passages[i].replace(\"#$\",\"</br> </br>\"))\n",
    "                rand_sent = random.randint(0,len(sents)-1)\n",
    "                hum_teaching_preds.append(sents[rand_sent])\n",
    "        for i in range(len(hum_validation_preds_b)):\n",
    "            if hum_validation_preds_b[i] == 1:\n",
    "                hum_validation_preds.append(test_answers[i])\n",
    "            else:\n",
    "                sents = nltk.sent_tokenize(test_raw_passages[i].replace(\"#$\",\"</br> </br>\"))\n",
    "                rand_sent = random.randint(0,len(sents)-1)\n",
    "                hum_validation_preds.append(sents[rand_sent])\n",
    "        priorhum_teaching_preds = human_predictor.prior_rejector(teaching_embeddings, teaching_embeddings, REJECT_EPSILON)\n",
    "        priorhum_validation_preds = human_predictor.prior_rejector(validation_embeddings, validation_embeddings, REJECT_EPSILON)\n",
    "\n",
    "        # Get AI predictions\n",
    "        ai_teaching_preds = []\n",
    "        ai_validation_preds = []\n",
    "        if setting == \"A\":\n",
    "            fakeai = FakeAI(teaching_embeddings, teaching_embeddings, 15, 15, (2,1), kmeans = human_predictor.kmeans_pass )\n",
    "        else:\n",
    "            fakeai = FakeAI(teaching_embeddings, teaching_embeddings, 15, 15, (1,1), kmeans = human_predictor.kmeans_pass )\n",
    "        ai_teaching_preds_b = fakeai.predict_right_wrong(teaching_embeddings, teaching_embeddings)\n",
    "        ai_validation_preds_b = fakeai.predict_right_wrong(validation_embeddings, validation_embeddings)\n",
    "        ai_teaching_preds = []\n",
    "        for i in range(len(ai_teaching_preds_b)):\n",
    "            if ai_teaching_preds_b[i] == 1:\n",
    "                ai_teaching_preds.append(train_answers[i])\n",
    "            else:\n",
    "                sents = nltk.sent_tokenize(train_raw_passages[i].replace(\"#$\",\"</br> </br>\"))\n",
    "                rand_sent = random.randint(0,len(sents)-1)\n",
    "                ai_teaching_preds.append(sents[rand_sent])\n",
    "        ai_validation_preds = []\n",
    "        for i in range(len(ai_validation_preds_b)):\n",
    "            if ai_validation_preds_b[i] == 1:\n",
    "                ai_validation_preds.append(test_answers[i])\n",
    "            else:\n",
    "                sents = nltk.sent_tokenize(test_raw_passages[i].replace(\"#$\",\"</br> </br>\"))\n",
    "                rand_sent = random.randint(0,len(sents)-1)\n",
    "                ai_validation_preds.append(sents[rand_sent])\n",
    "\n",
    "        # Optimal deferall decisions\n",
    "        opt_defer_teaching = []\n",
    "        opt_defer_validation = []\n",
    "        clusts_p_ai = fakeai.kmeans_pass.predict(teaching_embeddings)\n",
    "        clusts_p_hum = human_predictor.kmeans_pass.predict(teaching_embeddings)\n",
    "        for ex in range(len(hum_teaching_preds)):\n",
    "            corr_ai = fakeai.clust_err_p[clusts_p_ai[ex]]\n",
    "            corr_hum = human_predictor.clust_err_p[clusts_p_hum[ex]]\n",
    "            if corr_ai >= corr_hum:\n",
    "                opt_defer_teaching.append(1)\n",
    "            else:\n",
    "                opt_defer_teaching.append(0)\n",
    "        clusts_p_ai = fakeai.kmeans_pass.predict(validation_embeddings)\n",
    "        clusts_p_hum = human_predictor.kmeans_pass.predict(validation_embeddings)\n",
    "        for ex in range(len(hum_validation_preds)):\n",
    "            corr_ai = fakeai.clust_err_p[clusts_p_ai[ex]]\n",
    "            corr_hum = human_predictor.clust_err_p[clusts_p_hum[ex]]\n",
    "            if corr_ai >= corr_hum:\n",
    "                opt_defer_validation.append(1)\n",
    "            else:\n",
    "                opt_defer_validation.append(0)\n",
    "\n",
    "        optimal_score = compute_metrics(hum_validation_preds, ai_validation_preds, opt_defer_validation, test_answers)\n",
    "        prior_score = compute_metrics(hum_validation_preds, ai_validation_preds, priorhum_validation_preds, test_answers)\n",
    "        prior_score = prior_score[1]['exact_match']\n",
    "\n",
    "        human_score = compute_metrics(hum_validation_preds, ai_validation_preds, [0]*len(ai_validation_preds), test_answers)\n",
    "        ai_score = compute_metrics(hum_validation_preds, ai_validation_preds, [1]*len(ai_validation_preds), test_answers)\n",
    "\n",
    "        hum = human_score[1]['exact_match']\n",
    "        opt = optimal_score[1]['exact_match']\n",
    "        print(opt-hum)\n",
    "        print(opt-prior_score)\n",
    "        if (opt - hum) >= 12 and (opt - prior_score) >= 14:\n",
    "            not_found_good_config = False\n",
    "            print(\"human score is \" + str(human_score[1]['exact_match']))\n",
    "            print(optimal_score)\n",
    "\n",
    "        else:\n",
    "            print(\"trying again\")\n",
    "    scores_human.append(human_score[1]['exact_match'])\n",
    "    scores_oracle.append(optimal_score[1]['exact_match'])\n",
    "    if not greedy_gamma:\n",
    "        optimal_gammas = get_optimal_gammas()\n",
    "    else:\n",
    "        optimal_gammas = [1]*len(teaching_embeddings)\n",
    "    print(\"running our method\")\n",
    "    if greedy_gamma:\n",
    "        errors, indices_used = teach_ours_doublegreedy()\n",
    "\n",
    "    else:\n",
    "        errors, indices_used = teach_ours(False)\n",
    "               \n",
    "    print(\"running lime\")\n",
    "    DATA_DIM = teaching_embeddings.shape[1]\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(teaching_embeddings, discretize_continuous= False)\n",
    "    global_feature_importance = {}\n",
    "    cutoff_size = min(2000,len(teaching_embeddings))\n",
    "    for i in range(DATA_DIM):\n",
    "        global_feature_importance[i] = 0\n",
    "    individual_feature_importance = []\n",
    "    with tqdm(total=len(teaching_embeddings)) as pbar:\n",
    "        for ex in range(cutoff_size):\n",
    "            exp = explainer.explain_instance(teaching_embeddings[ex], fakeai.predict_proba_encoded)\n",
    "            feat_weights = exp.local_exp[1]\n",
    "            dic_feat_weights = {}\n",
    "            for j in range(len(feat_weights)):\n",
    "                dic_feat_weights[feat_weights[j][0]] = abs(feat_weights[j][1])\n",
    "                global_feature_importance[feat_weights[j][0]] += abs(feat_weights[j][1])\n",
    "            individual_feature_importance.append(dic_feat_weights)\n",
    "            pbar.update(1)\n",
    "\n",
    "    for i in range(DATA_DIM):\n",
    "        global_feature_importance[i] = math.sqrt(global_feature_importance[i])\n",
    "    errors_lime, indices_used_lime= teach_lime(greedy_gamma)\n",
    "    \n",
    "    print(\"running medoid\")\n",
    "    errors_medoid, indices_used_medoid = teach_medoids(greedy_gamma)\n",
    "    \n",
    "    print(\"running random\")\n",
    "    errors_random, indices_used_random = teach_random(greedy_gamma)\n",
    "        \n",
    "    print(\"running learnai\")\n",
    "    errors_learnai, indices_used_learnai = teach_learnai(greedy_gamma)\n",
    "\n",
    "    errors.insert(0, prior_score)\n",
    "    errors_learnai.insert(0, prior_score)\n",
    "    errors_medoid.insert(0, prior_score)\n",
    "    errors_random.insert(0, prior_score)\n",
    "    errors_lime.insert(0, prior_score)\n",
    "\n",
    "    scores_ours.append(errors)\n",
    "    scores_aibaseline.append(errors_learnai)\n",
    "    scores_medoid.append(errors_medoid)\n",
    "    scores_random.append(errors_random)\n",
    "    scores_lime.append(errors_lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_medoid, indices_used_medoid = teach_medoids(greedy_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(hum_validation_preds, ai_validation_preds, [1]*len(ai_validation_preds), test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, indices_used = teach_ours_doublegreedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHmJJilnnEM_"
   },
   "source": [
    "# Result plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnoy3pjUxmcL"
   },
   "outputs": [],
   "source": [
    "!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "NqQQCgQnzA58",
    "outputId": "9dd8add9-fa52-47f9-d4c5-07cba2d32937"
   },
   "outputs": [],
   "source": [
    "results = [scores_ours,scores_medoid,scores_random,scores_aibaseline,scores_lime,scores_human,scores_oracle]\n",
    "#pickle.dump(results,open(\"results_setB_10.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1VjtB_penEM_",
    "outputId": "91b22ebf-9215-407b-f72a-9016925539e0"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "def get_conf_interval(arr):\n",
    "    alpha_level = 0.4\n",
    "    err  = st.t.interval(alpha_level, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))[1]/2  - st.t.interval(alpha_level, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))[0]/2 \n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KA6VVLmweJT"
   },
   "outputs": [],
   "source": [
    "scores_oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "nZLLLaEtnEM_",
    "outputId": "4c309a33-f506-4d45-b339-79f40196d9d0"
   },
   "outputs": [],
   "source": [
    "\n",
    "teaching_sizes = [i*PLOT_INTERVAL for i in range(21)]\n",
    "actual_max_trials = len(scores_ours) \n",
    "\n",
    "avgs_rand = [np.average([ scores_oracle[triall] - scores_ours[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "stds_rand = [get_conf_interval([scores_oracle[triall] - scores_ours[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "plt.errorbar(teaching_sizes,  avgs_rand, yerr=stds_rand, marker = \"o\",  label=f'DOUBLE-GREEDY (Ours)')\n",
    "\n",
    "\n",
    "avgs_rand = [np.average([scores_oracle[triall] - scores_medoid[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "stds_rand = [get_conf_interval([ scores_oracle[triall] -scores_medoid[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "plt.errorbar(teaching_sizes,  avgs_rand, yerr=stds_rand, marker = \"s\",   label=f'K-Medoids')\n",
    "\n",
    "avgs_rand = [np.average([scores_oracle[triall]- scores_aibaseline[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "stds_rand = [get_conf_interval([scores_oracle[triall] -scores_aibaseline[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "plt.errorbar(teaching_sizes,  avgs_rand,yerr=stds_rand, marker = \"*\",   label=f'AI-Behavior')\n",
    "\n",
    "\n",
    "avgs_rand = [np.average([scores_oracle[triall] - scores_random[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "stds_rand = [get_conf_interval([scores_oracle[triall] -scores_random[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#plt.errorbar(list(range(1,len(teaching_sizes)+1)),  avgs_rand, yerr=stds_rand, label=f'random')\n",
    "plt.errorbar(teaching_sizes,  avgs_rand,yerr=stds_rand, marker = \"v\",  label=f'Random')\n",
    "\n",
    "avgs_rand = [np.average([scores_oracle[triall] - scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "stds_rand = [get_conf_interval([scores_oracle[triall] -scores_lime[triall][i] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#plt.errorbar(list(range(1,len(teaching_sizes)+1)),  avgs_rand, yerr=stds_rand, label=f'random')\n",
    "plt.errorbar(teaching_sizes,  avgs_rand,yerr=stds_rand, marker = \"+\",  label=f'LIME')\n",
    "\n",
    "avgs_rand = [np.average([scores_oracle[triall] - scores_human[triall] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "stds_rand = [get_conf_interval([scores_oracle[triall] -scores_human[triall] for triall in range(actual_max_trials)]) for i in range(len(teaching_sizes))]\n",
    "#plt.errorbar(list(range(1,len(teaching_sizes)+1)),  avgs_rand, yerr=stds_rand, label=f'random')\n",
    "plt.errorbar(teaching_sizes,  avgs_rand,yerr=stds_rand, marker = \"x\",  label=f'Human alone')\n",
    "\n",
    "'''\n",
    "plt.errorbar(teaching_sizes,  errors[:len(teaching_sizes)],  label=f'Ours')\n",
    "plt.errorbar(teaching_sizes,  errors_medoid[:len(teaching_sizes)],  label=f'Medoids')\n",
    "plt.errorbar(teaching_sizes,  errors_random[:len(teaching_sizes)],  label=f'Random')\n",
    "plt.errorbar(teaching_sizes,  errors_lime[:len(teaching_sizes)],  label=f'Lime')\n",
    "'''\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left()   \n",
    "plt.grid()\n",
    "plt.legend(fontsize='large')\n",
    "plt.legend()\n",
    "plt.ylabel('Difference to Oracle Accuracy',  fontsize='x-large')\n",
    "plt.xlabel('Teaching set size', fontsize='x-large')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 5\n",
    "fig_size[1] = 4\n",
    "plt.savefig(\"teaching_complexity_A_3.pdf\", dpi = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UP1CACu3irWL",
    "5WSnSiY1dF2E",
    "AK9JLhs-97wO",
    "UpcZrrMcwNWP",
    "k-L_wImhCL-o",
    "rBHrWz39CjhT",
    "C2Ch46jJttQL",
    "MSkPt-33wSAp",
    "ZosFDIVUqNbA"
   ],
   "machine_shape": "hm",
   "name": "hotpotqa_teaching_exp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06985fc128644e649774167c580e38be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b773166041b4b52bc968e8da555d235": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0babc95d3ffa467cbdb307e9f691c077": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_749afa67c4554b01accdfdef13c8dac5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0d0376851b4441fb30903e55f5aa78a",
      "value": 1
     }
    },
    "0c77e74c032d4a4884daecd92d619a72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18c16d656a064c248e298ead75564043": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06985fc128644e649774167c580e38be",
      "placeholder": "​",
      "style": "IPY_MODEL_a7346f15005d4f2fa88bf5938b5a041d",
      "value": " 306M/306M [00:21&lt;00:00, 14.1MB/s]"
     }
    },
    "1adac33380de4121aa3593e2e15c9595": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bfadc5a51cd47068be189674f9d3c49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e2d23dc4f9b48d39811624d0b6e54ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "214439042c384f999287cef480f956ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f01356e5ed8e4f9991fe6839ae1da8d5",
      "placeholder": "​",
      "style": "IPY_MODEL_d363ebd45d2d4385acdf720c624d52b3",
      "value": " 566M/566M [00:18&lt;00:00, 30.0MB/s]"
     }
    },
    "2d9c589f2668480cac427163dd8fa541": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eff7d36b95474bf5828673bad75a7c3c",
       "IPY_MODEL_9e54490ae0d846ef84340bc0cc16635f"
      ],
      "layout": "IPY_MODEL_0c77e74c032d4a4884daecd92d619a72"
     }
    },
    "3111d5456c3f4efd9c94c19c55560eb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "365424c612434daf9945229fec2bc6fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36e6d5888db0417b847ab7ec64f71c8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39248cca6ba14781819262c79197f46b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3d9a9ded626438690685b3b3096488a",
      "placeholder": "​",
      "style": "IPY_MODEL_f81a8ea5bca1475da4fba7e9a03316ce",
      "value": " 46.3M/46.3M [00:04&lt;00:00, 11.1MB/s]"
     }
    },
    "3b42603b8b1c4ac2812068485fc4a246": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44f309612f9d4a36b103c26d87573bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4be8038b99994c81a6c2dddfea661edd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a93568dd97de42b6845d006ffd14f06e",
      "max": 7405,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ecf56216555b43848a1e2957b3b70255",
      "value": 7405
     }
    },
    "50aef972bd6649be9f8cd99233271f05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50ca82f1f55c451689146981550dfb77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "516c2bfcb0024f618dd68e6ffb888e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e2d23dc4f9b48d39811624d0b6e54ba",
      "max": 566426227,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f483a4688d0740e7b0ef2231cbdd4d74",
      "value": 566426227
     }
    },
    "541d96be93914f69b66376ba74a99d37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef2a247862bb49ef8c83c5cd664a15e3",
       "IPY_MODEL_18c16d656a064c248e298ead75564043"
      ],
      "layout": "IPY_MODEL_1bfadc5a51cd47068be189674f9d3c49"
     }
    },
    "5a2073f8ba0a41e9ae41d8e63f97127c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5e5c83c1ad964b52ab3f5ab294d15b6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "609215891e394b95b7873f317d45dea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "66ff3b0230c34be18879e855bdfbc0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ef35c274a7a4173b901537b50fa95b2",
      "placeholder": "​",
      "style": "IPY_MODEL_f34227be34db469e95cfd1f95a225e18",
      "value": " 6.42k/? [00:00&lt;00:00, 28.5kB/s]"
     }
    },
    "678521f6e22e45c4bb346376c3a2d135": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_516c2bfcb0024f618dd68e6ffb888e2f",
       "IPY_MODEL_214439042c384f999287cef480f956ce"
      ],
      "layout": "IPY_MODEL_e1c3a4da07cb4d3b9ea4c38c321f3a49"
     }
    },
    "6818dcd1957141039f043f1a4accca29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb3d3a49d66542fe935906ef08b52ff0",
       "IPY_MODEL_39248cca6ba14781819262c79197f46b"
      ],
      "layout": "IPY_MODEL_c916e760a9514b17ae128559eed80c0c"
     }
    },
    "70c284ee211a4e7db734dd90216b1a42": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "749afa67c4554b01accdfdef13c8dac5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "768df23dfaf447d080e845b4c1bd08bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0babc95d3ffa467cbdb307e9f691c077",
       "IPY_MODEL_85585db43ae147ef90fb12f3f1eef1e5"
      ],
      "layout": "IPY_MODEL_fb07f93cc8624594b41e83607be0dda9"
     }
    },
    "76dbc1405ff745928737f59cae06ad1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c17e8380dc44d00baec2a3c181e75cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d45c3d7c001432598703f1d9b0a11ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca3799c46c654e4389e33a2fcea86700",
       "IPY_MODEL_8af8ee76afcc4fe08a7155e8aaf94761"
      ],
      "layout": "IPY_MODEL_afc87a4a21974707bf95c4e3c6502d3e"
     }
    },
    "841c89052af64248bb19965425580559": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "85585db43ae147ef90fb12f3f1eef1e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9177d2dc568643a5a949a96b804dfa2d",
      "placeholder": "​",
      "style": "IPY_MODEL_88118d3cab034266b4dbfbe6f0600e0e",
      "value": " 90447/0 [00:25&lt;00:00, 3517.28 examples/s]"
     }
    },
    "858e9646d78242bdb868033fd0cba5d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9949e54b38cb491d9caad7c4850ecb0a",
      "max": 90447,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef228b4e20544802a374962a9278d5c1",
      "value": 90447
     }
    },
    "88118d3cab034266b4dbfbe6f0600e0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8af8ee76afcc4fe08a7155e8aaf94761": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c17e8380dc44d00baec2a3c181e75cb",
      "placeholder": "​",
      "style": "IPY_MODEL_3111d5456c3f4efd9c94c19c55560eb4",
      "value": " 7405/0 [00:01&lt;00:00, 343.41 examples/s]"
     }
    },
    "8c6138961893478abcaa77cfa507ba21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ef35c274a7a4173b901537b50fa95b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9177d2dc568643a5a949a96b804dfa2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9208247da78a467195447352a5e5db1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9949e54b38cb491d9caad7c4850ecb0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e2b8131630f4198b6aa38a0ad71b309": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4be8038b99994c81a6c2dddfea661edd",
       "IPY_MODEL_a46013a5ac134dd5822cfb735b272dc9"
      ],
      "layout": "IPY_MODEL_70c284ee211a4e7db734dd90216b1a42"
     }
    },
    "9e54490ae0d846ef84340bc0cc16635f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9208247da78a467195447352a5e5db1b",
      "placeholder": "​",
      "style": "IPY_MODEL_3b42603b8b1c4ac2812068485fc4a246",
      "value": " 5.93k/? [00:00&lt;00:00, 151kB/s]"
     }
    },
    "9ee4989788e84c019b33605078607446": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3d9a9ded626438690685b3b3096488a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a46013a5ac134dd5822cfb735b272dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36e6d5888db0417b847ab7ec64f71c8e",
      "placeholder": "​",
      "style": "IPY_MODEL_44f309612f9d4a36b103c26d87573bcd",
      "value": " 7405/7405 [00:24&lt;00:00, 303.40ex/s]"
     }
    },
    "a67f65fdf2734482b6b760f2757dd435": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffbcead0b8bf4e1da8e4b029dd387eac",
       "IPY_MODEL_66ff3b0230c34be18879e855bdfbc0dd"
      ],
      "layout": "IPY_MODEL_5e5c83c1ad964b52ab3f5ab294d15b6a"
     }
    },
    "a7346f15005d4f2fa88bf5938b5a041d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a93568dd97de42b6845d006ffd14f06e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afc87a4a21974707bf95c4e3c6502d3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0d0376851b4441fb30903e55f5aa78a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c916e760a9514b17ae128559eed80c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca3799c46c654e4389e33a2fcea86700": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_365424c612434daf9945229fec2bc6fb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50ca82f1f55c451689146981550dfb77",
      "value": 1
     }
    },
    "cb3d3a49d66542fe935906ef08b52ff0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c6138961893478abcaa77cfa507ba21",
      "max": 46320117,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a2073f8ba0a41e9ae41d8e63f97127c",
      "value": 46320117
     }
    },
    "cced9717f2db4828a1eab405ccfe26bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_858e9646d78242bdb868033fd0cba5d5",
       "IPY_MODEL_d5d200b2a06f4177a0bb7fad1fb5a487"
      ],
      "layout": "IPY_MODEL_50aef972bd6649be9f8cd99233271f05"
     }
    },
    "d363ebd45d2d4385acdf720c624d52b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5d200b2a06f4177a0bb7fad1fb5a487": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ee4989788e84c019b33605078607446",
      "placeholder": "​",
      "style": "IPY_MODEL_0b773166041b4b52bc968e8da555d235",
      "value": " 90447/90447 [00:48&lt;00:00, 1852.76ex/s]"
     }
    },
    "e1c3a4da07cb4d3b9ea4c38c321f3a49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecf56216555b43848a1e2957b3b70255": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef01e42092e24514b234c42d983c8de8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef228b4e20544802a374962a9278d5c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef2a247862bb49ef8c83c5cd664a15e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76dbc1405ff745928737f59cae06ad1f",
      "max": 305584576,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3554f7b32bc428984b27f319ac2e605",
      "value": 305584576
     }
    },
    "eff7d36b95474bf5828673bad75a7c3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1adac33380de4121aa3593e2e15c9595",
      "max": 1422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_609215891e394b95b7873f317d45dea3",
      "value": 1422
     }
    },
    "f01356e5ed8e4f9991fe6839ae1da8d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f34227be34db469e95cfd1f95a225e18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3554f7b32bc428984b27f319ac2e605": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f483a4688d0740e7b0ef2231cbdd4d74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f81a8ea5bca1475da4fba7e9a03316ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb07f93cc8624594b41e83607be0dda9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffbcead0b8bf4e1da8e4b029dd387eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef01e42092e24514b234c42d983c8de8",
      "max": 2306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_841c89052af64248bb19965425580559",
      "value": 2306
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
