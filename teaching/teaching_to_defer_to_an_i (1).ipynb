{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "teaching_to_defer_to_an_i.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxD7R_w4ybIM"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9yZQJkFxqIz"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "from sklearn import neighbors, datasets\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import torch.nn.parallel\n",
        "from tqdm import tqdm\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "from torchvision.datasets.utils import download_url, check_integrity\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from scipy.stats import multivariate_normal\n",
        "import  scipy.stats as st\n",
        "from matplotlib import cm\n",
        "from __future__ import print_function\n",
        "from spacy.lang.en import English\n",
        "from sklearn.cluster import KMeans\n",
        "import pickle\n",
        "import matplotlib\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as tfunc\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "import scipy.stats as st\n",
        "#import lime\n",
        "#import lime.lime_tabular\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGQ3QXgp66Wl"
      },
      "source": [
        "class HumanLearner:\n",
        "    \"\"\" Model of Human Learner.\n",
        "    Learner has a list of training points each with a radius and label.\n",
        "    Learner follows the radius nearest neighbor assumption.\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel):\n",
        "        '''\n",
        "        Args:\n",
        "            kernel: function that takes two inputs and returns a similarity\n",
        "        '''\n",
        "        self.teaching_set = []\n",
        "        self.kernel = kernel\n",
        "\n",
        "    def predict(self, xs, prior_rejector_preds, to_print = False):\n",
        "        '''\n",
        "        Args:\n",
        "            xs: x points \n",
        "            prior_rejector_preds: predictions of prior rejector\n",
        "        Return:\n",
        "            preds: posterior human learner rejector predictions\n",
        "        '''\n",
        "        preds = []\n",
        "        idx = 0\n",
        "        used_posterior = 0 \n",
        "        for x in xs:\n",
        "            ball_at_x = []\n",
        "            similarities = self.kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n",
        "            for i in range(len(self.teaching_set)):\n",
        "                similarity = similarities[i]\n",
        "                if similarity >=  self.teaching_set[i][2]:\n",
        "                    ball_at_x.append(self.teaching_set[i])\n",
        "            if len(ball_at_x) == 0: \n",
        "                preds.append(prior_rejector_preds[idx])\n",
        "            else:\n",
        "                used_posterior += 1\n",
        "                ball_similarities = self.kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n",
        "                normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n",
        "                score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n",
        "                pred = score_one / normalization\n",
        "                if pred >= 0.5:\n",
        "                    preds.append(1)\n",
        "                else:\n",
        "                    preds.append(0)\n",
        "            idx += 1\n",
        "        \n",
        "        return preds\n",
        "\n",
        "    def add_to_teaching(self, teaching_example):\n",
        "        '''\n",
        "        adds teaching_example to training set\n",
        "        args:\n",
        "            teaching_example: (x, label, gamma)\n",
        "        '''\n",
        "        self.teaching_set.append(teaching_example)\n",
        "\n",
        "    def remove_last_teaching_item(self):\n",
        "        \"\"\" removes last placed teaching example from training set\"\"\"\n",
        "        self.teaching_set = self.teaching_set[:-1]\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHqbpHiN7ypi"
      },
      "source": [
        "def compute_predictions_humanai(hum_preds, hum_rejector, ai_preds, data_x):\n",
        "    '''\n",
        "    hum_preds: array of human predictions\n",
        "    ai_preds: array of AI predictions\n",
        "    hum_rejector: HumanLearner\n",
        "    data_x: array of inputs\n",
        "\n",
        "    Returns array of final predictions and deferalls\n",
        "    '''\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        reject_decisions = hum_rejector(data_x)\n",
        "        for i in range(len(data_x)):\n",
        "            if reject_decisions[i] == 1:\n",
        "                # defer\n",
        "                predictions.append(ai_preds[i])\n",
        "            else:\n",
        "                predictions.append(hum_preds[i])\n",
        "    return predictions, reject_decisions\n",
        "\n",
        "def get_metrics(preds, truths, metric_y):\n",
        "    # to be implemented for each method, higher better\n",
        "    '''\n",
        "    preds: array of predictions\n",
        "    truths:  target array\n",
        "    '''\n",
        "    acc = metric_y(truths, preds) #metrics.accuracy_score(truths, preds)\n",
        "    metrics_computed = { \"score\": acc}\n",
        "    return metrics_computed\n",
        "\n",
        "def compute_metrics(human_preds, ai_preds, reject_decisions, truths, metric_y, to_print = False):\n",
        "    coverage = 1 - np.sum(reject_decisions)/len(reject_decisions)\n",
        "    humanai_preds = []\n",
        "    human_preds_sys = []\n",
        "    truths_human = []\n",
        "    ai_preds_sys = []\n",
        "    truths_ai = []\n",
        "    for i in range(len(reject_decisions)):\n",
        "        if reject_decisions[i] == 1:\n",
        "            humanai_preds.append(ai_preds[i])\n",
        "            ai_preds_sys.append(ai_preds[i])\n",
        "            truths_ai.append(truths[i])\n",
        "        else:\n",
        "            humanai_preds.append(human_preds[i])\n",
        "            human_preds_sys.append(human_preds[i])\n",
        "            truths_human.append(truths[i])\n",
        "    humanai_metrics = get_metrics(humanai_preds, truths, metric_y)\n",
        "\n",
        "    human_metrics = get_metrics(human_preds_sys, truths_human, metric_y)\n",
        "\n",
        "    ai_metrics = get_metrics(ai_preds_sys, truths_ai, metric_y)\n",
        "\n",
        "    if to_print:\n",
        "        print(f'Coverage is {coverage*100:.2f}')\n",
        "        print(f' metrics of system are: {humanai_metrics}')\n",
        "        print(f' metrics of human are: {human_metrics}')\n",
        "        print(f' metrics of AI are: {ai_metrics}')\n",
        "    return coverage, humanai_metrics, human_metrics, ai_metrics"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A64Do-nD2NSj"
      },
      "source": [
        "class TeacherExplainer():\n",
        "    \"\"\" Returns top examples that best teach a learner when to defer to a classifier.\n",
        "    Given a tabular dataset with classifier predictions, human predictions and a similarity metric,\n",
        "    the method returns the top k images that best describe when to defer to the AI.    \n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                data_x,\n",
        "                data_y,\n",
        "                hum_preds,\n",
        "                ai_preds,\n",
        "                prior_rejector_preds,\n",
        "                sim_kernel,\n",
        "                metric_y,\n",
        "                alpha = 1,\n",
        "                teaching_points = 10):\n",
        "            \"\"\"Init function.\n",
        "            Args:\n",
        "                data_x: 2d numpy array of the features\n",
        "                data_y: 1d numpy array of labels\n",
        "                hum_preds:  1d array of the human predictions \n",
        "                ai_preds:  1d array of the AI predictions \n",
        "                prior_rejector_preds: 1d binary array of the prior rejector preds \n",
        "                sim_kernel: function that takes as input two inputs and returns a positive number\n",
        "                metric_y: metric function (positive, the higher the better) between predictions and ground truths \n",
        "                alpha: parameter of selection algorithm, set to 1 for now\n",
        "            \"\"\"\n",
        "            self.data_x = data_x\n",
        "            self.data_y = data_y\n",
        "            self.hum_preds = hum_preds\n",
        "            self.data_y = data_y\n",
        "            self.ai_preds = ai_preds\n",
        "            self.kernel = sim_kernel\n",
        "            self.prior_rejector_preds = prior_rejector_preds\n",
        "            self.metric_y = metric_y\n",
        "            self.alpha = alpha\n",
        "            self.teaching_points = teaching_points\n",
        "\n",
        "    def get_optimal_deferral(self):\n",
        "        '''\n",
        "        gets optimal deferral decisions computed emperically\n",
        "        Return:\n",
        "            opt_defer: optimal deferral decisions \n",
        "\n",
        "        '''\n",
        "        opt_defer_teaching = []\n",
        "        for ex in range(len(self.hum_preds)):\n",
        "            score_hum = self.metric_y([self.data_y[ex]], [self.hum_preds[ex]])\n",
        "            score_ai = self.metric_y([self.data_y[ex]], [self.ai_preds[ex]])\n",
        "            if score_hum >= score_ai:\n",
        "                opt_defer_teaching.append(0)\n",
        "            else:\n",
        "                opt_defer_teaching.append(1)\n",
        "        self.opt_defer = np.array(opt_defer_teaching)\n",
        "        return np.array(opt_defer_teaching)\n",
        "\n",
        "\n",
        "    def get_optimal_consistent_gammas(self):\n",
        "        '''\n",
        "        get optimal consistent gammas\n",
        "        Return:\n",
        "            optimal_consistent_gammas: array of optimal consistent gamma values\n",
        "        '''\n",
        "        optimal_consistent_gammas = []\n",
        "        with tqdm(total=len(self.data_x)) as pbar:\n",
        "            similarities_embeds_all = self.kernel( np.asarray(self.data_x), np.asarray(self.data_x)) # kernel matrix\n",
        "            self.similarities_embeds_all = similarities_embeds_all # save kernel matrix\n",
        "            for i in range(len(self.data_x)):\n",
        "                # get all similarities\n",
        "                similarities_embeds = similarities_embeds_all[i]\n",
        "                opt_defer_ex = self.opt_defer[i]\n",
        "                opt_gamma = 1\n",
        "                sorted_sim = sorted([(similarities_embeds[k], self.opt_defer[k]) for k in range(len(self.data_x))], key=lambda tup: tup[0])\n",
        "                indicess = list(range(1, len(self.opt_defer)))\n",
        "                indicess.reverse()\n",
        "                for k in indicess:\n",
        "                    if sorted_sim[k][1] == opt_defer_ex and sorted_sim[k- 1][1] != opt_defer_ex:\n",
        "                        opt_gamma = sorted_sim[k][0]\n",
        "                        break\n",
        "                optimal_consistent_gammas.append(opt_gamma)\n",
        "                pbar.update(1)\n",
        "        self.optimal_consistent_gammas = np.array(optimal_consistent_gammas)\n",
        "        return np.array(optimal_consistent_gammas)\n",
        "\n",
        "    def get_improvement_defer_consistent(self, current_defer_preds):\n",
        "        '''\n",
        "        Gets how much would score improve in terms of metric_y if you add each point to the teaching set \n",
        "        Assumption: assumes metric_y over all data is decomposed as the average of metric_y for each data point e.g. 0-1 loss\n",
        "        Relaxation: instead of simulating human learner, we assume if point added to the human's set, human will follow the points optimal decision\n",
        "        Note: for the consistent gamma strategy, the relaxation does not affect the result\n",
        "        Args:\n",
        "            current_defer_preds: current predictions of human learner on teaching set\n",
        "        Return:\n",
        "            error_improvements: improvement of adding point i for each i in data to the human training set\n",
        "        '''\n",
        "        error_improvements = []\n",
        "        error_at_i = 0\n",
        "        for i in range(len(self.data_x)):\n",
        "            error_at_i = 0\n",
        "            similarities_embeds = self.similarities_embeds_all[i]\n",
        "            # get the ball for x\n",
        "            # in this ball how many does the current defer not match the optimal\n",
        "            for j in range(len(similarities_embeds)):\n",
        "                if similarities_embeds[j] >= self.optimal_consistent_gammas[i]:\n",
        "                    score_hum = self.metric_y([self.data_y[j]], [self.hum_preds[j]])\n",
        "                    score_ai = self.metric_y([self.data_y[j]], [self.ai_preds[j]])\n",
        "                    if self.opt_defer[i] == 1:\n",
        "                        if current_defer_preds[j] == 0:\n",
        "                            error_at_i += score_ai - score_hum\n",
        "                    else:\n",
        "                        if current_defer_preds[j] == 1:\n",
        "                            error_at_i += score_hum - score_ai\n",
        "            error_improvements.append(error_at_i)\n",
        "\n",
        "        return error_improvements\n",
        "\n",
        "\n",
        "    def teach_consistent(self, to_print = False, plotting_interval = 2):\n",
        "        '''\n",
        "        our greedy consistent selection algorithm, updates human learner\n",
        "        returns:\n",
        "            errors: training errors after adding each teaching point\n",
        "            indices_used: indices used for teaching \n",
        "        '''\n",
        "        errors = []\n",
        "        data_sizes  = []\n",
        "        indices_used = []\n",
        "        points_chosen = []\n",
        "        plotting_interval = 2 # plotting interval\n",
        "        for itt in range(self.teaching_points):\n",
        "            print(f'New size {itt}')\n",
        "            best_index = -1\n",
        "            # predict with current human learner\n",
        "            if itt == 0:\n",
        "                preds_teach = self.prior_rejector_preds\n",
        "            else:\n",
        "                preds_teach = self.human_learner.predict(self.data_x, self.prior_rejector_preds)\n",
        "            # get improvements for each point if added\n",
        "            error_improvements = self.get_improvement_defer_consistent(preds_teach)\n",
        "            # pick best point and add it\n",
        "            best_index = np.argmax(error_improvements)\n",
        "            indices_used.append(best_index) # add found element to set used\n",
        "            ex_embed = self.data_x[best_index]\n",
        "            ex_label = self.opt_defer[best_index]\n",
        "            gamma = self.optimal_consistent_gammas[best_index]\n",
        "            if to_print:\n",
        "                print(f'got improvements with max {max(error_improvements)}')\n",
        "            self.human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n",
        "\n",
        "            # evaluate on teaching points\n",
        "            if to_print and itt % plotting_interval == 0:\n",
        "                print(\"####### train eval \" + str(itt)+ \" ###########\")\n",
        "                preds_teach = self.human_learner.predict(self.data_x, self.prior_rejector_preds)\n",
        "                _, metricss, __, ___ = compute_metrics(self.hum_preds, self.ai_preds, preds_teach, self.data_y, self.metric_y, to_print)\n",
        "                errors.append(metricss['score'])   \n",
        "                print(\"##############################\")\n",
        "        \n",
        "        return errors, indices_used\n",
        "\n",
        "\n",
        "    def get_teaching_examples(self, to_print = False, plot_interval = 2):\n",
        "        \"\"\" obtains teaching points. Currently only implemented for consistent strategy\n",
        "        Args:\n",
        "            to_print: display details of teaching process\n",
        "            plot_interval: how often to plot results\n",
        "        Return:\n",
        "            teaching_x: 2d numpy array of teaching points features\n",
        "            teaching_indices: indices of the teaching points in self.data_x\n",
        "            teaching_gammas: 1d numpy of gamma values used\n",
        "            teaching_labels: 1d array of deferral labels where 1 signifies defer to AI and 0 signifies don't defer to AI\n",
        "        \n",
        "        \"\"\"\n",
        "        assert self.alpha == 1, \"Only consistent strategy implemented with alpha=1\"\n",
        "\n",
        "        # run algorithm to get examples\n",
        "        # get optimal deferrall points\n",
        "        print(\"getting gammas and optimal deferral decisions on teaching set\")\n",
        "        self.get_optimal_deferral()\n",
        "        # get consistentg\n",
        "        self.get_optimal_consistent_gammas()\n",
        "        self.human_learner = HumanLearner(self.kernel)\n",
        "        print(\"starting the teaching process ...\")\n",
        "        errors, indices_used = self.teach_consistent(to_print, plot_interval)\n",
        "        teaching_x = self.data_x[indices_used]\n",
        "        teaching_indices = indices_used\n",
        "        teaching_gammas = self.optimal_consistent_gammas[indices_used]\n",
        "        teaching_labels = self.opt_defer[indices_used]\n",
        "\n",
        "        return teaching_x, teaching_gammas, teaching_labels, teaching_indices"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eJMKTcHbi_n"
      },
      "source": [
        "# test on synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKK581V2bkfo"
      },
      "source": [
        "\n",
        "def sample(mu, var, nb_samples=500):\n",
        "    \"\"\"\n",
        "    :param mu: torch.Tensor (features)\n",
        "    :param var: torch.Tensor (features) (note: zero covariance)\n",
        "    :return: torch.Tensor (nb_samples, features)\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for i in range(nb_samples):\n",
        "        out += [\n",
        "            torch.normal(mu, var.sqrt())\n",
        "        ]\n",
        "    return torch.stack(out, dim=0)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1caVm6Nbmf8"
      },
      "source": [
        "\n",
        "class Linear_net_sig(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Linear_net_sig, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(input_dim, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def run_classifier_sig(net, data_x, data_y, n_epochs = 10000):\n",
        "    '''\n",
        "    training code using GD\n",
        "    '''\n",
        "    BCE = torch.nn.BCELoss(size_average=True)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0)\n",
        "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000*10000)\n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs = data_x\n",
        "        labels = data_y\n",
        "        order = np.array(range(len(data_x)))\n",
        "        np.random.shuffle(order)\n",
        "        # in-place changing of values\n",
        "        inputs[np.array(range(len(data_x)))] = inputs[order]\n",
        "        labels[np.array(range(len(data_x)))] = labels[order]\n",
        "        # zero the parameter gradients\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)[:,0]\n",
        "\n",
        "        loss = BCE(outputs, labels*1.0) \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #scheduler.step()\n",
        "        running_loss += loss.item()\n",
        "        if epoch % 10000 == 0:\n",
        "            print(\"loss \" + str(loss.item()))\n",
        "\n",
        "    #print('Finished Training')\n",
        "\n",
        "\n",
        "def test_classifier_sig(net, data_x, data_y):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        inputs =  data_x\n",
        "        labels = data_y\n",
        "        outputs = net(inputs)\n",
        "        predicted = torch.round(outputs.data)\n",
        "        total = labels.size(0)\n",
        "        for i in range(total):\n",
        "            correct += predicted[i].item() == labels[i].item()\n",
        "        #correct = (predicted == labels).sum()\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))\n",
        "    \n",
        "def mscatter(x,y,ax=None, m=None, **kw):\n",
        "    import matplotlib.markers as mmarkers\n",
        "    if not ax: ax=plt.gca()\n",
        "    sc = ax.scatter(x,y,**kw)\n",
        "    if (m is not None) and (len(m)==len(x)):\n",
        "        paths = []\n",
        "        for marker in m:\n",
        "            if isinstance(marker, mmarkers.MarkerStyle):\n",
        "                marker_obj = marker\n",
        "            else:\n",
        "                marker_obj = mmarkers.MarkerStyle(marker)\n",
        "            path = marker_obj.get_path().transformed(\n",
        "                        marker_obj.get_transform())\n",
        "            paths.append(path)\n",
        "        sc.set_paths(paths)\n",
        "    return sc\n",
        "def conv_to_color(arr):\n",
        "    cols = []\n",
        "    for a in arr:\n",
        "        if a == 1:\n",
        "            cols.append(\"blue\")\n",
        "        else:\n",
        "            cols.append(\"red\")\n",
        "    return cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "5PzyM7tFbqtT",
        "outputId": "a40695f6-cc7d-416a-c7ef-3263d208ca1a"
      },
      "source": [
        "\n",
        "d = 2\n",
        "total_samples = 500\n",
        "mean_scale = 12\n",
        "variance = 1.0\n",
        "group_proportion = 0.5#np.random.uniform()\n",
        "'''\n",
        "if group_proportion <= 0.02:\n",
        "    group_proportion = 0.02\n",
        "if group_proportion >= 0.98:\n",
        "    group_proportion = 0.98\n",
        "#group_proportion = 0.4\n",
        "'''\n",
        "cluster1_mean = torch.rand(d)*mean_scale\n",
        "cluster1_var = torch.tensor(variance)#torch.rand(d)*d\n",
        "cluster1 = sample(\n",
        "    cluster1_mean,\n",
        "    cluster1_var,\n",
        "    nb_samples= math.floor(total_samples * group_proportion * 0.5 )\n",
        ")\n",
        "cluster1_labels = torch.ones([math.floor(total_samples * group_proportion * 0.5 )], dtype=torch.long)\n",
        "cluster2_mean = torch.rand(d)*mean_scale\n",
        "cluster2_var = torch.tensor(variance)#torch.rand(d)*d\n",
        "cluster2 = sample(\n",
        "    cluster2_mean,\n",
        "    cluster2_var,\n",
        "    nb_samples= math.floor(total_samples * group_proportion * 0.5 )\n",
        ")\n",
        "cluster2_labels = torch.zeros([math.floor(total_samples * group_proportion * 0.5 )], dtype=torch.long)\n",
        "cluster3_mean = torch.rand(d)*mean_scale\n",
        "cluster3_var = torch.tensor(variance)#torch.rand(d)*d\n",
        "cluster3 = sample(\n",
        "    cluster3_mean,\n",
        "    cluster3_var,\n",
        "    nb_samples= math.floor(total_samples * (1-group_proportion) * 0.5 )\n",
        ")\n",
        "cluster3_labels = torch.ones([math.floor(total_samples * (1-group_proportion) * 0.5 )], dtype=torch.long)\n",
        "\n",
        "cluster4_mean = torch.rand(d)*mean_scale\n",
        "cluster4_var = torch.tensor(variance)#torch.rand(d)*d\n",
        "cluster4 = sample(\n",
        "    cluster4_mean,\n",
        "    cluster4_var,\n",
        "    nb_samples= math.floor(total_samples * (1-group_proportion) * 0.5 )\n",
        ")\n",
        "cluster4_labels = torch.zeros([math.floor(total_samples * (1-group_proportion) * 0.5 )], dtype=torch.long)\n",
        "\n",
        "# test data\n",
        "cluster1_test = sample(\n",
        "    cluster1_mean,\n",
        "    cluster1_var,\n",
        "    nb_samples= math.floor(total_samples * group_proportion * 0.5 )\n",
        ")\n",
        "cluster1_labels_test = torch.ones([math.floor(total_samples * group_proportion * 0.5 )], dtype=torch.long)\n",
        "\n",
        "cluster2_test = sample(\n",
        "    cluster2_mean,\n",
        "    cluster2_var,\n",
        "    nb_samples= math.floor(total_samples * group_proportion * 0.5 )\n",
        ")\n",
        "cluster2_labels_test = torch.zeros([math.floor(total_samples * group_proportion * 0.5 )], dtype=torch.long)\n",
        "\n",
        "cluster3_test = sample(\n",
        "    cluster3_mean,\n",
        "    cluster3_var,\n",
        "    nb_samples= math.floor(total_samples * (1-group_proportion) * 0.5 )\n",
        ")\n",
        "cluster3_labels_test = torch.ones([math.floor(total_samples * (1-group_proportion) * 0.5 )], dtype=torch.long)\n",
        "\n",
        "cluster4_test = sample(\n",
        "    cluster4_mean,\n",
        "    cluster4_var,\n",
        "    nb_samples= math.floor(total_samples * (1-group_proportion) * 0.5 )\n",
        ")\n",
        "cluster4_labels_test = torch.zeros([math.floor(total_samples * (1-group_proportion) * 0.5 )], dtype=torch.long)\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "x1 = cluster1.numpy()\n",
        "x2 = cluster2.numpy()\n",
        "x3 = cluster3.numpy()\n",
        "x4 = cluster4.numpy()\n",
        "epsilon = 0.8\n",
        "ax.set_facecolor('white')\n",
        "#ax.set(xlim=(-4, 10), ylim=(-4, 10))\n",
        "#ax.vlines([-12,-6,0,6,12.3],-12,12.3)\n",
        "#ax.hlines([-12,-6,0,6,12.3],-12,12.3)\n",
        "#ax.plot([x1h, x2h], [y1h, y2h], color='red', marker='x',label = \"human\")\n",
        "#ax.plot([x1m, x2m], [y1m, y2m], color='blue', marker='x',label = \"machine\")\n",
        "\n",
        "scatter = mscatter(x1[:, 0], x1[:, 1],  cmap='RdBu',  ax=ax,s=100, label=\"human 0\")\n",
        "scatter = mscatter(x2[:, 0], x2[:, 1], cmap='RdBu',  ax=ax,s=100, label=\"human 1\")\n",
        "scatter = mscatter(x3[:, 0], x3[:, 1],  cmap='RdBu',  ax=ax,s=100, label=\"machine 0\")\n",
        "scatter = mscatter(x4[:, 0], x4[:, 1],  cmap='RdBu',  ax=ax,s=100, label=\"machine 1\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "FRYx1Q53br_c",
        "outputId": "1e3e698a-2528-4f13-bd10-b7f049db5bb9"
      },
      "source": [
        "print(\"Obtaining AI\")\n",
        "net_machine = Linear_net_sig(d)\n",
        "data_x = torch.cat([cluster3, cluster4])\n",
        "data_y = torch.cat([cluster3_labels, cluster4_labels])\n",
        "run_classifier_sig(net_machine, data_x, data_y, 50000)\n",
        "\n",
        "print(\"Obtaining human\")\n",
        "net_human = Linear_net_sig(d)\n",
        "data_x = torch.cat([cluster1, cluster2])\n",
        "data_y = torch.cat([cluster1_labels, cluster2_labels])\n",
        "run_classifier_sig(net_human, data_x, data_y, 50000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining AI\n",
            "loss 2.623969793319702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.28343623876571655\n",
            "loss 0.2529910206794739\n",
            "loss 0.23071178793907166\n",
            "loss 0.21406297385692596\n",
            "Obtaining human\n",
            "loss 0.6173954010009766\n",
            "loss 0.12918274104595184\n",
            "loss 0.10199941694736481\n",
            "loss 0.09191342443227768\n",
            "loss 0.08665629476308823\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3ee30e0e3e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster1_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster2_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrun_classifier_sig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_human\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mknn_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHumanLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'HumanLearner' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VkZeZojcrf0"
      },
      "source": [
        "data_x = torch.cat([cluster1, cluster2, cluster3, cluster4])\n",
        "data_y = torch.cat([cluster1_labels, cluster2_labels, cluster3_labels, cluster4_labels])\n",
        "data_x_np = data_x.numpy()\n",
        "data_y_np = data_y.numpy()\n",
        "outputs = net_human(data_x)\n",
        "predicted_hum = torch.round(outputs.data).numpy()[:,0]\n",
        "outputs = net_machine(data_x)\n",
        "predicted_mach = torch.round(outputs.data).numpy()[:,0]\n",
        "# I need prior\n",
        "# I need alpha\n",
        "alpha = 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGq_y7nsdphf"
      },
      "source": [
        "prior_rejector = []\n",
        "epsilon = 0.9\n",
        "with torch.no_grad():\n",
        "    inputs =  data_x\n",
        "    labels = data_y\n",
        "    outputs = net_human(inputs)\n",
        "    predicted = torch.round(outputs.data)\n",
        "    for i in range(len(inputs)):\n",
        "        r_score = max(1 - outputs.data[i].item(), outputs.data[i].item())\n",
        "        r = 0\n",
        "        if r_score <  epsilon:\n",
        "            r = 1\n",
        "        else:\n",
        "            r =  0\n",
        "        prior_rejector.append(r)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALPZ7gpteFHZ"
      },
      "source": [
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "from sklearn.metrics import accuracy_score\n",
        "kernel = rbf_kernel\n",
        "metric_y = accuracy_score\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSlEgUst1otG",
        "outputId": "2c8f0ced-7677-4bc8-9087-1093b714e9da"
      },
      "source": [
        "accuracy_score([1],[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7rdGGqe07-s"
      },
      "source": [
        "teacher = TeacherExplainer(data_x_np, data_y_np, predicted_hum, predicted_mach, prior_rejector, kernel, metric_y, 1, 50)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "R_rrXAA61LBt",
        "outputId": "e7f40e0e-0986-406b-b297-6033c74cacd5"
      },
      "source": [
        "print(teacher.get_teaching_examples())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f238be4e4bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_teaching_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-2d1be4f13dea>\u001b[0m in \u001b[0;36mget_teaching_examples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimal_deferral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# get consistentg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimal_consistent_gammas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuman_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHumanLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach_consistent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-2d1be4f13dea>\u001b[0m in \u001b[0;36mget_optimal_consistent_gammas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mopt_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_sim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0moptimal_gammas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_gamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimal_consistent_gammas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_consistent_gammas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimal_gammas' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT_m5xEJ00As"
      },
      "source": [
        "class TeacherExplainer():\n",
        "    \"\"\" Returns top examples that best teach a learner when to defer to a classifier.\n",
        "    Given a tabular dataset with classifier predictions, human predictions and a similarity metric,\n",
        "    the method returns the top k images that best describe when to defer to the AI.    \n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                data_x,\n",
        "                data_y,\n",
        "                hum_preds,\n",
        "                ai_preds,\n",
        "                prior_rejector_preds,\n",
        "                sim_kernel,\n",
        "                metric_y,\n",
        "                alpha = 1,\n",
        "                teaching_points = 10):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGPFtT9yq5T"
      },
      "source": [
        "GOAL\n",
        "\n",
        "general:\n",
        "\n",
        "given dataloader and costs, retreive set of points and their indices and gammas, and distance metric\n",
        "\n",
        "input:\n",
        "- \n",
        "- \n",
        "- \n",
        "\n",
        "test case\n",
        "- images with cifar \n",
        "\n",
        "- adult dataset fake expert\n",
        "\n",
        "- \n",
        "\n"
      ]
    }
  ]
}