{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"hotpot_qa_teaching_pretrained.ipynb","provenance":[{"file_id":"1gcI_DqzHGzy88fMXRmaLHQAmQZ8QrkLU","timestamp":1615308044138},{"file_id":"17ZhI4xATy-NPWIl-Uh7sSzgkHtN2j3gw","timestamp":1614622568106},{"file_id":"1nDHjgK_wPzlUYYFK0gh3KWtBWpIVgsYH","timestamp":1614093172414}],"collapsed_sections":["UP1CACu3irWL","5WSnSiY1dF2E","PuxiBHbj_zde"],"toc_visible":true,"authorship_tag":"ABX9TyOYWSvsJVn9BG5bdOxmdTIs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2395999c0d5441b3ab5c6c48828e9698":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_03bac1e51c6548869bde56f0dbbaeba9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f6751b7486e34057aba5bd037d6d122e","IPY_MODEL_89df61891fd240cda79a401497637e0b"]}},"03bac1e51c6548869bde56f0dbbaeba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6751b7486e34057aba5bd037d6d122e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7ccef9780950451c8fe8811c617751c8","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":2341,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2341,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c855aff6a0447d9bc96efe70fb37de4"}},"89df61891fd240cda79a401497637e0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30016bfb5f2e45999b1b497a2cd2655a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6.49k/? [01:47&lt;00:00, 60.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9cd2265276349d68180a9e798b7e276"}},"7ccef9780950451c8fe8811c617751c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c855aff6a0447d9bc96efe70fb37de4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30016bfb5f2e45999b1b497a2cd2655a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f9cd2265276349d68180a9e798b7e276":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fded24e0e1f24789881677533bf45381":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8fea9ff742e54cdb9c31ee708ffcc99b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7e11be24b8f472ebabcd59fe1ba5cc5","IPY_MODEL_2a9a6eba45ed41e8bdef10a79765f0e4"]}},"8fea9ff742e54cdb9c31ee708ffcc99b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7e11be24b8f472ebabcd59fe1ba5cc5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f76fd57318eb4180908a786b516d7829","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":1422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d46c1571c15e47e8bdeb1e5dd5544470"}},"2a9a6eba45ed41e8bdef10a79765f0e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e9867111d90471d90c58760a5a947f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.93k/? [00:00&lt;00:00, 71.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3175ea69cdc7415fb6ab496780cb4e62"}},"f76fd57318eb4180908a786b516d7829":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d46c1571c15e47e8bdeb1e5dd5544470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e9867111d90471d90c58760a5a947f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3175ea69cdc7415fb6ab496780cb4e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc83c987a5b84331b1ca41275500ab07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c57fa447964a4e40bd1bc452bbd2d3e9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9ba2e3844e4f40938c19f33fea58eb37","IPY_MODEL_57395df57b7349558904f5e84981653e"]}},"c57fa447964a4e40bd1bc452bbd2d3e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ba2e3844e4f40938c19f33fea58eb37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_18a9f48f180a48e08ec7829d24f11084","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":566426227,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":566426227,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da49832b0bc04f64acccd41670332e77"}},"57395df57b7349558904f5e84981653e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b4c6996c6244ec8bdd8ff80e229622e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 566M/566M [01:46&lt;00:00, 5.33MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f86431ca61cf4b8bba9c3292cd217533"}},"18a9f48f180a48e08ec7829d24f11084":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da49832b0bc04f64acccd41670332e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b4c6996c6244ec8bdd8ff80e229622e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f86431ca61cf4b8bba9c3292cd217533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe8a968ed0b84f0d947b37734910cb1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_718e3ba076834233b52e021c23ff42ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aadf1e76e287415bbf3d834821a77016","IPY_MODEL_18b3334441a4493da38122ed4de7d931"]}},"718e3ba076834233b52e021c23ff42ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aadf1e76e287415bbf3d834821a77016":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_feecf44942fc400297bf6fa7d7fed4f7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":46320117,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46320117,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ec4a3c530e143c09bb891075e31e945"}},"18b3334441a4493da38122ed4de7d931":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0b903864710b4f1a9f2e9fca593ac875","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 46.3M/46.3M [00:09&lt;00:00, 4.77MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_368ca2beff5b44bf8fff2c42e392aac0"}},"feecf44942fc400297bf6fa7d7fed4f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9ec4a3c530e143c09bb891075e31e945":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b903864710b4f1a9f2e9fca593ac875":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"368ca2beff5b44bf8fff2c42e392aac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d10ddf0b0e4540f4a8a2950b47e0ecbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97e4e23e40194a7f9c6cf6e959568283","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ac55590646cc451bb5f18969dfaf6d16","IPY_MODEL_e2d0a0805cc3492a8f995648dd8e4c18"]}},"97e4e23e40194a7f9c6cf6e959568283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac55590646cc451bb5f18969dfaf6d16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1715b4e0d5e1482db7188e3797546029","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5666d1f85dc24a7f911cc4586b0aa241"}},"e2d0a0805cc3492a8f995648dd8e4c18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_04ab376310ce42e384a714f677d1a950","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 90447/0 [00:34&lt;00:00, 2433.04 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_00485faa9eb8401db96069a1e263a028"}},"1715b4e0d5e1482db7188e3797546029":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5666d1f85dc24a7f911cc4586b0aa241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04ab376310ce42e384a714f677d1a950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"00485faa9eb8401db96069a1e263a028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80970f78bdb345abb20c9562884a0967":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b8b77965be5d40b99c8e096ba621a5d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b94d19bec66a413886c3d3233c3b7a6e","IPY_MODEL_cc3d395009a242c198fb61b7206dc2d6"]}},"b8b77965be5d40b99c8e096ba621a5d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b94d19bec66a413886c3d3233c3b7a6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_09af4aa7493b4eaeadce3838f3e29151","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ac0115d9a9a479cba3aef62de165db5"}},"cc3d395009a242c198fb61b7206dc2d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_20977f734948463e83a4b22089d195b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7405/0 [00:02&lt;00:00, 907.33 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a877b2befa3450f8753a73b02465228"}},"09af4aa7493b4eaeadce3838f3e29151":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7ac0115d9a9a479cba3aef62de165db5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20977f734948463e83a4b22089d195b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a877b2befa3450f8753a73b02465228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39bf8ab0148c4fbe8a4ee0d5ca185aa3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60669539253846ae9da9e39073d2f304","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f5c50966ad3c4c898e0b517b9b643f6e","IPY_MODEL_7777b13abe14477f9aecca4608da42dc"]}},"60669539253846ae9da9e39073d2f304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5c50966ad3c4c898e0b517b9b643f6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_be064c3a66994348af607918f4219764","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":90447,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":90447,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3160f8bc8014f6f9e1dd1ef25482684"}},"7777b13abe14477f9aecca4608da42dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ea17942c33c412ebe41254b8c5dc4c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 90447/90447 [06:26&lt;00:00, 234.16ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c4b2dc8aa83641f58b1b248bbfda389b"}},"be064c3a66994348af607918f4219764":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e3160f8bc8014f6f9e1dd1ef25482684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ea17942c33c412ebe41254b8c5dc4c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c4b2dc8aa83641f58b1b248bbfda389b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e62d1b9df92e42ddb4fa42198dd41d20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_638d769051d642f98200846a78103eb0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b65cdfd920c4a2c9a45035c98102132","IPY_MODEL_e69c7877b1e34c578264745c6461f80c"]}},"638d769051d642f98200846a78103eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b65cdfd920c4a2c9a45035c98102132":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_31db52fb258f41a4a9f421ab6b60e230","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7405,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7405,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74c64a70e5724de18485bef4fef17975"}},"e69c7877b1e34c578264745c6461f80c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_99a2ce37c37f479b9dc37fd3aab09908","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7405/7405 [05:53&lt;00:00, 20.92ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08525716a8834928b757ed310db29291"}},"31db52fb258f41a4a9f421ab6b60e230":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"74c64a70e5724de18485bef4fef17975":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99a2ce37c37f479b9dc37fd3aab09908":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08525716a8834928b757ed310db29291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UP1CACu3irWL"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"h9FD0NWldZ1T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615352097335,"user_tz":300,"elapsed":39601,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"76539578-952c-4b63-8bb6-7e86a2ae07f9"},"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece\n","!pip install scikit-learn-extra"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 11.4MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 42.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 39.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=7367c65c690028597b07994dc4447fd1444e9e719b8dfb1ae7837190341223b3\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n","Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/73/742d17d8a9a1c639132affccc9250f0743e484cbf263ede6ddcbe34ef212/datasets-1.4.1-py3-none-any.whl (186kB)\n","\u001b[K     |████████████████████████████████| 194kB 10.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 21.1MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.2\n","  Downloading https://files.pythonhosted.org/packages/b5/93/7cb0755c62c36cdadc70c79a95681df685b52cbaf76c724facb6ecac3272/huggingface_hub-0.0.2-py3-none-any.whl\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 22.3MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, huggingface-hub, fsspec, datasets\n","Successfully installed datasets-1.4.1 fsspec-0.8.7 huggingface-hub-0.0.2 xxhash-2.0.0\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 10.9MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n","Collecting scikit-learn-extra\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/891d2ee7bd18af8f2e1df5d63a52ee96edd0eacc21bb9627072b1c5f6a6c/scikit-learn-extra-0.1.0b2.tar.gz (615kB)\n","\u001b[K     |████████████████████████████████| 624kB 11.2MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->scikit-learn-extra) (1.0.1)\n","Building wheels for collected packages: scikit-learn-extra\n","  Building wheel for scikit-learn-extra (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.1.0b2-cp37-cp37m-linux_x86_64.whl size=339937 sha256=adaf48ae9763348c22cd98f050fcf9ca72e394255ed837f0e3f2bfcaf4f27342\n","  Stored in directory: /root/.cache/pip/wheels/04/01/0f/943bffb48bac048fa216b4325f1a6c939491ccb0ff500e08f4\n","Successfully built scikit-learn-extra\n","Installing collected packages: scikit-learn-extra\n","Successfully installed scikit-learn-extra-0.1.0b2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRNFoaJXvO4x","executionInfo":{"status":"ok","timestamp":1615352104919,"user_tz":300,"elapsed":47083,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"1b7340a6-135f-4959-cd6f-24926fd22f43"},"source":["import math\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import argparse\n","from __future__ import print_function\n","from collections import Counter\n","import string\n","import re\n","import argparse\n","import json\n","import os\n","import random\n","import shutil\n","import time\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","from tqdm import tqdm\n","import torch.optim\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.autograd import Variable\n","from PIL import Image\n","import torch.utils.data as data\n","from torchvision.datasets.utils import download_url, check_integrity\n","import sys\n","from sklearn.decomposition import PCA\n","from matplotlib import pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","import pickle\n","from sklearn.gaussian_process.kernels import RBF\n","import torch\n","from scipy.stats import multivariate_normal\n","import  scipy.stats as st\n","from matplotlib import cm\n","import torch.optim as optim\n","from __future__ import print_function\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW, AutoModel\n","import nltk\n","from torch.utils.data import DataLoader\n","import pickle\n","import spacy\n","from gensim import corpora, models, similarities\n","import gensim\n","from spacy.lang.en import English\n","from nltk.corpus import wordnet as wn\n","from nltk.stem.wordnet import WordNetLemmatizer\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5WSnSiY1dF2E"},"source":["# HotpotQA\n"]},{"cell_type":"code","metadata":{"id":"e-1r7KAwnJZJ"},"source":["DISTRACTORS_PARS_LEN = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3E0eakH8dHfv","colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["2395999c0d5441b3ab5c6c48828e9698","03bac1e51c6548869bde56f0dbbaeba9","f6751b7486e34057aba5bd037d6d122e","89df61891fd240cda79a401497637e0b","7ccef9780950451c8fe8811c617751c8","6c855aff6a0447d9bc96efe70fb37de4","30016bfb5f2e45999b1b497a2cd2655a","f9cd2265276349d68180a9e798b7e276","fded24e0e1f24789881677533bf45381","8fea9ff742e54cdb9c31ee708ffcc99b","d7e11be24b8f472ebabcd59fe1ba5cc5","2a9a6eba45ed41e8bdef10a79765f0e4","f76fd57318eb4180908a786b516d7829","d46c1571c15e47e8bdeb1e5dd5544470","7e9867111d90471d90c58760a5a947f5","3175ea69cdc7415fb6ab496780cb4e62","bc83c987a5b84331b1ca41275500ab07","c57fa447964a4e40bd1bc452bbd2d3e9","9ba2e3844e4f40938c19f33fea58eb37","57395df57b7349558904f5e84981653e","18a9f48f180a48e08ec7829d24f11084","da49832b0bc04f64acccd41670332e77","9b4c6996c6244ec8bdd8ff80e229622e","f86431ca61cf4b8bba9c3292cd217533","fe8a968ed0b84f0d947b37734910cb1d","718e3ba076834233b52e021c23ff42ef","aadf1e76e287415bbf3d834821a77016","18b3334441a4493da38122ed4de7d931","feecf44942fc400297bf6fa7d7fed4f7","9ec4a3c530e143c09bb891075e31e945","0b903864710b4f1a9f2e9fca593ac875","368ca2beff5b44bf8fff2c42e392aac0","d10ddf0b0e4540f4a8a2950b47e0ecbe","97e4e23e40194a7f9c6cf6e959568283","ac55590646cc451bb5f18969dfaf6d16","e2d0a0805cc3492a8f995648dd8e4c18","1715b4e0d5e1482db7188e3797546029","5666d1f85dc24a7f911cc4586b0aa241","04ab376310ce42e384a714f677d1a950","00485faa9eb8401db96069a1e263a028","80970f78bdb345abb20c9562884a0967","b8b77965be5d40b99c8e096ba621a5d0","b94d19bec66a413886c3d3233c3b7a6e","cc3d395009a242c198fb61b7206dc2d6","09af4aa7493b4eaeadce3838f3e29151","7ac0115d9a9a479cba3aef62de165db5","20977f734948463e83a4b22089d195b4","5a877b2befa3450f8753a73b02465228"]},"executionInfo":{"status":"ok","timestamp":1615352508099,"user_tz":300,"elapsed":144549,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"215ced73-5dbd-40b7-99b9-57b6f58baad7"},"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"hotpot_qa\", 'distractor')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2395999c0d5441b3ab5c6c48828e9698","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2341.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fded24e0e1f24789881677533bf45381","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1422.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Downloading and preparing dataset hotpot_qa/distractor (download: 584.36 MiB, generated: 570.93 MiB, post-processed: Unknown size, total: 1.13 GiB) to /root/.cache/huggingface/datasets/hotpot_qa/distractor/1.0.0/2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc83c987a5b84331b1ca41275500ab07","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=566426227.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe8a968ed0b84f0d947b37734910cb1d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=46320117.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d10ddf0b0e4540f4a8a2950b47e0ecbe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80970f78bdb345abb20c9562884a0967","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rDataset hotpot_qa downloaded and prepared to /root/.cache/huggingface/datasets/hotpot_qa/distractor/1.0.0/2079f58c1c29624e56735ac2c00efe8808ce52a014e1297552384edae85e3e6d. Subsequent calls will reuse this data.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S-o25hhVijhw"},"source":["train_dataset = dataset['train']\n","validation_dataset = dataset['validation']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqzhee23lkrz"},"source":["\n","def get_token_lenght(context, question):\n","    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n","    return len(inputs['input_ids'][0])\n","\n","def remove_distractors(example):\n","    all_pars = example['context']['title']\n","    gold_pars = list(set(example['supporting_facts']['title']))\n","    distractor_pars = list(set(all_pars) - set(gold_pars))\n","    # get indices to keep from disractors\n","    if len(distractor_pars) == 0 or DISTRACTORS_PARS_LEN == 0:\n","        distract_indices = []\n","    else:\n","        distract_indices = random.sample(range(len(distractor_pars)), DISTRACTORS_PARS_LEN)\n","    distractor_pars = [distractor_pars[idx] for idx in distract_indices]\n","    keep_pars = gold_pars + distractor_pars\n","    keep_pars_indices = [all_pars.index(keep_par) for keep_par in keep_pars]\n","    example['context']['title'] = [example['context']['title'][idx] for idx in keep_pars_indices]\n","    example['context']['sentences'] = [\"\".join(example['context']['sentences'][idx]) for idx in keep_pars_indices] \n","    return example"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["39bf8ab0148c4fbe8a4ee0d5ca185aa3","60669539253846ae9da9e39073d2f304","f5c50966ad3c4c898e0b517b9b643f6e","7777b13abe14477f9aecca4608da42dc","be064c3a66994348af607918f4219764","e3160f8bc8014f6f9e1dd1ef25482684","0ea17942c33c412ebe41254b8c5dc4c2","c4b2dc8aa83641f58b1b248bbfda389b","e62d1b9df92e42ddb4fa42198dd41d20","638d769051d642f98200846a78103eb0","6b65cdfd920c4a2c9a45035c98102132","e69c7877b1e34c578264745c6461f80c","31db52fb258f41a4a9f421ab6b60e230","74c64a70e5724de18485bef4fef17975","99a2ce37c37f479b9dc37fd3aab09908","08525716a8834928b757ed310db29291"]},"id":"unz9KJ9qofO3","executionInfo":{"status":"ok","timestamp":1615353229675,"user_tz":300,"elapsed":35882,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"4bdab2e5-3b9b-4ddf-ec22-f0db5b283751"},"source":["train_dataset = train_dataset.map(remove_distractors)\n","validation_dataset = validation_dataset.map(remove_distractors)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39bf8ab0148c4fbe8a4ee0d5ca185aa3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=90447.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e62d1b9df92e42ddb4fa42198dd41d20","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7405.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLgW2o6dyI0F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615353575624,"user_tz":300,"elapsed":443,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"5461eb96-5885-419b-b84b-fa9b9ef07f68"},"source":["train_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['answer', 'context', 'id', 'level', 'question', 'supporting_facts', 'type'],\n","    num_rows: 90447\n","})"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"7uaXr2c6wNWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615353577895,"user_tz":300,"elapsed":529,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"5132bf14-7cb1-4486-c4fc-f8b7032ea21d"},"source":["validation_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['answer', 'context', 'id', 'level', 'question', 'supporting_facts', 'type'],\n","    num_rows: 7405\n","})"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"LChYrx5dAe--","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615355983597,"user_tz":300,"elapsed":989,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"8e57cde1-ca20-4b29-820c-8d86b5754082"},"source":["def read_hotpot(hotpot_dataset):\n","\n","    contexts = []\n","    questions = []\n","    answers = []\n","    all_contexts = hotpot_dataset['context'][:]\n","    all_questions = hotpot_dataset['question'][:]\n","    all_answers = hotpot_dataset['answer'][:]\n","    invalid_quests = 0\n","    for i in range(len(all_contexts)):\n","\n","        answer = {}\n","        context = \"\".join(all_contexts[i]['sentences'])\n","        answer['text'] = all_answers[i]\n","        answer_start = context.find(answer['text'])\n","        if answer_start == -1:\n","            if answer['text'] not in [\"yes\", \"no\"]:\n","                invalid_quests += 1\n","            answer['answer_start'] = answer_start\n","            answers.append(answer)\n","            contexts.append(context)\n","            questions.append(all_questions[i])\n","        else:\n","            answer['answer_start'] = answer_start\n","            answers.append(answer)\n","            contexts.append(context)\n","            questions.append(all_questions[i])\n","    print(f'invalid percentage {invalid_quests/len(hotpot_dataset)*100:.2f}')\n","    return contexts, questions, answers\n","\n","START_TEST = math.floor(len(validation_dataset)/2)\n","val_contexts, val_questions, val_answers = read_hotpot(validation_dataset)\n","teaching_contexts = val_contexts[:START_TEST]\n","teaching_questions = val_questions[:START_TEST]\n","teaching_answers = val_answers[:START_TEST]\n","validation_contexts = val_contexts[START_TEST:]\n","validation_questions = val_questions[START_TEST:]\n","validation_answers = val_answers[START_TEST:]\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["invalid percentage 0.00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUTN6fECt4Kz","executionInfo":{"status":"ok","timestamp":1615355985823,"user_tz":300,"elapsed":763,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"39e3f23c-9f21-4434-d99f-8bfc23ffb12a"},"source":["len(val_answers)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7405"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"AK9JLhs-97wO"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"40Mqih9Z8rTx"},"source":["\n","def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def f1_score(prediction, ground_truth):\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def exact_match_score(prediction, ground_truth):\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n","\n","\n","def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","    return max(scores_for_ground_truths)\n","\n","\n","\n","def evaluate_truth_pred(truths, preds):\n","    '''\n","    truths, preds: matched arrays of ground truth answers and predictions\n","    '''\n","    f1 = exact_match = total = 0\n","    for i in range(len(truths)):\n","        total += 1\n","        if truths[i] in ['yes', \"no\"]:\n","            continue\n","        ground_truths = [truths[i]]\n","        prediction = preds[i]\n","        exact_match += metric_max_over_ground_truths(\n","            exact_match_score, prediction, ground_truths)\n","        f1 += metric_max_over_ground_truths(\n","            f1_score, prediction, ground_truths)\n","\n","    exact_match = 100.0 * exact_match / (total+ 0.00000000001)\n","    f1 = 100.0 * f1 / (total+ 0.00000000001)\n","\n","    return {'exact_match': exact_match, 'f1': f1}\n","\n","\n","def get_answer( model, tokenizer, context, question):\n","    # 1. TOKENIZE THE INPUT\n","    # note: if you don't include return_tensors='pt' you'll get a list of lists which is easier for\n","    # exploration but you cannot feed that into a model.\n","    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n","    inputs = inputs.to(device)\n","    # 2. OBTAIN MODEL SCORES\n","    # the AutoModelForQuestionAnswering class includes a span predictor on top of the model.\n","    # the model returns answer start and end scores for each word in the text\n","    answer_start_scores, answer_end_scores = model(**inputs, return_dict=False)\n","    answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n","    answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n","    # 3. GET THE ANSWER SPAN\n","    # once we have the most likely start and end tokens, we grab all the tokens between them\n","    # and convert tokens back to words!\n","    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n","    return answer\n","# https://huggingface.co/transformers/migration.html\n","def model_evaluation(model, tokenizer, questions, contexts, answers, to_print = False):\n","    preds = []\n","    my_list = list(range(len(questions)))\n","    with tqdm(total=len(my_list)) as pbar:\n","        for ex in range(len(questions)):\n","            answer = get_answer(model, tokenizer, contexts[ex],questions[ex])\n","            preds.append(answer)\n","            if ex % 100 == 0 and to_print:\n","                print(\"context \" +contexts[ex] )\n","                print(\"quest \" +questions[ex] )\n","                print(\"truth \" +answers[ex]['text'] )\n","                print(\"pred \" + answer)\n","            pbar.update(1)\n","    truths = [answers[i]['text'] for i in range(len(answers))]\n","    scores = evaluate_truth_pred(truths, preds)\n","    print(scores)\n","    return scores\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XyWLfhR6Az3C"},"source":["# Teaching setup"]},{"cell_type":"markdown","metadata":{"id":"PuxiBHbj_zde"},"source":["## Human model Complex\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vn_XDNKEBnA5","executionInfo":{"status":"ok","timestamp":1615354054509,"user_tz":300,"elapsed":2982,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"8bdb323b-452b-440e-ad9e-e14ee99b149a"},"source":["# downloads\n","spacy.load('en')\n","parser = English()\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","en_stop = set(nltk.corpus.stopwords.words('english'))\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"14hVslHL_0ng"},"source":["# see https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n","#import pyLDAvis.gensim and https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n","def tokenize(text):\n","    lda_tokens = []\n","    tokens = parser(text)\n","    for token in tokens:\n","        if token.orth_.isspace():\n","            continue\n","        elif token.like_url:\n","            lda_tokens.append('URL')\n","        elif token.orth_.startswith('@'):\n","            lda_tokens.append('SCREEN_NAME')\n","        else:\n","            lda_tokens.append(token.lower_)\n","    return lda_tokens\n","\n","def get_lemma(word):\n","    lemma = wn.morphy(word)\n","    if lemma is None:\n","        return word\n","    else:\n","        return lemma\n","def get_lemma2(word):\n","    return WordNetLemmatizer().lemmatize(word)\n","\n","def detect_question(token):\n","    # assume token is string\n","    tag = nltk.pos_tag([token])\n","    if tag[0][1] in [\"WP\", \"WRB\", \"WP$\"]:\n","        return True\n","    else:\n","        return False\n","def prepare_text_for_lda(text):\n","    tokens = tokenize(text)\n","    tokens = [token for token in tokens if len(token) > 3]\n","    tokens = [token for token in tokens if (token not in en_stop) or  (detect_question(token))]\n","    tokens = [get_lemma(token) for token in tokens]\n","    return tokens\n","\n","def learn_lda_model():\n","    file_name = \"../squad/train-v2.0.json\"\n","    paragraphs = []\n","    with open(file_name) as f:\n","        dataset = json.load(f)['data']\n","    for article in dataset:\n","        for paragraph in article['paragraphs']:\n","            paragraphs.append(paragraph['context'])\n","\n","    # prep data\n","    paragraphs_lda = []\n","    for i in range(len(paragraphs)):\n","        paragraphs_lda.append(prepare_text_for_lda(paragraphs[i]))\n","\n","    dictionary = corpora.Dictionary(paragraphs_lda)\n","    corpus = [dictionary.doc2bow(text) for text in paragraphs_lda]\n","    pickle.dump(corpus, open('corpus.pkl', 'wb'))\n","    dictionary.save('dictionary.gensim')\n","    NUM_TOPICS = 10\n","    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n","    ldamodel.save('lda_model_10_squad.gensim')\n","    topics = ldamodel.print_topics(num_words=10)\n","    for topic in topics:\n","        print(topic)\n","\n","class LDA_model:\n","    def __init__(self):\n","        self.n_topics = 10\n","        self.model =  models.LdaModel.load('lda_model_10_squad.gensim')\n","        self.dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n","        self.corpus = pickle.load(open('corpus.pkl', 'rb'))\n","    def predict(self, paragraph):\n","        paragraph = prepare_text_for_lda(paragraph)\n","        new_doc_bow = self.dictionary.doc2bow(paragraph)\n","        result = self.model.get_document_topics(new_doc_bow)\n","        vector = [0] * self.n_topics\n","        for top in result:\n","            vector[top[0]] = top[1]\n","        return vector\n","    def show_topics(self):\n","        topics = self.model.print_topics(num_words=10)\n","        for topic in topics:\n","            print(topic)\n","#learn_lda_model()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6YB6u8H_55N"},"source":["\n","#import pyLDAvis.gensim\n","\n","def tokenize(text):\n","    lda_tokens = []\n","    tokens = parser(text)\n","    for token in tokens:\n","        if token.orth_.isspace():\n","            continue\n","        elif token.like_url:\n","            lda_tokens.append('URL')\n","        elif token.orth_.startswith('@'):\n","            lda_tokens.append('SCREEN_NAME')\n","        else:\n","            lda_tokens.append(token.lower_)\n","    return lda_tokens\n","\n","def get_lemma(word):\n","    lemma = wn.morphy(word)\n","    if lemma is None:\n","        return word\n","    else:\n","        return lemma\n","def get_lemma2(word):\n","    return WordNetLemmatizer().lemmatize(word)\n","\n","def detect_question(token):\n","    # assume token is string\n","    tag = nltk.pos_tag([token])\n","    if tag[0][1] in [\"WP\", \"WRB\", \"WP$\"]:\n","        return True\n","    else:\n","        return False\n","\n","\n","\n","def question_classification(question):\n","    question_words = [\"what\", \"when\", \"where\", \"which\", \"who\", \"whom\", \"whose\", \"why\", \"how\"]\n","    question_vec = [0] * len(question_words)\n","    tokens = tokenize(question)\n","    tokens = [get_lemma(token) for token in tokens]\n","    all_zero = True\n","    for token in tokens:\n","        for i in range(len(question_words)):\n","            if token == question_words[i]:\n","                question_vec[i] == 1\n","                all_zero = False\n","    if all_zero:\n","        print(f' question: {question}')\n","    return question_vec, all_zero\n","\n","def question_test():\n","    file_name = \"../squad/dev-v2.0.json\"\n","    paragraphs = []\n","    total = 0\n","    zeros = 0\n","    with open(file_name) as f:\n","        dataset = json.load(f)['data']\n","    for article in dataset:\n","        print(article[\"title\"])\n","        for paragraph in article['paragraphs']:\n","            paragraphs.append(paragraph['context'])\n","            for qa in paragraph['qas']:\n","                total +=1\n","                a, b = question_classification(qa['question'])\n","                zeros += int(b)\n","    print(zeros/total*1.0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WfnCUMgaIqnM"},"source":["## Human model Naiive"]},{"cell_type":"code","metadata":{"id":"W58vz-PuIqBY"},"source":["class HumanPredictor_simple:\n","    def __init__(self, accuracy):\n","        '''\n","        accuracy and ai_accuracy: floats in [0,1]\n","        '''\n","        self.accuracy = accuracy\n","    def predict(self, contexts, questions, answers):\n","        '''\n","        expects array of strings for inputs\n","        returns list of string answer\n","        '''\n","        preds = []\n","        for i in range(len(questions)):\n","            coin = random.random() # random number between [0,1]\n","            if coin <= self.accuracy:\n","                preds.append(answers[i]['text'])\n","            else:\n","                # generate random answer\n","                sents = nltk.sent_tokenize(contexts[i])\n","                rand_sent = random.randint(0,len(sents)-1)\n","                preds.append(sents[rand_sent])\n","        return preds\n","    def prior_rejector(self, contexts, questions, answers):\n","        '''\n","        this rejector is agnostic to input, random deferall 1-self.accuracy times\n","        '''\n","        preds = []\n","        for i in range(len(questions)):\n","            coin = random.random() # random number between [0,1]\n","            preds.append(0)\n","            '''\n","            if coin >= self.accuracy:\n","                preds.append(1)\n","            else:\n","                preds.append(0)\n","            '''\n","        return preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjLzhebZqo8w"},"source":["from sklearn.metrics.pairwise import rbf_kernel\n","def kernel_similarity(x, y):\n","        kernel_dist = rbf_kernel(x.reshape(1, -1),y.reshape(1, -1))\n","        return kernel_dist[0][0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8U7LbFTFVFhr"},"source":["## Our Approach"]},{"cell_type":"code","metadata":{"id":"ASIRoqmiApwE"},"source":["class HumanLearner:\n","    def __init__(self, kernel):\n","        '''\n","        kernel: function that takes two inputs and returns a similarity\n","        prior rejector: returns rejector\n","        '''\n","        self.teaching_set = []\n","        self.kernel = kernel\n","    def predict(self, xs, prior_rejector_preds, to_print = False):\n","        '''\n","        xs: expected array of inputs\n","        '''\n","        preds = []\n","        idx = 0\n","        used_posterior = 0 \n","        if to_print:\n","            print(\"-- Human making reject predictions --\")\n","            with tqdm(total=len(xs)) as pbar:\n","                for x in xs:\n","                    ball_at_x = []\n","                    similarities = rbf_kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n","                    for i in range(len(self.teaching_set)):\n","                        similarity = similarities[i]\n","                        if similarity >=  self.teaching_set[i][2]:\n","                            ball_at_x.append((self.teaching_set[i], similarity))\n","                    if len(ball_at_x) == 0: \n","                        # use prior rejector\n","                        preds.append(prior_rejector_preds[idx])\n","                    else:\n","                        ball_at_x= sorted(ball_at_x, key=lambda tup: tup[1])\n","                        ball_at_x.reverse()\n","                        ball_at_x = ball_at_x[:10]\n","                        used_posterior += 1\n","                        ball_similarities = rbf_kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0][0] for kk in range(len(ball_at_x))]))[0]\n","                        #normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n","                        normalization = len(ball_at_x)\n","                        #score_one = np.sum([ball_similarities[i]*ball_at_x[i][0][1] for i in range(len(ball_at_x))])\n","                        score_one = np.sum([ball_at_x[i][0][1] for i in range(len(ball_at_x))])\n","                        pred = score_one / normalization\n","                        if pred >= 0.5:\n","                            preds.append(1)\n","                        else:\n","                            preds.append(0)\n","                    idx += 1\n","                    pbar.update(1)\n","        else:\n","            for x in xs:\n","                ball_at_x = []\n","                similarities = rbf_kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n","                for i in range(len(self.teaching_set)):\n","                    similarity = similarities[i]\n","                    if similarity >=  self.teaching_set[i][2]:\n","                        ball_at_x.append(self.teaching_set[i])\n","                if len(ball_at_x) == 0: \n","                    # use prior rejector\n","                    preds.append(prior_rejector_preds[idx])\n","                else:\n","                    used_posterior += 1\n","                    ball_similarities = rbf_kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n","                    normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n","                    score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n","                    pred = score_one / normalization\n","                    if pred >= 0.5:\n","                        preds.append(1)\n","                    else:\n","                        preds.append(0)\n","                idx += 1\n","        if to_print:\n","            print(f'Used posterior {used_posterior/len(xs)*100:.2f}')\n","        return preds\n","\n","    def add_to_teaching(self, teaching_example):\n","        '''\n","        teaching_example: (x, label, gamma)\n","        '''\n","        self.teaching_set.append(teaching_example)\n","\n","    def remove_last_teaching_item(self):\n","        self.teaching_set = self.teaching_set[:-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqa5tAIgML2l"},"source":["def compute_predictions_humanai(hum_preds, hum_rejector, ai_preds, data_x):\n","    '''\n","    hum_preds: array of human predictions\n","    ai_preds: array of AI predictions\n","    hum_rejector: HumanLearner\n","    data_x: array of inputs\n","\n","    Returns array of final predictions and deferalls\n","    '''\n","    predictions = []\n","    with torch.no_grad():\n","        reject_decisions = hum_rejector(data_x)\n","        for i in range(len(data_x)):\n","            if reject_decisions[i] == 1:\n","                # defer\n","                predictions.append(ai_preds[i])\n","            else:\n","                predictions.append(hum_preds[i])\n","    return predictions, reject_decisions\n","\n","def get_metrics(preds, truths):\n","    # custom for each use case\n","    return evaluate_truth_pred(truths, preds)\n","\n","def compute_metrics(human_preds, ai_preds, reject_decisions, truths, to_print = False):\n","    coverage = 1 - np.sum(reject_decisions)/len(reject_decisions)\n","    humanai_preds = []\n","    human_preds_sys = []\n","    truths_human = []\n","    ai_preds_sys = []\n","    truths_ai = []\n","    for i in range(len(reject_decisions)):\n","        if reject_decisions[i] == 1:\n","            humanai_preds.append(ai_preds[i])\n","            ai_preds_sys.append(ai_preds[i])\n","            truths_ai.append(truths[i])\n","        else:\n","            humanai_preds.append(human_preds[i])\n","            human_preds_sys.append(human_preds[i])\n","            truths_human.append(truths[i])\n","    humanai_metrics = get_metrics(humanai_preds, truths)\n","    human_metrics = get_metrics(human_preds_sys, truths_human)\n","    ai_metrics = get_metrics(ai_preds_sys, truths_ai)\n","    if to_print:\n","        print(f'Coverage is {coverage*100:.2f}')\n","        print(f' metrics of system are: {humanai_metrics}')\n","        print(f' metrics of human are: {human_metrics}')\n","        print(f' metrics of AI are: {ai_metrics}')\n","    return coverage, humanai_metrics, human_metrics, ai_metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzX4BNVrwsjv"},"source":["# Preliminary steps:\n","# Step 1.1: get predictions of human and predictions of AI on teaching set\n","# Step 1.2: get prior rejector decisions of Human on teaching set\n","# Step 2: Compute optimal deferal decision for each point in teaching set  \n","# Step 3: Compute optimal gamma for each point, can start with a constant guess\n","\n","# Algorithms:\n","# Initialize HumanLearner\n","# Baseline 1:\n","# step 1: get k-mediods points\n","# step 2: add to HumanLearner\n","# step 3: evaluate on validation set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kvke1RG19y8n"},"source":["# Get AI predictions\n","ai_teaching_preds = []\n","ai_validation_preds = []\n","ai_val_preds = []\n","ai_train_preds = []\n","with open('/content/predictions_ans_val.json', 'r') as handle:\n","    preds_val = json.load(handle)\n","#with open('preds_train_data.p', 'rb') as handle:\n","#    preds_train = pickle.load(handle)\n","\n","for key, value in preds_val.items():\n","    ai_val_preds.append(value)\n","\n","#for key, value in preds_train.items():\n","#    ai_train_preds.append(value)\n","\n","ai_teaching_preds = ai_val_preds[:START_TEST]\n","ai_validation_preds = ai_val_preds[START_TEST:]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wObOYxRa_yYy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615384291442,"user_tz":300,"elapsed":1873,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"6830d6fc-1c40-4e9c-defb-571e425f7be5"},"source":["# Get Human Predictions\n","human_predictor = HumanPredictor_simple(0.6)\n","hum_teaching_preds = []\n","hum_validation_preds = []\n","priorhum_teaching_preds = []\n","priorhum_validation_preds = []\n","print(\"--Getting Human predictions on teach and validation sets --\\n\")\n","hum_teaching_preds = human_predictor.predict(teaching_contexts, teaching_questions, teaching_answers)\n","hum_validation_preds = human_predictor.predict(validation_contexts, validation_questions, validation_answers)\n","print(\"--Getting prior rejector predictions on teach and validation sets\") \n","priorhum_teaching_preds = human_predictor.prior_rejector(teaching_contexts, teaching_questions, teaching_answers)\n","priorhum_validation_preds = human_predictor.prior_rejector(validation_contexts, validation_questions, validation_answers)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--Getting Human predictions on teach and validation sets --\n","\n","--Getting prior rejector predictions on teach and validation sets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AkOgLiQFCfnr"},"source":["# Optimal deferall decisions\n","opt_defer_teaching = []\n","opt_defer_validation = []\n","for ex in range(len(teaching_contexts)):\n","    f1_hum = metric_max_over_ground_truths(f1_score, teaching_answers[ex]['text'], [hum_teaching_preds[ex]])\n","    f1_ai = metric_max_over_ground_truths(f1_score, teaching_answers[ex]['text'], [ai_teaching_preds[ex]])\n","\n","    if f1_ai > f1_hum:\n","        opt_defer_teaching.append(1)\n","    else:\n","        opt_defer_teaching.append(0)\n","\n","for ex in range(len(validation_contexts)):\n","    f1_hum = metric_max_over_ground_truths(f1_score, validation_answers[ex]['text'], [hum_validation_preds[ex]])\n","    f1_ai = metric_max_over_ground_truths(f1_score, validation_answers[ex]['text'], [ai_validation_preds[ex]])\n","    if f1_ai > f1_hum:\n","        opt_defer_validation.append(1)\n","    else:\n","        opt_defer_validation.append(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3n94HMAQohg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615384298014,"user_tz":300,"elapsed":882,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"1f63be0f-1d3d-437b-faf0-2ed2311813b1"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, priorhum_validation_preds, [validation_answers[i]['text'] for i in range(len(validation_answers))], True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 100.00\n"," metrics of system are: {'exact_match': 55.71158520118807, 'f1': 57.2702156863682}\n"," metrics of human are: {'exact_match': 55.71158520118807, 'f1': 57.2702156863682}\n"," metrics of AI are: {'exact_match': 0.0, 'f1': 0.0}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1.0,\n"," {'exact_match': 55.71158520118807, 'f1': 57.2702156863682},\n"," {'exact_match': 55.71158520118807, 'f1': 57.2702156863682},\n"," {'exact_match': 0.0, 'f1': 0.0})"]},"metadata":{"tags":[]},"execution_count":226}]},{"cell_type":"code","metadata":{"id":"FLDRcNORVnhE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615384300066,"user_tz":300,"elapsed":831,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"dd468baa-8c79-4ef4-ed6d-ce338215ad86"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, opt_defer_validation, [validation_answers[i]['text'] for i in range(len(validation_answers))])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.6594652984066973,\n"," {'exact_match': 80.82635700783126, 'f1': 86.47748080712576},\n"," {'exact_match': 84.47993447993413, 'f1': 84.69960534403612},\n"," {'exact_match': 73.75099127676388, 'f1': 89.9204402685561})"]},"metadata":{"tags":[]},"execution_count":227}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"2toUXpkvGR-C","executionInfo":{"status":"ok","timestamp":1615356378203,"user_tz":300,"elapsed":779,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"9373fef1-e244-4c42-86ee-3852f4237418"},"source":["import pickle\n","with open('/content/embeddings_data_val.p', 'rb') as handle:\n","    embeddings_val = pickle.load(handle)\n","\n","embeddings_val = [embeddings_val[i][1] for i in range(len(embeddings_val))]\n","embeddings_val = np.asarray(embeddings_val)\n","teaching_embeddings = embeddings_val[:START_TEST]\n","validation_embeddings = embeddings_val[START_TEST:]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nwith open('embeddings_train_data.p', 'rb') as handle:\\n    embeddings_train = pickle.load(handle)\\nteaching_embeddings = [embeddings_train[i][1] for i in range(len(embeddings_train))]\\nteaching_embeddings = np.asarray(teaching_embeddings)\\nteaching_embeddings = np.asarray([np.mean(teaching_embeddings[i], axis = 0) for i in range(len(teaching_embeddings))])\\n\""]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcU7RmpWnuVC","executionInfo":{"status":"ok","timestamp":1615384400516,"user_tz":300,"elapsed":96623,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"eb751372-9453-455c-c2aa-26ba5d5f2b6b"},"source":["# get optimal gammas\n","optimal_gammas = []\n","with tqdm(total=len(teaching_embeddings)) as pbar:\n","    for i in range(len(teaching_embeddings)):\n","        # get all similarities\n","        opt_defer_ex = opt_defer_teaching[i]\n","        similarities_embeds = rbf_kernel(teaching_embeddings[i].reshape(1,-1), np.asarray(teaching_embeddings))[0]\n","        sorted_sim = sorted([(similarities_embeds[k], opt_defer_teaching[k]) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n","        indicess = list(range(1, len(opt_defer_teaching)))\n","        indicess.reverse()\n","        for k in indicess:\n","            if sorted_sim[k][1] == opt_defer_ex and sorted_sim[k- 1][1] != opt_defer_ex:\n","                optimal_gammas.append(sorted_sim[k][0])\n","                break\n","        pbar.update(1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 3702/3702 [01:35<00:00, 38.59it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ju0Uo1ygN57b","executionInfo":{"status":"ok","timestamp":1615384806835,"user_tz":300,"elapsed":3803,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"83fa1b1c-119d-487d-f688-7c10d31ec823"},"source":["# Baseline get medoids\n","from sklearn_extra.cluster import KMedoids\n","kmedoids = KMedoids(n_clusters=len(teaching_embeddings)-1, init='k-medoids++', max_iter=10000).fit(teaching_embeddings)\n","print(kmedoids.inertia_)\n","teaching_indices = kmedoids.medoid_indices_"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7242298\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f3vb__twflp4"},"source":["[teaching_contexts[i] for i in teaching_indices]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYdDHTVDOuMy"},"source":["human_learner = HumanLearner(kernel_similarity)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ypgVR3zaYxi"},"source":["for teach_ex_idx in teaching_indices:\n","    ex_embed = teaching_embeddings[teach_ex_idx]\n","    ex_label = opt_defer_teaching[teach_ex_idx]\n","    gamma = 0.95#optimal_gammas[teach_ex_idx] # random choice\n","    human_learner.add_to_teaching([ex_embed, ex_label, gamma])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8nTD390avbN","executionInfo":{"status":"ok","timestamp":1615384980057,"user_tz":300,"elapsed":164969,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"5762cc00-e6c9-4060-bbb4-426336c5c6eb"},"source":["preds_teaching = human_learner.predict(teaching_embeddings, priorhum_teaching_preds, True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 2/3702 [00:00<03:07, 19.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["-- Human making reject predictions --\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3702/3702 [02:44<00:00, 22.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Used posterior 100.00\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WH0UyQ6yOQkT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615383529311,"user_tz":300,"elapsed":87574,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"99464007-f80c-4659-b53c-62c1de49fc65"},"source":["preds_val = human_learner.predict(validation_embeddings, priorhum_validation_preds, True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 4/3703 [00:00<01:36, 38.14it/s]"],"name":"stderr"},{"output_type":"stream","text":["-- Human making reject predictions --\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3703/3703 [01:27<00:00, 42.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Used posterior 100.00\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Hkv4LciOXCM","executionInfo":{"status":"ok","timestamp":1615383599790,"user_tz":300,"elapsed":1113,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"3040b517-f4de-4816-aaa7-7ec165ad8a12"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, preds_val, [validation_answers[i]['text'] for i in range(len(validation_answers))], True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 87.90\n"," metrics of system are: {'exact_match': 56.79179044018348, 'f1': 59.857469325326164}\n"," metrics of human are: {'exact_match': 56.52841781874022, 'f1': 58.05541610373188}\n"," metrics of AI are: {'exact_match': 58.70535714285583, 'f1': 72.95051226347023}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.8790170132325141,\n"," {'exact_match': 56.79179044018348, 'f1': 59.857469325326164},\n"," {'exact_match': 56.52841781874022, 'f1': 58.05541610373188},\n"," {'exact_match': 58.70535714285583, 'f1': 72.95051226347023})"]},"metadata":{"tags":[]},"execution_count":208}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDEj109hZvFx","executionInfo":{"status":"ok","timestamp":1615383597223,"user_tz":300,"elapsed":1157,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"3bd56ba9-d25e-46b8-db6c-9f6be95c6346"},"source":["compute_metrics(hum_validation_preds, ai_validation_preds, priorhum_validation_preds, [validation_answers[i]['text'] for i in range(len(validation_answers))], True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 100.00\n"," metrics of system are: {'exact_match': 56.19767755873601, 'f1': 57.734920668872135}\n"," metrics of human are: {'exact_match': 56.19767755873601, 'f1': 57.734920668872135}\n"," metrics of AI are: {'exact_match': 0.0, 'f1': 0.0}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1.0,\n"," {'exact_match': 56.19767755873601, 'f1': 57.734920668872135},\n"," {'exact_match': 56.19767755873601, 'f1': 57.734920668872135},\n"," {'exact_match': 0.0, 'f1': 0.0})"]},"metadata":{"tags":[]},"execution_count":207}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74emkKDJdQ3O","executionInfo":{"status":"ok","timestamp":1615385427532,"user_tz":300,"elapsed":1058,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"63730175-320f-4c82-e908-f7cd4047dc45"},"source":["compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teaching, [teaching_answers[i]['text'] for i in range(len(teaching_answers))], True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 72.47\n"," metrics of system are: {'exact_match': 63.371150729335326, 'f1': 68.08218030799523}\n"," metrics of human are: {'exact_match': 60.79016026835609, 'f1': 62.07308123813874}\n"," metrics of AI are: {'exact_match': 70.1668302257108, 'f1': 83.90397893844079}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.7247433819556997,\n"," {'exact_match': 63.371150729335326, 'f1': 68.08218030799523},\n"," {'exact_match': 60.79016026835609, 'f1': 62.07308123813874},\n"," {'exact_match': 70.1668302257108, 'f1': 83.90397893844079})"]},"metadata":{"tags":[]},"execution_count":241}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj3gpI3Ib_iz","executionInfo":{"status":"ok","timestamp":1615385029111,"user_tz":300,"elapsed":900,"user":{"displayName":"Hussein Mozannar","photoUrl":"","userId":"03221912190329599144"}},"outputId":"48f23ce0-8ef8-4135-fdee-81845bf04619"},"source":["compute_metrics(hum_teaching_preds, ai_teaching_preds, priorhum_teaching_preds, [teaching_answers[i]['text'] for i in range(len(teaching_answers))], True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Coverage is 100.00\n"," metrics of system are: {'exact_match': 54.80821177741746, 'f1': 56.437087734483555}\n"," metrics of human are: {'exact_match': 54.80821177741746, 'f1': 56.437087734483555}\n"," metrics of AI are: {'exact_match': 0.0, 'f1': 0.0}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1.0,\n"," {'exact_match': 54.80821177741746, 'f1': 56.437087734483555},\n"," {'exact_match': 54.80821177741746, 'f1': 56.437087734483555},\n"," {'exact_match': 0.0, 'f1': 0.0})"]},"metadata":{"tags":[]},"execution_count":239}]},{"cell_type":"markdown","metadata":{"id":"ya-DAgGbPmFh"},"source":["## Our approach"]},{"cell_type":"code","metadata":{"id":"gp3DsCWrQAFR"},"source":["data_sizes  = []\n","indices_used = []\n","points_chosen = []\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBIkCCsUPoPT"},"source":["MAX_SIZE = 2000\n","human_learner = HumanLearner(kernel_similarity)\n","errors = []\n","for itt in range(MAX_SIZE):\n","    print(f'New size {itt}')\n","    best_index = -1\n","    best_value = 0\n","    valid_indices = list(set(list(range(len(teaching_answers)))) - set(indices_used))\n","    subset_size = min(10, len(valid_indices))\n","    random_teach_subset = random.sample(valid_indices, subset_size) # used to take gradient steps\n","    random_validation_subset = random.sample(valid_indices, subset_size)\n","    print(\"\")\n","    # for each point, add and see effect then remove\n","    counter_ = 0\n","    for j in random_teach_subset:\n","        counter_ += 1\n","        ex_embed = teaching_embeddings[j]\n","        ex_label = opt_defer_teaching[j]\n","        gamma = optimal_gammas[j] # random choice\n","        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n","        preds_teach = human_learner.predict([teaching_embeddings[i] for i in random_validation_subset], [priorhum_teaching_preds[i] for i in random_validation_subset])\n","        _, metrics, __, ___ = compute_metrics([hum_teaching_preds[kk] for kk in random_validation_subset], [ai_teaching_preds[kk] for kk in random_validation_subset], preds_teach, [teaching_answers[kk]['text'] for kk in random_validation_subset])\n","        #if counter_ % 100 == 0:\n","        #    print(metrics)\n","        acc = metrics[\"f1\"]\n","        if acc >= best_value:\n","            best_value = acc\n","            best_index = j\n","        human_learner.remove_last_teaching_item()\n","\n","    indices_used.append(best_index) # add found element to set used\n","    ex_embed = teaching_embeddings[best_index]\n","    ex_label = opt_defer_teaching[best_index]\n","    gamma = optimal_gammas[best_index] # random choice\n","    human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n","    if itt % 50 == 0:\n","        print(\"####### Actual eval \" +str(itt)+ \" ###########\")\n","        preds_teach = human_learner.predict(validation_embeddings, priorhum_validation_preds)\n","        _, metrics, __, ___ = compute_metrics(hum_validation_preds, ai_validation_preds, preds_teach, [validation_answers[i]['text'] for i in range(len(validation_answers))], True)\n","        errors.append(metrics)   \n","        print(\"##############################\")"],"execution_count":null,"outputs":[]}]}