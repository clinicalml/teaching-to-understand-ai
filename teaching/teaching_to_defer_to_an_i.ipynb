{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "teaching_to_defer_to_an_i.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxD7R_w4ybIM"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9yZQJkFxqIz"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "from sklearn import neighbors, datasets\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import torch.nn.parallel\n",
        "from tqdm import tqdm\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "from torchvision.datasets.utils import download_url, check_integrity\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from scipy.stats import multivariate_normal\n",
        "import  scipy.stats as st\n",
        "from matplotlib import cm\n",
        "from __future__ import print_function\n",
        "from spacy.lang.en import English\n",
        "from sklearn.cluster import KMeans\n",
        "import pickle\n",
        "import matplotlib\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as tfunc\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "import scipy.stats as st\n",
        "#import lime\n",
        "#import lime.lime_tabular\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A64Do-nD2NSj"
      },
      "source": [
        "class TeacherExplainer():\n",
        "    \"\"\" Returns top examples that best teach a learner when to defer to a classifier.\n",
        "    Given a tabular dataset with classifier predictions, human predictions and a similarity metric,\n",
        "    the method returns the top k images that best describe when to defer to the AI.    \n",
        "     \"\"\"\n",
        "\n",
        "def __init__(self,\n",
        "             data_x,\n",
        "             data_y,\n",
        "             hum_preds,\n",
        "             ai_preds,\n",
        "             prior_rejector_preds,\n",
        "             sim_kernel,\n",
        "             metric_y,\n",
        "             teaching_points = 10):\n",
        "        \"\"\"Init function.\n",
        "        Args:\n",
        "            data_x: 2d numpy array of the features\n",
        "            data_y: 1d numpy array of labels\n",
        "            hum_preds:  1d array of the human predictions \n",
        "            ai_preds:  1d array of the AI predictions \n",
        "            prior_rejector_preds: 1d binary array of the prior rejector preds \n",
        "            sim_kernel: function that takes as input two inputs and returns a positive number \n",
        "        \"\"\"\n",
        "        self.data_x = data_x\n",
        "        self.data_y = data_y\n",
        "        self.hum_preds = hum_preds\n",
        "        self.data_y = data_y\n",
        "        self.ai_preds = ai_preds\n",
        "        self.sim_kernel = sim_kernel\n",
        "        self.prior_rejector_preds = self.prior_rejector_preds\n",
        "        self.teaching_points = teaching_points\n",
        "\n",
        "def get_teaching_examples(teaching_points):\n",
        "    \"\"\" obtains teaching points.\n",
        "    Args:\n",
        "        teaching_points: number of teaching points\n",
        "    Return:\n",
        "        teaching_x: 2d numpy array of teaching points features\n",
        "        teaching_indices: indices of the teaching points in self.data_x\n",
        "        teaching_gammas: 1d numpy of gamma values used\n",
        "        teaching_labels: 1d array of deferral labels where 1 signifies defer to AI and 0 signifies don't defer to AI\n",
        "    \n",
        "    \"\"\"\n",
        "    self.teaching_points = teaching_points\n",
        "    # run algorithm to get examples\n",
        "    teaching_x = [ ]\n",
        "    teaching_indices = []\n",
        "    teaching_gammas = []\n",
        "    teaching_labels = []\n",
        "    # ALGORITHM here\n",
        "    # define human learner \n",
        "    # run algorithm to get teaching points\n",
        "    return teaching_x, teaching_gammas, teaching_labels, teaching_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGQ3QXgp66Wl"
      },
      "source": [
        "class HumanLearner:\n",
        "    \"\"\" Model of Human Learner.\n",
        "    Learner has a list of training points each with a radius and label.\n",
        "    Learner follows the radius nearest neighbor assumption.\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel):\n",
        "        '''\n",
        "        Args:\n",
        "            kernel: function that takes two inputs and returns a similarity\n",
        "        '''\n",
        "        self.teaching_set = []\n",
        "        self.kernel = kernel\n",
        "        self.rejector_tresh = 0.8\n",
        "\n",
        "    def predict(self, xs, prior_rejector_preds, to_print = False):\n",
        "        '''\n",
        "        Args:\n",
        "            xs: teaching points \n",
        "            prior_rejector_preds: predictions of prior rejector\n",
        "        Return:\n",
        "            preds: posterior human learner rejector predictions\n",
        "        '''\n",
        "        preds = []\n",
        "        idx = 0\n",
        "        used_posterior = 0 \n",
        "        for x in xs:\n",
        "            ball_at_x = []\n",
        "            similarities = kernel(x.reshape(1,-1), np.asarray([self.teaching_set[kk][0] for kk in range(len(self.teaching_set))]))[0]\n",
        "            for i in range(len(self.teaching_set)):\n",
        "                similarity = similarities[i]\n",
        "                if similarity >=  self.teaching_set[i][2]:\n",
        "                    ball_at_x.append(self.teaching_set[i])\n",
        "            if len(ball_at_x) == 0: \n",
        "                preds.append(prior_rejector_preds[idx])\n",
        "            else:\n",
        "                used_posterior += 1\n",
        "                ball_similarities = kernel(x.reshape(1,-1), np.asarray([ball_at_x[kk][0] for kk in range(len(ball_at_x))]))[0]\n",
        "                normalization = np.sum([ball_similarities[i] for i in range(len(ball_at_x))])\n",
        "                score_one = np.sum([ball_similarities[i]*ball_at_x[i][1] for i in range(len(ball_at_x))])\n",
        "                pred = score_one / normalization\n",
        "                if pred >= 0.5:\n",
        "                    preds.append(1)\n",
        "                else:\n",
        "                    preds.append(0)\n",
        "            idx += 1\n",
        "        \n",
        "        return preds\n",
        "\n",
        "    def add_to_teaching(self, teaching_example):\n",
        "        '''\n",
        "        adds teaching_example to training set\n",
        "        args:\n",
        "            teaching_example: (x, label, gamma)\n",
        "        '''\n",
        "        self.teaching_set.append(teaching_example)\n",
        "\n",
        "    def remove_last_teaching_item(self):\n",
        "        \"\"\" removes last placed teaching example from training set\"\"\"\n",
        "        self.teaching_set = self.teaching_set[:-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHqbpHiN7ypi"
      },
      "source": [
        "def compute_predictions_humanai(hum_preds, hum_rejector, ai_preds, data_x):\n",
        "    '''\n",
        "    hum_preds: array of human predictions\n",
        "    ai_preds: array of AI predictions\n",
        "    hum_rejector: HumanLearner\n",
        "    data_x: array of inputs\n",
        "\n",
        "    Returns array of final predictions and deferalls\n",
        "    '''\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        reject_decisions = hum_rejector(data_x)\n",
        "        for i in range(len(data_x)):\n",
        "            if reject_decisions[i] == 1:\n",
        "                # defer\n",
        "                predictions.append(ai_preds[i])\n",
        "            else:\n",
        "                predictions.append(hum_preds[i])\n",
        "    return predictions, reject_decisions\n",
        "\n",
        "def get_metrics(preds, truths):\n",
        "    # to be implemented for each method, higher better\n",
        "    '''\n",
        "    preds: array of predictions\n",
        "    truths:  target array\n",
        "    '''\n",
        "    acc = metrics.accuracy_score(truths, preds)\n",
        "    metrics_computed = { \"score\": acc}\n",
        "    return metrics_computed\n",
        "\n",
        "def compute_metrics(human_preds, ai_preds, reject_decisions, truths, to_print = False):\n",
        "    coverage = 1 - np.sum(reject_decisions)/len(reject_decisions)\n",
        "    humanai_preds = []\n",
        "    human_preds_sys = []\n",
        "    truths_human = []\n",
        "    ai_preds_sys = []\n",
        "    truths_ai = []\n",
        "    for i in range(len(reject_decisions)):\n",
        "        if reject_decisions[i] == 1:\n",
        "            humanai_preds.append(ai_preds[i])\n",
        "            ai_preds_sys.append(ai_preds[i])\n",
        "            truths_ai.append(truths[i])\n",
        "        else:\n",
        "            humanai_preds.append(human_preds[i])\n",
        "            human_preds_sys.append(human_preds[i])\n",
        "            truths_human.append(truths[i])\n",
        "    humanai_metrics = get_metrics(humanai_preds, truths)\n",
        "\n",
        "    human_metrics = get_metrics(human_preds_sys, truths_human)\n",
        "\n",
        "    ai_metrics = get_metrics(ai_preds_sys, truths_ai)\n",
        "\n",
        "    if to_print:\n",
        "        print(f'Coverage is {coverage*100:.2f}')\n",
        "        print(f' metrics of system are: {humanai_metrics}')\n",
        "        print(f' metrics of human are: {human_metrics}')\n",
        "        print(f' metrics of AI are: {ai_metrics}')\n",
        "    return coverage, humanai_metrics, human_metrics, ai_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IztFgisW7006"
      },
      "source": [
        "# get optimal gammas, ONLY FOR TEACHING\n",
        "def get_optimal_consistent_gammas(teaching_embeddings, opt_defer_teaching ):\n",
        "    '''\n",
        "    Args:\n",
        "        teaching_embeddings: teaching points \n",
        "        opt_defer_teaching: binary deferral label \n",
        "    Return:\n",
        "        preds: posterior human learner rejector predictions\n",
        "    '''\n",
        "    optimal_gammas = []\n",
        "    with tqdm(total=len(teaching_embeddings)) as pbar:\n",
        "        similarities_embeds_all = rbf_kernel( np.asarray(teaching_embeddings), np.asarray(teaching_embeddings))\n",
        "        for i in range(len(teaching_embeddings)):\n",
        "            # get all similarities\n",
        "            similarities_embeds = similarities_embeds_all[i]\n",
        "            opt_defer_ex = opt_defer_teaching[i]\n",
        "            opt_gamma = 1\n",
        "            sorted_sim = sorted([(similarities_embeds[k], opt_defer_teaching[k]) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n",
        "            indicess = list(range(1, len(opt_defer_teaching)))\n",
        "            indicess.reverse()\n",
        "            for k in indicess:\n",
        "                if sorted_sim[k][1] == opt_defer_ex and sorted_sim[k- 1][1] != opt_defer_ex:\n",
        "                    opt_gamma = sorted_sim[k][0]\n",
        "                    break\n",
        "            optimal_gammas.append(opt_gamma)\n",
        "            pbar.update(1)\n",
        "    return optimal_gammas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJcc6fFa728Z"
      },
      "source": [
        "import multiprocessing\n",
        "from multiprocessing.dummy import Pool as ThreadPool\n",
        "\n",
        "indicess = list(range(1, len(teaching_embeddings) -1 ))\n",
        "indicess.reverse()\n",
        "def get_improvement_defer_greedy(current_defer_preds, opt_defer_preds, xs, seen_indices):\n",
        "\n",
        "    error_improvements = []\n",
        "    error_at_i = 0\n",
        "    found_gammas = []\n",
        "    for i in range(len(opt_defer_preds)):\n",
        "        coin = random.random() # random number between [0,1]\n",
        "\n",
        "        similarities_embeds = similarities_embeds_all[i]\n",
        "        sorted_sim = sorted_sims[i] #sorted([(similarities_embeds[k], k) for k in range(len(teaching_embeddings))], key=lambda tup: tup[0])\n",
        "\n",
        "        max_improve = -1000\n",
        "        gamma_value = optimal_gammas[i]\n",
        "        current_improve = 0\n",
        "        so_far = 0\n",
        "        for j in indicess:\n",
        "            if i in seen_indices:\n",
        "                continue\n",
        "\n",
        "            so_far += 1\n",
        "            idx = int(sorted_sim[j][1])\n",
        "            f1_hum = hum_teaching_preds_b[idx]\n",
        "            f1_ai = ai_teaching_preds_b[idx]\n",
        "            if opt_defer_preds[i] == 1:\n",
        "                if current_defer_preds[idx] == 0:\n",
        "                    current_improve += f1_ai - f1_hum\n",
        "            else:\n",
        "                if current_defer_preds[idx] == 1:\n",
        "                    current_improve += f1_hum - f1_ai\n",
        "\n",
        "            if current_improve >= max_improve:\n",
        "                max_improve = current_improve \n",
        "                gamma_value = min(optimal_gammas[i], sorted_sim[j][0] )\n",
        "            \n",
        "        error_improvements.append(max_improve)\n",
        "        found_gammas.append(gamma_value)\n",
        "    return error_improvements, found_gammas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wd5Ob6B74MZ"
      },
      "source": [
        "def teach_ours_doublegreedy():\n",
        "    human_learner = HumanLearner(None)\n",
        "\n",
        "    errors = []\n",
        "    data_sizes  = []\n",
        "    indices_used = []\n",
        "    points_chosen = []\n",
        "    for itt in range(MAX_SIZE):\n",
        "        print(f'New size {itt}')\n",
        "        best_index = -1\n",
        "        # predict with current human learner\n",
        "        if itt == 0:\n",
        "            preds_teach = priorhum_teaching_preds\n",
        "        else:\n",
        "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
        "        error_improvements, best_gammas = get_improvement_defer_greedy(preds_teach, opt_defer_teaching,  teaching_embeddings, indices_used)\n",
        "        print(f'got improvements with max {max(error_improvements)}')\n",
        "        best_index = np.argmax(error_improvements)\n",
        "        indices_used.append(best_index) # add found element to set used\n",
        "        ex_embed = teaching_embeddings[best_index]\n",
        "        ex_label = opt_defer_teaching[best_index]\n",
        "        gamma = best_gammas[best_index] # + (np.random.rand(1)[0])*(1-optimal_gammas[best_index])-(1-optimal_gammas[best_index])/2 # random choice\n",
        "        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n",
        "\n",
        "        if False and itt % PLOT_INTERVAL == 0:\n",
        "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
        "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
        "            _, metricsc, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, teaching_target, True)\n",
        "            #errors.append(metricsc)   \n",
        "            print(\"##############################\")\n",
        "\n",
        "        if   itt % PLOT_INTERVAL == 0:\n",
        "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
        "            preds_teach = human_learner.predict(testing_embeddings, priorhum_testing_preds)\n",
        "            _, metricsc, __, ___ = compute_metrics(hum_testing_preds, ai_testing_preds, preds_teach, testing_target, True)\n",
        "            errors.append(metricsc['accuracy'])   \n",
        "            print(\"##############################\")\n",
        "    return errors, indices_used\n",
        "#errors_doublegreedy, indices_used_doublegreedy = teach_ours_doublegreedy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wbtcrgs75WJ"
      },
      "source": [
        "def get_improvement_defer(current_defer_preds, opt_defer_preds, gammas, xs, coin_prob = 0.1):\n",
        "    error_improvements = []\n",
        "    #similarities_embeds_all = rbf_kernel(np.asarray(xs), np.asarray(xs))\n",
        "    error_at_i = 0\n",
        "    for i in range(len(gammas)):\n",
        "        coin = random.random() # random number between [0,1]\n",
        "        error_at_i = 0\n",
        "        similarities_embeds = similarities_embeds_all[i]\n",
        "        for j in range(len(similarities_embeds)):\n",
        "            if similarities_embeds[j] >= gammas[i]:\n",
        "                f1_hum = hum_teaching_preds_b[j]\n",
        "                f1_ai = ai_teaching_preds_b[j]\n",
        "                if opt_defer_preds[i] == 1:\n",
        "                    if current_defer_preds[j] == 0:\n",
        "                        error_at_i += f1_ai - f1_hum\n",
        "                else:\n",
        "                    if current_defer_preds[j] == 1:\n",
        "                        error_at_i += f1_hum - f1_ai\n",
        "        error_improvements.append(error_at_i)\n",
        "\n",
        "        # get the ball for x\n",
        "        # in this ball how many does the current defer not match the optimal\n",
        "    return error_improvements\n",
        "\n",
        "\n",
        "\n",
        "def teach_ours(greedy_gamma = False):\n",
        "    human_learner = HumanLearner(None)\n",
        "    errors = []\n",
        "    data_sizes  = []\n",
        "    indices_used = []\n",
        "    points_chosen = []\n",
        "    for itt in range(MAX_SIZE):\n",
        "        print(f'New size {itt}')\n",
        "        best_index = -1\n",
        "        # predict with current human learner\n",
        "        if itt == 0:\n",
        "            preds_teach = priorhum_teaching_preds\n",
        "        else:\n",
        "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
        "        error_improvements = get_improvement_defer(preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
        "        best_index = np.argmax(error_improvements)\n",
        "        indices_used.append(best_index) # add found element to set used\n",
        "        ex_embed = teaching_embeddings[best_index]\n",
        "        ex_label = opt_defer_teaching[best_index]\n",
        "\n",
        "        if greedy_gamma:\n",
        "            _, greedy_gamma = get_greedy_gamma(best_index, preds_teach, opt_defer_teaching, optimal_gammas, teaching_embeddings)\n",
        "            gamma = greedy_gamma\n",
        "            print(f'got improvements with max {_}')\n",
        "        else:\n",
        "            gamma = optimal_gammas[best_index]\n",
        "            print(f'got improvements with max {max(error_improvements)}')\n",
        "\n",
        "        #gamma = optimal_gammas[best_index] # + (np.random.rand(1)[0])*(1-optimal_gammas[best_index])-(1-optimal_gammas[best_index])/2 # random choice\n",
        "        human_learner.add_to_teaching([ex_embed, ex_label, gamma])\n",
        "\n",
        "        if False and itt % 3 == 0:\n",
        "            print(\"####### train eval \" +str(itt)+ \" ###########\")\n",
        "            preds_teach = human_learner.predict(teaching_embeddings, priorhum_teaching_preds)\n",
        "            _, metrics, __, ___ = compute_metrics(hum_teaching_preds, ai_teaching_preds, preds_teach, teaching_target, True)\n",
        "            #errors.append(metrics)   \n",
        "            print(\"##############################\")\n",
        "\n",
        "        if   itt % PLOT_INTERVAL == 0:\n",
        "\n",
        "            plt.imshow(  train_dataset[best_index][0].permute(1, 2, 0)  )\n",
        "            plt.show()\n",
        "            print(\"####### val eval \" +str(itt)+ \" ###########\")\n",
        "            preds_teach = human_learner.predict(testing_embeddings, priorhum_testing_preds)\n",
        "            _, metrics, __, ___ = compute_metrics(hum_testing_preds, ai_testing_preds, preds_teach, testing_target, True)\n",
        "            errors.append(metrics['accuracy'])   \n",
        "            print(\"##############################\")\n",
        "    return errors, indices_used\n",
        "#errors, indices_used = teach_ours(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGPFtT9yq5T"
      },
      "source": [
        "GOAL\n",
        "\n",
        "general:\n",
        "\n",
        "given dataloader and costs, retreive set of points and their indices and gammas, and distance metric\n",
        "\n",
        "input:\n",
        "- \n",
        "- \n",
        "- \n",
        "\n",
        "test case\n",
        "- images with cifar \n",
        "\n",
        "- adult dataset fake expert\n",
        "\n",
        "- \n",
        "\n"
      ]
    }
  ]
}